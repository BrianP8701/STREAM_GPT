{
    "metadata": {
        "type": "web",
        "url": "https://docs.llamaindex.ai/en/stable/core_modules/query_modules/chat_engines/root.html",
        "title": "Chat Engine - LlamaIndex \ud83e\udd99 0.8.49",
        "description": null
    },
    "text": "[Back to top](#)\n\nToggle table of contents sidebar\n\n## Chat Engine[\uf0c1](#chat-engine \"Permalink to this heading\")\n\n## Concept[\uf0c1](#concept \"Permalink to this heading\")\n\nChat engine is a high-level interface for having a conversation with your data (multiple back-and-forth instead of a single question & answer). Think ChatGPT, but augmented with your knowledge base.\n\nConceptually, it is a **stateful** analogy of a [Query Engine](https://docs.llamaindex.ai/en/stable/core_modules/query_modules/query_engine/root.html). By keeping track of the conversation history, it can answer questions with past context in mind.\n\nTip\n\nIf you want to ask standalone question over your data (i.e. without keeping track of conversation history), use [Query Engine](https://docs.llamaindex.ai/en/stable/core_modules/query_modules/query_engine/root.html) instead.\n\n## Usage Pattern[\uf0c1](#usage-pattern \"Permalink to this heading\")\n\nGet started with:\n\nchat\\_engine \\= index.as\\_chat\\_engine()\nresponse \\= chat\\_engine.chat(\"Tell me a joke.\")\n\nTo stream response:\n\nchat\\_engine \\= index.as\\_chat\\_engine()\nstreaming\\_response \\= chat\\_engine.stream\\_chat(\"Tell me a joke.\")\nfor token in streaming\\_response.response\\_gen:\n    print(token, end\\=\"\")\n\n*   [Usage Pattern](https://docs.llamaindex.ai/en/stable/core_modules/query_modules/chat_engines/usage_pattern.html)\n    *   [Get Started](https://docs.llamaindex.ai/en/stable/core_modules/query_modules/chat_engines/usage_pattern.html#get-started)\n    *   [Configuring a Chat Engine](https://docs.llamaindex.ai/en/stable/core_modules/query_modules/chat_engines/usage_pattern.html#configuring-a-chat-engine)\n\n## Modules[\uf0c1](#modules \"Permalink to this heading\")\n\nBelow you can find corresponding tutorials to see the available chat engines in action.\n\n*   [Module Guides](https://docs.llamaindex.ai/en/stable/core_modules/query_modules/chat_engines/modules.html)\n    *   [ReAct Chat Engine](https://docs.llamaindex.ai/en/stable/examples/chat_engine/chat_engine_react.html)\n    *   [OpenAI Chat Engine](https://docs.llamaindex.ai/en/stable/examples/chat_engine/chat_engine_openai.html)\n    *   [Context Chat Engine](https://docs.llamaindex.ai/en/stable/examples/chat_engine/chat_engine_context.html)\n    *   [Condense Question Chat Engine](https://docs.llamaindex.ai/en/stable/examples/chat_engine/chat_engine_condense_question.html)\n    *   [Simple Chat Engine](https://docs.llamaindex.ai/en/stable/examples/chat_engine/chat_engine_repl.html)"
}