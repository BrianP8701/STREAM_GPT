{
    "metadata": {
        "type": "web",
        "url": "https://docs.llamaindex.ai/en/stable/community/integrations/guidance.html",
        "title": "Guidance - LlamaIndex \ud83e\udd99 0.8.49",
        "description": null
    },
    "text": "[Back to top](#)\n\nToggle table of contents sidebar\n\n## Guidance[\uf0c1](#guidance \"Permalink to this heading\")\n\n[Guidance](https://github.com/microsoft/guidance) is a guidance language for controlling large language models developed by Microsoft.\n\nGuidance programs allow you to interleave generation, prompting, and logical control into a single continuous flow matching how the language model actually processes the text.\n\n## Structured Output[\uf0c1](#structured-output \"Permalink to this heading\")\n\nOne particularly exciting aspect of guidance is the ability to output structured objects (think JSON following a specific schema, or a pydantic object). Instead of just \u201csuggesting\u201d the desired output structure to the LLM, guidance can actually \u201cforce\u201d the LLM output to follow the desired schema. This allows the LLM to focus on the content rather than the syntax, and completely eliminate the possibility of output parsing issues.\n\nThis is particularly powerful for weaker LLMs which be smaller in parameter count, and not trained on sufficient source code data to be able to reliably produce well-formed, hierarchical structured output.\n\n### Creating a guidance program to generate pydantic objects[\uf0c1](#creating-a-guidance-program-to-generate-pydantic-objects \"Permalink to this heading\")\n\nIn LlamaIndex, we provide an initial integration with guidance, to make it super easy for generating structured output (more specifically pydantic objects).\n\nFor example, if we want to generate an album of songs, with the following schema:\n\nclass Song(BaseModel):\n    title: str\n    length\\_seconds: int\n\nclass Album(BaseModel):\n    name: str\n    artist: str\n    songs: List\\[Song\\]\n\nIt\u2019s as simple as creating a `GuidancePydanticProgram`, specifying our desired pydantic class `Album`, and supplying a suitable prompt template.\n\n> Note: guidance uses handlebars-style templates, which uses double braces for variable substitution, and single braces for literal braces. This is the opposite convention of Python format strings.\n\n> Note: We provide an utility function `from llama_index.prompts.guidance_utils import convert_to_handlebars` that can convert from the Python format string style template to guidance handlebars-style template.\n\nprogram \\= GuidancePydanticProgram(\n    output\\_cls\\=Album,\n    prompt\\_template\\_str\\=\"Generate an example album, with an artist and a list of songs. Using the movie {{movie\\_name}} as inspiration\",\n    guidance\\_llm\\=OpenAI('text-davinci-003'),\n    verbose\\=True,\n)\n\nNow we can run the program by calling it with additional user input. Here let\u2019s go for something spooky and create an album inspired by the Shining.\n\noutput \\= program(movie\\_name\\='The Shining')\n\nWe have our pydantic object:\n\nAlbum(name\\='The Shining', artist\\='Jack Torrance', songs\\=\\[Song(title\\='All Work and No Play', length\\_seconds\\=180), Song(title\\='The Overlook Hotel', length\\_seconds\\=240), Song(title\\='The Shining', length\\_seconds\\=210)\\])\n\nYou can play with [this notebook](https://docs.llamaindex.ai/en/stable/examples/output_parsing/guidance_pydantic_program.html) for more details.\n\n### Using guidance to improve the robustness of our sub-question query engine.[\uf0c1](#using-guidance-to-improve-the-robustness-of-our-sub-question-query-engine \"Permalink to this heading\")\n\nLlamaIndex provides a toolkit of advanced query engines for tackling different use-cases. Several relies on structured output in intermediate steps. We can use guidance to improve the robustness of these query engines, by making sure the intermediate response has the expected structure (so that they can be parsed correctly to a structured object).\n\nAs an example, we implement a `GuidanceQuestionGenerator` that can be plugged into a `SubQuestionQueryEngine` to make it more robust than using the default setting.\n\nfrom llama\\_index.question\\_gen.guidance\\_generator import GuidanceQuestionGenerator\nfrom guidance.llms import OpenAI as GuidanceOpenAI\n\n\\# define guidance based question generator\nquestion\\_gen \\= GuidanceQuestionGenerator.from\\_defaults(guidance\\_llm\\=GuidanceOpenAI('text-davinci-003'), verbose\\=False)\n\n\\# define query engine tools\nquery\\_engine\\_tools \\= ...\n\n\\# construct sub-question query engine\ns\\_engine \\= SubQuestionQueryEngine.from\\_defaults(\n    question\\_gen\\=question\\_gen  \\# use guidance based question\\_gen defined above\n    query\\_engine\\_tools\\=query\\_engine\\_tools,\n)\n\nSee [this notebook](https://docs.llamaindex.ai/en/stable/examples/output_parsing/guidance_sub_question.html) for more details."
}