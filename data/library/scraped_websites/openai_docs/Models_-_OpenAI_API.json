{
    "metadata": {
        "type": "web",
        "url": "https://platform.openai.com/docs/models/default-usage-policies-by-endpoint",
        "title": "Models - OpenAI API",
        "description": "Explore resources, tutorials, API docs, and dynamic examples to get the most out of OpenAI's developer platform."
    },
    "text": "[](https://platform.openai.com/docs/models/models)\n\n## [Models](https://platform.openai.com/docs/models/models)\n\n[](https://platform.openai.com/docs/models/overview)\n\n## [Overview](https://platform.openai.com/docs/models/overview)\n\nThe OpenAI API is powered by a diverse set of models with different capabilities and price points. You can also make customizations to our models for your specific use case with [fine-tuning](https://platform.openai.com/docs/guides/fine-tuning).\n\n| Models | Description |\n| --- | --- |\n| [GPT-4](https://platform.openai.com/docs/models/gpt-4) | A set of models that improve on GPT-3.5 and can understand as well as generate natural language or code |\n| [GPT-3.5](https://platform.openai.com/docs/models/gpt-3-5) | A set of models that improve on GPT-3 and can understand as well as generate natural language or code |\n| [GPT base](https://platform.openai.com/docs/models/gpt-base) | A set of models without instruction following that can understand as well as generate natural language or code |\n| [DALL\u00b7E](https://platform.openai.com/docs/models/dall-e) | A model that can generate and edit images given a natural language prompt |\n| [Whisper](https://platform.openai.com/docs/models/whisper) | A model that can convert audio into text |\n| [Embeddings](https://platform.openai.com/docs/models/embeddings) | A set of models that can convert text into a numerical form |\n| [Moderation](https://platform.openai.com/docs/models/moderation) | A fine-tuned model that can detect whether text may be sensitive or unsafe |\n| [GPT-3](https://platform.openai.com/docs/models/gpt-3)<br><br>Legacy | A set of models that can understand and generate natural language |\n| [Deprecated](https://platform.openai.com/docs/deprecations) | A full list of models that have been deprecated |\n\nWe have also published open source models including [Point-E](https://github.com/openai/point-e), [Whisper](https://github.com/openai/whisper), [Jukebox](https://github.com/openai/jukebox), and [CLIP](https://github.com/openai/CLIP).\n\nVisit our [model index for researchers](https://platform.openai.com/docs/model-index-for-researchers) to learn more about which models have been featured in our research papers and the differences between model series like InstructGPT and GPT-3.5.\n\n* * *\n\n[](https://platform.openai.com/docs/models/continuous-model-upgrades)\n\n## [Continuous model upgrades](https://platform.openai.com/docs/models/continuous-model-upgrades)\n\nBased on developer feedback, we are extending support for gpt-3.5-turbo-0301 and gpt-4-0314 models in the OpenAI API until at least June 13, 2024. We've updated our [June 13 blog post](https://openai.com/blog/function-calling-and-other-api-updates) with more details.\n\nWith the release of `gpt-3.5-turbo`, some of our models are now being continually updated. `gpt-3.5-turbo`, `gpt-4`, and `gpt-4-32k` point to the latest model version. You can verify this by looking at the [response object](https://platform.openai.com/docs/api-reference/chat/object) after sending a ChatCompletion request. The response will include the specific model version used (e.g. `gpt-3.5-turbo-0613`).\n\nWe also offer static model versions that developers can continue using for at least three months after an updated model has been introduced. With the new cadence of model updates, we are also giving people the ability to contribute evals to help us improve the model for different use cases. If you are interested, check out the [OpenAI Evals](https://github.com/openai/evals) repository.\n\nThe following models are the temporary snapshots, we will announce their deprecation dates once updated versions are available. If you want to use the latest model version, use the standard model names like `gpt-4` or `gpt-3.5-turbo`.\n\n| Model name | Discontinuation date | Replacement model |\n| --- | --- | --- |\n| `gpt-3.5-turbo-0301` | at earliest 2024-06-13 | `gpt-3.5-turbo-0613` |\n| `gpt-4-0314` | at earliest 2024-06-13 | `gpt-4-0613` |\n| `gpt-4-32k-0314` | at earliest 2024-06-13 | `gpt-4-32k-0613` |\n\nLearn more about model deprecation on our [deprecation page](https://platform.openai.com/docs/deprecations).\n\n[](https://platform.openai.com/docs/models/gpt-4)\n\n## [GPT-4](https://platform.openai.com/docs/models/gpt-4)\n\nGPT-4 is currently accessible to those who have made at least [one successful payment](https://help.openai.com/en/articles/7102672-how-can-i-access-gpt-4) through our developer platform.\n\nGPT-4 is a large multimodal model (accepting text inputs and emitting text outputs today, with image inputs coming in the future) that can solve difficult problems with greater accuracy than any of our previous models, thanks to its broader general knowledge and advanced reasoning capabilities. Like `gpt-3.5-turbo`, GPT-4 is optimized for chat but works well for traditional completions tasks using the [Chat completions API](https://platform.openai.com/docs/api-reference/chat). Learn how to use GPT-4 in our [GPT guide](https://platform.openai.com/docs/guides/gpt).\n\n| Latest model | Description | Max tokens | Training data |\n| --- | --- | --- | --- |\n| gpt-4 | More capable than any GPT-3.5 model, able to do more complex tasks, and optimized for chat. Will be updated with our latest model iteration 2 weeks after it is released. | 8,192 tokens | Up to Sep 2021 |\n| gpt-4-0613 | Snapshot of `gpt-4` from June 13th 2023 with function calling data. Unlike `gpt-4`, this model will not receive updates, and will be deprecated 3 months after a new version is released. | 8,192 tokens | Up to Sep 2021 |\n| gpt-4-32k | Same capabilities as the standard `gpt-4` mode but with 4x the context length. Will be updated with our latest model iteration. | 32,768 tokens | Up to Sep 2021 |\n| gpt-4-32k-0613 | Snapshot of `gpt-4-32` from June 13th 2023. Unlike `gpt-4-32k`, this model will not receive updates, and will be deprecated 3 months after a new version is released. | 32,768 tokens | Up to Sep 2021 |\n| gpt-4-0314 (Legacy) | Snapshot of `gpt-4` from March 14th 2023 with function calling data. Unlike `gpt-4`, this model will not receive updates, and will be deprecated on June 13th 2024 at the earliest. | 8,192 tokens | Up to Sep 2021 |\n| gpt-4-32k-0314 (Legacy) | Snapshot of `gpt-4-32` from March 14th 2023. Unlike `gpt-4-32k`, this model will not receive updates, and will be deprecated on June 13th 2024 at the earliest. | 32,768 tokens | Up to Sep 2021 |\n\nFor many basic tasks, the difference between GPT-4 and GPT-3.5 models is not significant. However, in more complex reasoning situations, GPT-4 is much more capable than any of our previous models.\n\n[](https://platform.openai.com/docs/models/gpt-3-5)\n\n## [GPT-3.5](https://platform.openai.com/docs/models/gpt-3-5)\n\nGPT-3.5 models can understand and generate natural language or code. Our most capable and cost effective model in the GPT-3.5 family is `gpt-3.5-turbo` which has been optimized for chat using the [Chat completions API](https://platform.openai.com/docs/api-reference/chat) but works well for traditional completions tasks as well.\n\n| Latest model | Description | Max tokens | Training data |\n| --- | --- | --- | --- |\n| gpt-3.5-turbo | Most capable GPT-3.5 model and optimized for chat at 1/10th the cost of `text-davinci-003`. Will be updated with our latest model iteration 2 weeks after it is released. | 4,097 tokens | Up to Sep 2021 |\n| gpt-3.5-turbo-16k | Same capabilities as the standard `gpt-3.5-turbo` model but with 4 times the context. | 16,385 tokens | Up to Sep 2021 |\n| gpt-3.5-turbo-instruct | Similar capabilities as `text-davinci-003` but compatible with legacy Completions endpoint and not Chat Completions. | 4,097 tokens | Up to Sep 2021 |\n| gpt-3.5-turbo-0613 | Snapshot of `gpt-3.5-turbo` from June 13th 2023 with function calling data. Unlike `gpt-3.5-turbo`, this model will not receive updates, and will be deprecated 3 months after a new version is released. | 4,097 tokens | Up to Sep 2021 |\n| gpt-3.5-turbo-16k-0613 | Snapshot of `gpt-3.5-turbo-16k` from June 13th 2023. Unlike `gpt-3.5-turbo-16k`, this model will not receive updates, and will be deprecated 3 months after a new version is released. | 16,385 tokens | Up to Sep 2021 |\n| gpt-3.5-turbo-0301 (Legacy) | Snapshot of `gpt-3.5-turbo` from March 1st 2023. Unlike `gpt-3.5-turbo`, this model will not receive updates, and will be deprecated on June 13th 2024 at the earliest. | 4,097 tokens | Up to Sep 2021 |\n| text-davinci-003 (Legacy) | Can do any language task with better quality, longer output, and consistent instruction-following than the curie, babbage, or ada models. Also supports some additional features such as [inserting text](https://platform.openai.com/docs/guides/gpt/inserting-text). | 4,097 tokens | Up to Jun 2021 |\n| text-davinci-002 (Legacy) | Similar capabilities to `text-davinci-003` but trained with supervised fine-tuning instead of reinforcement learning | 4,097 tokens | Up to Jun 2021 |\n| code-davinci-002 (Legacy) | Optimized for code-completion tasks | 8,001 tokens | Up to Jun 2021 |\n\nWe recommend using `gpt-3.5-turbo` over the other GPT-3.5 models because of its lower cost and improved performance.\n\nOpenAI models are non-deterministic, meaning that identical inputs can yield different outputs. Setting [temperature](https://platform.openai.com/docs/api-reference/chat/create#chat/create-temperature) to 0 will make the outputs mostly deterministic, but a small amount of variability may remain.\n\n[](https://platform.openai.com/docs/models/gpt-base)\n\n## [GPT base](https://platform.openai.com/docs/models/gpt-base)\n\nGPT base models can understand and generate natural language or code but are not trained with instruction following. These models are made to be replacements for our original GPT-3 base models and use the legacy Completions API. Most customers should use GPT-3.5 or GPT-4.\n\n| Latest model | Description | Max tokens | Training data |\n| --- | --- | --- | --- |\n| babbage-002 | Replacement for the GPT-3 `ada` and `babbage` base models. | 16,384 tokens | Up to Sep 2021 |\n| davinci-002 | Replacement for the GPT-3 `curie` and `davinci` base models. | 16,384 tokens | Up to Sep 2021 |\n\n[](https://platform.openai.com/docs/models/dall-e)\n\n## [DALL\u00b7E](https://platform.openai.com/docs/models/dall-e)\n\nDALL\u00b7E is a AI system that can create realistic images and art from a description in natural language. We currently support the ability, given a prompt, to create a new image with a certain size, edit an existing image, or create variations of a user provided image.\n\nThe current DALL\u00b7E model available through our API is the 2nd iteration of DALL\u00b7E with more realistic, accurate, and 4x greater resolution images than the original model. You can try it through the our [Labs interface](https://labs.openai.com/) or [via the API](https://platform.openai.com/docs/guides/images/introduction).\n\n[](https://platform.openai.com/docs/models/whisper)\n\n## [Whisper](https://platform.openai.com/docs/models/whisper)\n\nWhisper is a general-purpose speech recognition model. It is trained on a large dataset of diverse audio and is also a multi-task model that can perform multilingual speech recognition as well as speech translation and language identification. The Whisper v2-large model is currently available through our API with the `whisper-1` model name.\n\nCurrently, there is no difference between the [open source version of Whisper](https://github.com/openai/whisper) and the version available through our API. However, through our API, we offer an optimized inference process which makes running Whisper through our API much faster than doing it through other means. For more technical details on Whisper, you can [read the paper](https://arxiv.org/abs/2212.04356).\n\n[](https://platform.openai.com/docs/models/embeddings)\n\n## [Embeddings](https://platform.openai.com/docs/models/embeddings)\n\nEmbeddings are a numerical representation of text that can be used to measure the relatedness between two pieces of text. Our second generation embedding model, `text-embedding-ada-002` is a designed to replace the previous 16 first-generation embedding models at a fraction of the cost. Embeddings are useful for search, clustering, recommendations, anomaly detection, and classification tasks. You can read more about our latest embedding model in the [announcement blog post](https://openai.com/blog/new-and-improved-embedding-model).\n\n* * *\n\n[](https://platform.openai.com/docs/models/moderation)\n\n## [Moderation](https://platform.openai.com/docs/models/moderation)\n\nThe Moderation models are designed to check whether content complies with OpenAI's [usage policies](https://openai.com/policies/usage-policies). The models provide classification capabilities that look for content in the following categories: hate, hate/threatening, self-harm, sexual, sexual/minors, violence, and violence/graphic. You can find out more in our [moderation guide](https://platform.openai.com/docs/guides/moderation/overview).\n\nModeration models take in an arbitrary sized input that is automatically broken up into chunks of 4,096 tokens. In cases where the input is more than 32,768 tokens, truncation is used which in a rare condition may omit a small number of tokens from the moderation check.\n\nThe final results from each request to the moderation endpoint shows the maximum value on a per category basis. For example, if one chunk of 4K tokens had a category score of 0.9901 and the other had a score of 0.1901, the results would show 0.9901 in the API response since it is higher.\n\n| Model | Description | Max tokens |\n| --- | --- | --- |\n| text-moderation-latest | Most capable moderation model. Accuracy will be slightly higher than the stable model. | 32,768 |\n| text-moderation-stable | Almost as capable as the latest model, but slightly older. | 32,768 |\n\nGPT-3 models can understand and generate natural language. These models were superseded by the more powerful GPT-3.5 generation models. However, the original GPT-3 base models (`davinci`, `curie`, `ada`, and `babbage`) are current the only models that are available to fine-tune.\n\n| Latest model | Description | Max tokens | Training data |\n| --- | --- | --- | --- |\n| text-curie-001 | Very capable, faster and lower cost than Davinci. | 2,049 tokens | Up to Oct 2019 |\n| text-babbage-001 | Capable of straightforward tasks, very fast, and lower cost. | 2,049 tokens | Up to Oct 2019 |\n| text-ada-001 | Capable of very simple tasks, usually the fastest model in the GPT-3 series, and lowest cost. | 2,049 tokens | Up to Oct 2019 |\n| davinci | Most capable GPT-3 model. Can do any task the other models can do, often with higher quality. | 2,049 tokens | Up to Oct 2019 |\n| curie | Very capable, but faster and lower cost than Davinci. | 2,049 tokens | Up to Oct 2019 |\n| babbage | Capable of straightforward tasks, very fast, and lower cost. | 2,049 tokens | Up to Oct 2019 |\n| ada | Capable of very simple tasks, usually the fastest model in the GPT-3 series, and lowest cost. | 2,049 tokens | Up to Oct 2019 |\n\n[](https://platform.openai.com/docs/models/how-we-use-your-data)\n\n## [How we use your data](https://platform.openai.com/docs/models/how-we-use-your-data)\n\nYour data is your data.\n\nAs of March 1, 2023, data sent to the OpenAI API will not be used to train or improve OpenAI models (unless you explicitly [opt in](https://docs.google.com/forms/d/e/1FAIpQLSevgtKyiSWIOj6CV6XWBHl1daPZSOcIWzcUYUXQ1xttjBgDpA/viewform)). One advantage to opting in is that the models may get better at your use case over time.\n\nTo help identify abuse, API data may be retained for up to 30 days, after which it will be deleted (unless otherwise required by law). For trusted customers with sensitive applications, zero data retention may be available. With zero data retention, request and response bodies are not persisted to any logging mechanism and exist only in memory in order to serve the request.\n\nNote that this data policy does not apply to OpenAI's non-API consumer services like [ChatGPT](https://chat.openai.com/) or [DALL\u00b7E Labs](https://labs.openai.com/).\n\n[](https://platform.openai.com/docs/models/default-usage-policies-by-endpoint)\n\n### [Default usage policies by endpoint](https://platform.openai.com/docs/models/default-usage-policies-by-endpoint)\n\n| Endpoint | Data used for training | Default retention | Eligible for zero retention |\n| --- | --- | --- | --- |\n| `/v1/completions` | No  | 30 days | Yes |\n| `/v1/chat/completions` | No  | 30 days | Yes |\n| `/v1/edits` | No  | 30 days | Yes |\n| `/v1/images/generations` | No  | 30 days | No  |\n| `/v1/images/edits` | No  | 30 days | No  |\n| `/v1/images/variations` | No  | 30 days | No  |\n| `/v1/embeddings` | No  | 30 days | Yes |\n| `/v1/audio/transcriptions` | No  | Zero data retention | \\-  |\n| `/v1/audio/translations` | No  | Zero data retention | \\-  |\n| `/v1/files` | No  | Until deleted by customer | No  |\n| `/v1/fine_tuning/jobs` | No  | Until deleted by customer | No  |\n| `/v1/fine-tunes` | No  | Until deleted by customer | No  |\n| `/v1/moderations` | No  | Zero data retention | \\-  |\n\nFor details, see our [API data usage policies](https://openai.com/policies/api-data-usage-policies). To learn more about zero retention, get in touch with our [sales team](https://openai.com/contact-sales).\n\n[](https://platform.openai.com/docs/models/model-endpoint-compatibility)\n\n## [Model endpoint compatibility](https://platform.openai.com/docs/models/model-endpoint-compatibility)\n\n| Endpoint | Latest models |\n| --- | --- |\n| /v1/audio/transcriptions | `whisper-1` |\n| /v1/audio/translations | `whisper-1` |\n| /v1/chat/completions | `gpt-4`, `gpt-4-0613`, `gpt-4-32k`, `gpt-4-32k-0613`, `gpt-3.5-turbo`, `gpt-3.5-turbo-0613`, `gpt-3.5-turbo-16k`, `gpt-3.5-turbo-16k-0613` |\n| /v1/completions (Legacy) | `gpt-3.5-turbo-instruct`, `babbage-002`, `davinci-002` |\n| /v1/embeddings | `text-embedding-ada-002` |\n| /v1/fine\\_tuning/jobs | `gpt-3.5-turbo`, `babbage-002`, `davinci-002` |\n| /v1/moderations | `text-moderation-stable`, `text-moderation-latest` |\n\nThis list excludes all of our [DALL\u00b7E models](https://platform.openai.com/docs/guides/images/image-generation-beta) and our [deprecated models](https://platform.openai.com/docs/deprecations)."
}