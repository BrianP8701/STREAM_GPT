{
    "metadata": {
        "type": "repo",
        "path": "src/MobileNetv3/inference.py"
    },
    "text": "'''\n    This file contains the code for loading the model and performing inference on a single image.\n    \n    First load the model using the load_model function. \n    Then, passing that model and the path to an image to the infer_image function will return the predicted class.\n    \n    The output is a number starting from 0. These typically correspond to your classes alphabetically.\n'''\nfrom PIL import Image\nfrom torchvision import transforms\nimport numpy as np\n# You may need to adjust the input size based on the model you are using\n# For example, EfficientNet-B0 uses 224, but other versions may use larger sizes\ninput_size = 224\npreprocess = transforms.Compose([\n    transforms.Resize(input_size),\n    transforms.ToTensor(),\n    transforms.Lambda(lambda x: x.repeat(3, 1, 1) if x.shape[0] == 1 else x),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n])\n    \n# Perform inference using ONNX runtime\ndef run_onnx_inference(session, input_image):\n    input_name = session.get_inputs()[0].name\n    outputs = session.run(None, {input_name: input_image.numpy()})[0]\n    probabilities = softmax(outputs)\n    predicted_class = np.argmax(probabilities) # 0, 1 or 2\n    if predicted_class.item() == 0:\n        return 'normal'\n    elif predicted_class.item() == 1:\n        return 'over'\n    else:\n        return 'under'\n    \ndef apply_transforms(img):\n    if isinstance(img, str):\n        image = Image.open(img)\n    else:\n        img = Image.fromarray((img * 255).astype(np.uint8))\n        \n    image = preprocess(img)\n    image = image.unsqueeze(0)  # create a mini-batch as expected by the model\n    \n    return image\n\ndef softmax(logits):\n    exps = np.exp(logits - np.max(logits))\n    return exps / exps.sum()"
}