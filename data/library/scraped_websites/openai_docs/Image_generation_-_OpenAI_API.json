{
    "metadata": {
        "type": "web",
        "url": "https://platform.openai.com/docs/guides/images/error-handling",
        "title": "Image generation - OpenAI API",
        "description": "Explore resources, tutorials, API docs, and dynamic examples to get the most out of OpenAI's developer platform."
    },
    "text": "[](https://platform.openai.com/docs/guides/images/image-generation)\n\n## [Image generation](https://platform.openai.com/docs/guides/images/image-generation)\n\nLearn how to generate or manipulate images with our DALL\u00b7E models\n\n[](https://platform.openai.com/docs/guides/images/introduction)\n\n## [Introduction](https://platform.openai.com/docs/guides/images/introduction)\n\nThe Images API provides three methods for interacting with images:\n\n1.  Creating images from scratch based on a text prompt\n2.  Creating edits of an existing image based on a new text prompt\n3.  Creating variations of an existing image\n\nThis guide covers the basics of using these three API endpoints with useful code samples. To see them in action, check out our [DALL\u00b7E preview app](https://labs.openai.com/).\n\n[](https://platform.openai.com/docs/guides/images/usage)\n\n## [Usage](https://platform.openai.com/docs/guides/images/usage)\n\n[](https://platform.openai.com/docs/guides/images/generations)\n\n### [Generations](https://platform.openai.com/docs/guides/images/generations)\n\nThe [image generations](https://platform.openai.com/docs/api-reference/images/create) endpoint allows you to create an original image given a text prompt. Generated images can have a size of 256x256, 512x512, or 1024x1024 pixels. Smaller sizes are faster to generate. You can request 1-10 images at a time using the [n](https://platform.openai.com/docs/api-reference/images/create#images/create-n) parameter.\n\n```\n1\n2\n3\n4\n5\n6\nresponse = openai.Image.create(\n  prompt=\"a white siamese cat\",\n  n=1,\n  size=\"1024x1024\"\n)\nimage_url = response['data'][0]['url']\n```\n\nThe more detailed the description, the more likely you are to get the result that you or your end user want. You can explore the examples in the [DALL\u00b7E preview app](https://labs.openai.com/) for more prompting inspiration. Here's a quick example:\n\nEach image can be returned as either a URL or Base64 data, using the [response\\_format](https://platform.openai.com/docs/api-reference/images/create#images/create-response_format) parameter. URLs will expire after an hour.\n\n[](https://platform.openai.com/docs/guides/images/edits)\n\n### [Edits](https://platform.openai.com/docs/guides/images/edits)\n\nThe [image edits](https://platform.openai.com/docs/api-reference/images/create-edit) endpoint allows you to edit and extend an image by uploading a mask. The transparent areas of the mask indicate where the image should be edited, and the prompt should describe the full new image, **not just the erased area**. This endpoint can enable experiences like [the editor in our DALL\u00b7E preview app](https://labs.openai.com/editor).\n\n```\n1\n2\n3\n4\n5\n6\n7\n8\nresponse = openai.Image.create_edit(\n  image=open(\"sunlit_lounge.png\", \"rb\"),\n  mask=open(\"mask.png\", \"rb\"),\n  prompt=\"A sunlit indoor lounge area with a pool containing a flamingo\",\n  n=1,\n  size=\"1024x1024\"\n)\nimage_url = response['data'][0]['url']\n```\n\nPrompt: a sunlit indoor lounge area with a pool containing a flamingo\n\nThe uploaded image and mask must both be square PNG images less than 4MB in size, and also must have the same dimensions as each other. The non-transparent areas of the mask are not used when generating the output, so they don\u2019t necessarily need to match the original image like the example above.\n\n[](https://platform.openai.com/docs/guides/images/variations)\n\n### [Variations](https://platform.openai.com/docs/guides/images/variations)\n\nThe [image variations](https://platform.openai.com/docs/api-reference/images/create-variation) endpoint allows you to generate a variation of a given image.\n\n```\n1\n2\n3\n4\n5\n6\nresponse = openai.Image.create_variation(\n  image=open(\"corgi_and_cat_paw.png\", \"rb\"),\n  n=1,\n  size=\"1024x1024\"\n)\nimage_url = response['data'][0]['url']\n```\n\nSimilar to the edits endpoint, the input image must be a square PNG image less than 4MB in size.\n\n[](https://platform.openai.com/docs/guides/images/content-moderation)\n\n### [Content moderation](https://platform.openai.com/docs/guides/images/content-moderation)\n\nPrompts and images are filtered based on our [content policy](https://labs.openai.com/policies/content-policy), returning an error when a prompt or image is flagged. If you have any feedback on false positives or related issues, please contact us through our [help center](https://help.openai.com/).\n\n[](https://platform.openai.com/docs/guides/images/language-specific-tips)\n\n## [Language-specific tips](https://platform.openai.com/docs/guides/images/language-specific-tips)\n\n[](https://platform.openai.com/docs/guides/images/using-in-memory-image-data)\n\n### [Using in-memory image data](https://platform.openai.com/docs/guides/images/using-in-memory-image-data)\n\nThe Node.js examples in the guide above use the `fs` module to read image data from disk. In some cases, you may have your image data in memory instead. Here's an example API call that uses image data stored in a Node.js `Buffer` object:\n\n```\n1\n2\n3\n4\n5\n6\n7\n8\n9\n// This is the Buffer object that contains your image data\nconst buffer = [your image data];\n// Set a `name` that ends with .png so that the API knows it's a PNG image\nbuffer.name = \"image.png\";\nconst response = await openai.createImageVariation(\n  buffer,\n  1,\n  \"1024x1024\"\n);\n```\n\n[](https://platform.openai.com/docs/guides/images/working-with-typescript)\n\n### [Working with TypeScript](https://platform.openai.com/docs/guides/images/working-with-typescript)\n\nIf you're using TypeScript, you may encounter some quirks with image file arguments. Here's an example of working around the type mismatch by explicitly casting the argument:\n\n```\n1\n2\n3\n4\n5\n6\n// Cast the ReadStream to `any` to appease the TypeScript compiler\nconst response = await openai.createImageVariation(\n  fs.createReadStream(\"image.png\") as any,\n  1,\n  \"1024x1024\"\n);\n```\n\nAnd here's a similar example for in-memory image data:\n\n```\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n// This is the Buffer object that contains your image data\nconst buffer: Buffer = [your image data];\n// Cast the buffer to `any` so that we can set the `name` property\nconst file: any = buffer;\n// Set a `name` that ends with .png so that the API knows it's a PNG image\nfile.name = \"image.png\";\nconst response = await openai.createImageVariation(\n  file,\n  1,\n  \"1024x1024\"\n);\n```\n\n[](https://platform.openai.com/docs/guides/images/error-handling)\n\n### [Error handling](https://platform.openai.com/docs/guides/images/error-handling)\n\nAPI requests can potentially return errors due to invalid inputs, rate limits, or other issues. These errors can be handled with a `try...catch` statement, and the error details can be found in either `error.response` or `error.message`:\n\n```\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\ntry {\n  const response = await openai.createImageVariation(\n    fs.createReadStream(\"image.png\"),\n    1,\n    \"1024x1024\"\n  );\n  console.log(response.data.data[0].url);\n} catch (error) {\n  if (error.response) {\n    console.log(error.response.status);\n    console.log(error.response.data);\n  } else {\n    console.log(error.message);\n  }\n}\n```"
}