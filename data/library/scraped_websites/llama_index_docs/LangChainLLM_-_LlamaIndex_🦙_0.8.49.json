{
    "metadata": {
        "type": "web",
        "url": "https://docs.llamaindex.ai/en/stable/api_reference/llms/langchain.html",
        "title": "LangChainLLM - LlamaIndex \ud83e\udd99 0.8.49",
        "description": null
    },
    "text": "[Back to top](#)\n\nToggle table of contents sidebar\n\n## LangChainLLM[\uf0c1](#langchainllm \"Permalink to this heading\")\n\n_pydantic model_ llama\\_index.llms.langchain.LangChainLLM[\uf0c1](#llama_index.llms.langchain.LangChainLLM \"Permalink to this definition\")\n\nAdapter for a LangChain LLM.\n\nShow JSON schema\n\n{\n   \"title\": \"LangChainLLM\",\n   \"description\": \"Adapter for a LangChain LLM.\",\n   \"type\": \"object\",\n   \"properties\": {\n      \"callback\\_manager\": {\n         \"title\": \"Callback Manager\"\n      }\n   }\n}\n\nConfig\n\n*   **arbitrary\\_types\\_allowed**: _bool = True_\n    \n\nFields\n\nValidators\n\n*   `_validate_callback_manager` \u00bb `callback_manager`\n    \n\n_async_ achat(_messages: Sequence\\[[ChatMessage](https://docs.llamaindex.ai/en/stable/api_reference/llms.html#llama_index.llms.base.ChatMessage \"llama_index.llms.base.ChatMessage\")\\]_, _\\*\\*kwargs: Any_) \u2192 Any[\uf0c1](#llama_index.llms.langchain.LangChainLLM.achat \"Permalink to this definition\")\n\nAsync chat endpoint for LLM.\n\n_async_ acomplete(_\\*args: Any_, _\\*\\*kwargs: Any_) \u2192 Any[\uf0c1](#llama_index.llms.langchain.LangChainLLM.acomplete \"Permalink to this definition\")\n\nAsync completion endpoint for LLM.\n\n_async_ astream\\_chat(_messages: Sequence\\[[ChatMessage](https://docs.llamaindex.ai/en/stable/api_reference/llms.html#llama_index.llms.base.ChatMessage \"llama_index.llms.base.ChatMessage\")\\]_, _\\*\\*kwargs: Any_) \u2192 Any[\uf0c1](#llama_index.llms.langchain.LangChainLLM.astream_chat \"Permalink to this definition\")\n\nAsync streaming chat endpoint for LLM.\n\n_async_ astream\\_complete(_\\*args: Any_, _\\*\\*kwargs: Any_) \u2192 Any[\uf0c1](#llama_index.llms.langchain.LangChainLLM.astream_complete \"Permalink to this definition\")\n\nAsync streaming completion endpoint for LLM.\n\nchat(_messages: Sequence\\[[ChatMessage](https://docs.llamaindex.ai/en/stable/api_reference/llms.html#llama_index.llms.base.ChatMessage \"llama_index.llms.base.ChatMessage\")\\]_, _\\*\\*kwargs: Any_) \u2192 Any[\uf0c1](#llama_index.llms.langchain.LangChainLLM.chat \"Permalink to this definition\")\n\nChat endpoint for LLM.\n\n_classmethod_ class\\_name() \u2192 str[\uf0c1](#llama_index.llms.langchain.LangChainLLM.class_name \"Permalink to this definition\")\n\nGet the class name, used as a unique ID in serialization.\n\nThis provides a key that makes serialization robust against actual class name changes.\n\ncomplete(_\\*args: Any_, _\\*\\*kwargs: Any_) \u2192 Any[\uf0c1](#llama_index.llms.langchain.LangChainLLM.complete \"Permalink to this definition\")\n\nCompletion endpoint for LLM.\n\nstream\\_chat(_messages: Sequence\\[[ChatMessage](https://docs.llamaindex.ai/en/stable/api_reference/llms.html#llama_index.llms.base.ChatMessage \"llama_index.llms.base.ChatMessage\")\\]_, _\\*\\*kwargs: Any_) \u2192 Any[\uf0c1](#llama_index.llms.langchain.LangChainLLM.stream_chat \"Permalink to this definition\")\n\nStreaming chat endpoint for LLM.\n\nstream\\_complete(_\\*args: Any_, _\\*\\*kwargs: Any_) \u2192 Any[\uf0c1](#llama_index.llms.langchain.LangChainLLM.stream_complete \"Permalink to this definition\")\n\nStreaming completion endpoint for LLM.\n\n_property_ llm_: BaseLanguageModel_[\uf0c1](#llama_index.llms.langchain.LangChainLLM.llm \"Permalink to this definition\")\n\n_property_ metadata_: [LLMMetadata](https://docs.llamaindex.ai/en/stable/api_reference/llms.html#llama_index.llms.base.LLMMetadata \"llama_index.llms.base.LLMMetadata\")_[\uf0c1](#llama_index.llms.langchain.LangChainLLM.metadata \"Permalink to this definition\")\n\nLLM metadata."
}