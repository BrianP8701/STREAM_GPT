{
    "metadata": {
        "type": "web",
        "url": "https://docs.llamaindex.ai/en/stable/api_reference/query/query_engines/flare_query_engine.html",
        "title": "Flare Query Engine - LlamaIndex \ud83e\udd99 0.8.49",
        "description": null
    },
    "text": "[Back to top](#)\n\nToggle table of contents sidebar\n\n## Flare Query Engine[\uf0c1](#module-llama_index.query_engine.flare.base \"Permalink to this heading\")\n\nQuery engines based on the FLARE paper.\n\nActive Retrieval Augmented Generation.\n\n_class_ llama\\_index.query\\_engine.flare.base.FLAREInstructQueryEngine(_query\\_engine: BaseQueryEngine_, _service\\_context: Optional\\[[ServiceContext](https://docs.llamaindex.ai/en/stable/api_reference/service_context.html#llama_index.indices.service_context.ServiceContext \"llama_index.indices.service_context.ServiceContext\")\\] \\= None_, _instruct\\_prompt: Optional\\[[BasePromptTemplate](https://docs.llamaindex.ai/en/stable/api_reference/prompts.html#llama_index.prompts.base.BasePromptTemplate \"llama_index.prompts.base.BasePromptTemplate\")\\] \\= None_, _lookahead\\_answer\\_inserter: Optional\\[BaseLookaheadAnswerInserter\\] \\= None_, _done\\_output\\_parser: Optional\\[IsDoneOutputParser\\] \\= None_, _query\\_task\\_output\\_parser: Optional\\[QueryTaskOutputParser\\] \\= None_, _max\\_iterations: int \\= 10_, _max\\_lookahead\\_query\\_tasks: int \\= 1_, _callback\\_manager: Optional\\[[CallbackManager](https://docs.llamaindex.ai/en/stable/api_reference/callbacks.html#llama_index.callbacks.CallbackManager \"llama_index.callbacks.base.CallbackManager\")\\] \\= None_, _verbose: bool \\= False_)[\uf0c1](#llama_index.query_engine.flare.base.FLAREInstructQueryEngine \"Permalink to this definition\")\n\nFLARE Instruct query engine.\n\nThis is the version of FLARE that uses retrieval-encouraging instructions.\n\nNOTE: this is a beta feature. Interfaces might change, and it might not always give correct answers.\n\nParameters\n\n*   **query\\_engine** (_BaseQueryEngine_) \u2013 query engine to use\n    \n*   **service\\_context** (_Optional__\\[_[_ServiceContext_](https://docs.llamaindex.ai/en/stable/api_reference/service_context.html#llama_index.indices.service_context.ServiceContext \"llama_index.indices.service_context.ServiceContext\")_\\]_) \u2013 service context. Defaults to None.\n    \n*   **instruct\\_prompt** (_Optional__\\[_[_PromptTemplate_](https://docs.llamaindex.ai/en/stable/api_reference/prompts.html#llama_index.prompts.base.PromptTemplate \"llama_index.prompts.base.PromptTemplate\")_\\]_) \u2013 instruct prompt. Defaults to None.\n    \n*   **lookahead\\_answer\\_inserter** (_Optional__\\[__BaseLookaheadAnswerInserter__\\]_) \u2013 lookahead answer inserter. Defaults to None.\n    \n*   **done\\_output\\_parser** (_Optional__\\[__IsDoneOutputParser__\\]_) \u2013 done output parser. Defaults to None.\n    \n*   **query\\_task\\_output\\_parser** (_Optional__\\[__QueryTaskOutputParser__\\]_) \u2013 query task output parser. Defaults to None.\n    \n*   **max\\_iterations** (_int_) \u2013 max iterations. Defaults to 10.\n    \n*   **max\\_lookahead\\_query\\_tasks** (_int_) \u2013 max lookahead query tasks. Defaults to 1.\n    \n*   **callback\\_manager** (_Optional__\\[_[_CallbackManager_](https://docs.llamaindex.ai/en/stable/api_reference/callbacks.html#llama_index.callbacks.CallbackManager \"llama_index.callbacks.CallbackManager\")_\\]_) \u2013 callback manager. Defaults to None.\n    \n*   **verbose** (_bool_) \u2013 give verbose outputs. Defaults to False."
}