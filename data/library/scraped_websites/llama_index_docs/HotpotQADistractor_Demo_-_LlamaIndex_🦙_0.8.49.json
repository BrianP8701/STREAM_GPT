{
    "metadata": {
        "type": "web",
        "url": "https://docs.llamaindex.ai/en/stable/examples/evaluation/HotpotQADistractor.html",
        "title": "HotpotQADistractor Demo - LlamaIndex \ud83e\udd99 0.8.49",
        "description": null
    },
    "text": "[Back to top](#)\n\nToggle table of contents sidebar\n\n## HotpotQADistractor Demo[\uf0c1](#hotpotqadistractor-demo \"Permalink to this heading\")\n\nThis notebook walks through evaluating a query engine using the HotpotQA dataset. In this task, the LLM must answer a question given a pre-configured context. The answer usually has to be concise, and accuracy is measured by calculating the overlap (measured by F1) and exact match.\n\nfrom llama\\_index.evaluation.benchmarks import HotpotQAEvaluator\nfrom llama\\_index import ServiceContext, VectorStoreIndex\nfrom llama\\_index.schema import Document\nfrom llama\\_index.llms import OpenAI\n\nllm \\= OpenAI(model\\=\"gpt-3.5-turbo\")\n\nservice\\_context \\= ServiceContext.from\\_defaults(\n    embed\\_model\\=\"local:sentence-transformers/all-MiniLM-L6-v2\",\n    llm\\=llm,\n)\nindex \\= VectorStoreIndex.from\\_documents(\n    \\[Document.example()\\], service\\_context\\=service\\_context, show\\_progress\\=True\n)\n\nParsing documents into nodes: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 \\[00:00<00:00, 129.13it/s\\]\nGenerating embeddings: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 \\[00:00<00:00, 36.62it/s\\]\n\nFirst we try with a very simple engine. In this particular benchmark, the retriever and hence index is actually ignored, as the documents retrieved for each query is provided in the dataset. This is known as the \u201cdistractor\u201d setting in HotpotQA.\n\nengine \\= index.as\\_query\\_engine(service\\_context\\=service\\_context)\n\nHotpotQAEvaluator().run(engine, queries\\=5, show\\_result\\=True)\n\nDataset: hotpot\\_dev\\_distractor downloaded at: /Users/loganmarkewich/Library/Caches/llama\\_index/datasets/HotpotQA\nEvaluating on dataset: hotpot\\_dev\\_distractor\n-------------------------------------\nLoading 5 queries out of 7405 (fraction: 0.00068)\nQuestion:  Were Scott Derrickson and Ed Wood of the same nationality?\nResponse: No.\nCorrect answer:  yes\nEM: 0 F1: 0\n-------------------------------------\nQuestion:  What government position was held by the woman who portrayed Corliss Archer in the film Kiss and Tell?\nResponse: Unknown\nCorrect answer:  Chief of Protocol\nEM: 0 F1: 0\n-------------------------------------\nQuestion:  What science fantasy young adult series, told in first person, has a set of companion books narrating the stories of enslaved worlds and alien species?\nResponse: Animorphs\nCorrect answer:  Animorphs\nEM: 1 F1: 1.0\n-------------------------------------\nQuestion:  Are the Laleli Mosque and Esma Sultan Mansion located in the same neighborhood?\nResponse: Yes.\nCorrect answer:  no\nEM: 0 F1: 0\n-------------------------------------\nQuestion:  The director of the romantic comedy \"Big Stone Gap\" is based in what New York city?\nResponse: Greenwich Village\nCorrect answer:  Greenwich Village, New York City\nEM: 0 F1: 0.5714285714285715\n-------------------------------------\nScores:  {'exact\\_match': 0.2, 'f1': 0.31428571428571433}\n\nNow we try with a sentence transformer reranker, which selects 3 out of the 10 nodes proposed by the retriever\n\nfrom llama\\_index.indices.postprocessor import SentenceTransformerRerank\n\nrerank \\= SentenceTransformerRerank(top\\_n\\=3)\n\nengine \\= index.as\\_query\\_engine(\n    service\\_context\\=service\\_context,\n    node\\_postprocessors\\=\\[rerank\\],\n)\n\nHotpotQAEvaluator().run(engine, queries\\=5, show\\_result\\=True)\n\nDataset: hotpot\\_dev\\_distractor downloaded at: /Users/loganmarkewich/Library/Caches/llama\\_index/datasets/HotpotQA\nEvaluating on dataset: hotpot\\_dev\\_distractor\n-------------------------------------\nLoading 5 queries out of 7405 (fraction: 0.00068)\nQuestion:  Were Scott Derrickson and Ed Wood of the same nationality?\nResponse: No.\nCorrect answer:  yes\nEM: 0 F1: 0\n-------------------------------------\nQuestion:  What government position was held by the woman who portrayed Corliss Archer in the film Kiss and Tell?\nResponse: No government position.\nCorrect answer:  Chief of Protocol\nEM: 0 F1: 0\n-------------------------------------\nQuestion:  What science fantasy young adult series, told in first person, has a set of companion books narrating the stories of enslaved worlds and alien species?\nResponse: Animorphs\nCorrect answer:  Animorphs\nEM: 1 F1: 1.0\n-------------------------------------\nQuestion:  Are the Laleli Mosque and Esma Sultan Mansion located in the same neighborhood?\nResponse: No.\nCorrect answer:  no\nEM: 1 F1: 1.0\n-------------------------------------\nQuestion:  The director of the romantic comedy \"Big Stone Gap\" is based in what New York city?\nResponse: New York City.\nCorrect answer:  Greenwich Village, New York City\nEM: 0 F1: 0.7499999999999999\n-------------------------------------\nScores:  {'exact\\_match': 0.4, 'f1': 0.55}\n\nThe F1 and exact match scores appear to improve slightly.\n\nNote that the benchmark optimizes for producing short factoid answers without explanations, although it is known that CoT prompting can sometimes help in output quality.\n\nThe scores used are also not a perfect measure of correctness, but can be a quick way to identify how changes in your query engine change the output."
}