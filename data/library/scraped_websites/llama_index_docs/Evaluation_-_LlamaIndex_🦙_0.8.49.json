{
    "metadata": {
        "type": "web",
        "url": "https://docs.llamaindex.ai/en/stable/api_reference/evaluation.html",
        "title": "Evaluation - LlamaIndex \ud83e\udd99 0.8.49",
        "description": null
    },
    "text": "Toggle table of contents sidebar\n\n## Evaluation[\uf0c1](#evaluation \"Permalink to this heading\")\n\nWe have modules for both LLM-based evaluation and retrieval-based evaluation.\n\nEvaluation modules.\n\n_class_ llama\\_index.evaluation.BaseEvaluator[\uf0c1](#llama_index.evaluation.BaseEvaluator \"Permalink to this definition\")\n\nBase Evaluator class.\n\n_abstract async_ aevaluate(_query: Optional\\[str\\] \\= None_, _response: Optional\\[str\\] \\= None_, _contexts: Optional\\[Sequence\\[str\\]\\] \\= None_, _\\*\\*kwargs: Any_) \u2192 [EvaluationResult](#llama_index.evaluation.EvaluationResult \"llama_index.evaluation.base.EvaluationResult\")[\uf0c1](#llama_index.evaluation.BaseEvaluator.aevaluate \"Permalink to this definition\")\n\nRun evaluation with query string, retrieved contexts, and generated response string.\n\nSubclasses can override this method to provide custom evaluation logic and take in additional arguments.\n\n_async_ aevaluate\\_response(_query: Optional\\[str\\] \\= None_, _response: Optional\\[[Response](https://docs.llamaindex.ai/en/stable/api_reference/response.html#llama_index.response.schema.Response \"llama_index.response.schema.Response\")\\] \\= None_, _\\*\\*kwargs: Any_) \u2192 [EvaluationResult](#llama_index.evaluation.EvaluationResult \"llama_index.evaluation.base.EvaluationResult\")[\uf0c1](#llama_index.evaluation.BaseEvaluator.aevaluate_response \"Permalink to this definition\")\n\nRun evaluation with query string and generated Response object.\n\nSubclasses can override this method to provide custom evaluation logic and take in additional arguments.\n\nevaluate(_query: Optional\\[str\\] \\= None_, _response: Optional\\[str\\] \\= None_, _contexts: Optional\\[Sequence\\[str\\]\\] \\= None_, _\\*\\*kwargs: Any_) \u2192 [EvaluationResult](#llama_index.evaluation.EvaluationResult \"llama_index.evaluation.base.EvaluationResult\")[\uf0c1](#llama_index.evaluation.BaseEvaluator.evaluate \"Permalink to this definition\")\n\nRun evaluation with query string, retrieved contexts, and generated response string.\n\nSubclasses can override this method to provide custom evaluation logic and take in additional arguments.\n\nevaluate\\_response(_query: Optional\\[str\\] \\= None_, _response: Optional\\[[Response](https://docs.llamaindex.ai/en/stable/api_reference/response.html#llama_index.response.schema.Response \"llama_index.response.schema.Response\")\\] \\= None_, _\\*\\*kwargs: Any_) \u2192 [EvaluationResult](#llama_index.evaluation.EvaluationResult \"llama_index.evaluation.base.EvaluationResult\")[\uf0c1](#llama_index.evaluation.BaseEvaluator.evaluate_response \"Permalink to this definition\")\n\nRun evaluation with query string and generated Response object.\n\nSubclasses can override this method to provide custom evaluation logic and take in additional arguments.\n\n_pydantic model_ llama\\_index.evaluation.BaseRetrievalEvaluator[\uf0c1](#llama_index.evaluation.BaseRetrievalEvaluator \"Permalink to this definition\")\n\nBase Retrieval Evaluator class.\n\nShow JSON schema\n\n{\n   \"title\": \"BaseRetrievalEvaluator\",\n   \"description\": \"Base Retrieval Evaluator class.\",\n   \"type\": \"object\",\n   \"properties\": {\n      \"metrics\": {\n         \"title\": \"Metrics\"\n      }\n   }\n}\n\nConfig\n\n*   **arbitrary\\_types\\_allowed**: _bool = True_\n    \n\nFields\n\n*   `metrics (List[llama_index.evaluation.retrieval.metrics_base.BaseRetrievalMetric])`\n    \n\n_field_ metrics_: List\\[BaseRetrievalMetric\\]_ _\\[Required\\]_[\uf0c1](#llama_index.evaluation.BaseRetrievalEvaluator.metrics \"Permalink to this definition\")\n\nList of metrics to evaluate\n\n_async_ aevaluate(_query: str_, _expected\\_ids: List\\[str\\]_, _\\*\\*kwargs: Any_) \u2192 [RetrievalEvalResult](#llama_index.evaluation.RetrievalEvalResult \"llama_index.evaluation.retrieval.base.RetrievalEvalResult\")[\uf0c1](#llama_index.evaluation.BaseRetrievalEvaluator.aevaluate \"Permalink to this definition\")\n\nRun evaluation with query string, retrieved contexts, and generated response string.\n\nSubclasses can override this method to provide custom evaluation logic and take in additional arguments.\n\n_async_ aevaluate\\_dataset(_dataset: [EmbeddingQAFinetuneDataset](https://docs.llamaindex.ai/en/stable/api_reference/finetuning.html#llama_index.finetuning.EmbeddingQAFinetuneDataset \"llama_index.finetuning.embeddings.common.EmbeddingQAFinetuneDataset\")_, _workers: int \\= 2_, _show\\_progress: bool \\= False_, _\\*\\*kwargs: Any_) \u2192 List\\[[RetrievalEvalResult](#llama_index.evaluation.RetrievalEvalResult \"llama_index.evaluation.retrieval.base.RetrievalEvalResult\")\\][\uf0c1](#llama_index.evaluation.BaseRetrievalEvaluator.aevaluate_dataset \"Permalink to this definition\")\n\nRun evaluation with dataset.\n\n_classmethod_ construct(_\\_fields\\_set: Optional\\[SetStr\\] \\= None_, _\\*\\*values: Any_) \u2192 Model[\uf0c1](#llama_index.evaluation.BaseRetrievalEvaluator.construct \"Permalink to this definition\")\n\nCreates a new model setting \\_\\_dict\\_\\_ and \\_\\_fields\\_set\\_\\_ from trusted or pre-validated data. Default values are respected, but no other validation is performed. Behaves as if Config.extra = \u2018allow\u2019 was set since it adds all passed values\n\ncopy(_\\*_, _include: Optional\\[Union\\[AbstractSetIntStr, MappingIntStrAny\\]\\] \\= None_, _exclude: Optional\\[Union\\[AbstractSetIntStr, MappingIntStrAny\\]\\] \\= None_, _update: Optional\\[DictStrAny\\] \\= None_, _deep: bool \\= False_) \u2192 Model[\uf0c1](#llama_index.evaluation.BaseRetrievalEvaluator.copy \"Permalink to this definition\")\n\nDuplicate a model, optionally choose which fields to include, exclude and change.\n\nParameters\n\n*   **include** \u2013 fields to include in new model\n    \n*   **exclude** \u2013 fields to exclude from new model, as with values this takes precedence over include\n    \n*   **update** \u2013 values to change/add in the new model. Note: the data is not validated before creating the new model: you should trust this data\n    \n*   **deep** \u2013 set to True to make a deep copy of the model\n    \n\nReturns\n\nnew model instance\n\ndict(_\\*_, _include: Optional\\[Union\\[AbstractSetIntStr, MappingIntStrAny\\]\\] \\= None_, _exclude: Optional\\[Union\\[AbstractSetIntStr, MappingIntStrAny\\]\\] \\= None_, _by\\_alias: bool \\= False_, _skip\\_defaults: Optional\\[bool\\] \\= None_, _exclude\\_unset: bool \\= False_, _exclude\\_defaults: bool \\= False_, _exclude\\_none: bool \\= False_) \u2192 DictStrAny[\uf0c1](#llama_index.evaluation.BaseRetrievalEvaluator.dict \"Permalink to this definition\")\n\nGenerate a dictionary representation of the model, optionally specifying which fields to include or exclude.\n\nevaluate(_query: str_, _expected\\_ids: List\\[str\\]_, _\\*\\*kwargs: Any_) \u2192 [RetrievalEvalResult](#llama_index.evaluation.RetrievalEvalResult \"llama_index.evaluation.retrieval.base.RetrievalEvalResult\")[\uf0c1](#llama_index.evaluation.BaseRetrievalEvaluator.evaluate \"Permalink to this definition\")\n\nRun evaluation results with query string and expected ids.\n\nParameters\n\n*   **query** (_str_) \u2013 Query string\n    \n*   **expected\\_ids** (_List__\\[__str__\\]_) \u2013 Expected ids\n    \n\nReturns\n\nEvaluation result\n\nReturn type\n\n[RetrievalEvalResult](#llama_index.evaluation.RetrievalEvalResult \"llama_index.evaluation.RetrievalEvalResult\")\n\n_classmethod_ from\\_metric\\_names(_metric\\_names: List\\[str\\]_, _\\*\\*kwargs: Any_) \u2192 [BaseRetrievalEvaluator](#llama_index.evaluation.BaseRetrievalEvaluator \"llama_index.evaluation.retrieval.base.BaseRetrievalEvaluator\")[\uf0c1](#llama_index.evaluation.BaseRetrievalEvaluator.from_metric_names \"Permalink to this definition\")\n\nCreate evaluator from metric names.\n\nParameters\n\n*   **metric\\_names** (_List__\\[__str__\\]_) \u2013 List of metric names\n    \n*   **\\*\\*kwargs** \u2013 Additional arguments for the evaluator\n    \n\n_classmethod_ from\\_orm(_obj: Any_) \u2192 Model[\uf0c1](#llama_index.evaluation.BaseRetrievalEvaluator.from_orm \"Permalink to this definition\")\n\njson(_\\*_, _include: Optional\\[Union\\[AbstractSetIntStr, MappingIntStrAny\\]\\] \\= None_, _exclude: Optional\\[Union\\[AbstractSetIntStr, MappingIntStrAny\\]\\] \\= None_, _by\\_alias: bool \\= False_, _skip\\_defaults: Optional\\[bool\\] \\= None_, _exclude\\_unset: bool \\= False_, _exclude\\_defaults: bool \\= False_, _exclude\\_none: bool \\= False_, _encoder: Optional\\[Callable\\[\\[Any\\], Any\\]\\] \\= None_, _models\\_as\\_dict: bool \\= True_, _\\*\\*dumps\\_kwargs: Any_) \u2192 unicode[\uf0c1](#llama_index.evaluation.BaseRetrievalEvaluator.json \"Permalink to this definition\")\n\nGenerate a JSON representation of the model, include and exclude arguments as per dict().\n\nencoder is an optional function to supply as default to json.dumps(), other arguments as per json.dumps().\n\n_classmethod_ parse\\_file(_path: Union\\[str, Path\\]_, _\\*_, _content\\_type: unicode \\= None_, _encoding: unicode \\= 'utf8'_, _proto: Protocol \\= None_, _allow\\_pickle: bool \\= False_) \u2192 Model[\uf0c1](#llama_index.evaluation.BaseRetrievalEvaluator.parse_file \"Permalink to this definition\")\n\n_classmethod_ parse\\_obj(_obj: Any_) \u2192 Model[\uf0c1](#llama_index.evaluation.BaseRetrievalEvaluator.parse_obj \"Permalink to this definition\")\n\n_classmethod_ parse\\_raw(_b: Union\\[str, bytes\\]_, _\\*_, _content\\_type: unicode \\= None_, _encoding: unicode \\= 'utf8'_, _proto: Protocol \\= None_, _allow\\_pickle: bool \\= False_) \u2192 Model[\uf0c1](#llama_index.evaluation.BaseRetrievalEvaluator.parse_raw \"Permalink to this definition\")\n\n_classmethod_ schema(_by\\_alias: bool \\= True_, _ref\\_template: unicode \\= '#/definitions/{model}'_) \u2192 DictStrAny[\uf0c1](#llama_index.evaluation.BaseRetrievalEvaluator.schema \"Permalink to this definition\")\n\n_classmethod_ schema\\_json(_\\*_, _by\\_alias: bool \\= True_, _ref\\_template: unicode \\= '#/definitions/{model}'_, _\\*\\*dumps\\_kwargs: Any_) \u2192 unicode[\uf0c1](#llama_index.evaluation.BaseRetrievalEvaluator.schema_json \"Permalink to this definition\")\n\n_classmethod_ update\\_forward\\_refs(_\\*\\*localns: Any_) \u2192 None[\uf0c1](#llama_index.evaluation.BaseRetrievalEvaluator.update_forward_refs \"Permalink to this definition\")\n\nTry to update ForwardRefs on fields based on this Model, globalns and localns.\n\n_classmethod_ validate(_value: Any_) \u2192 Model[\uf0c1](#llama_index.evaluation.BaseRetrievalEvaluator.validate \"Permalink to this definition\")\n\n_class_ llama\\_index.evaluation.BatchEvalRunner(_evaluators: Dict\\[str, [BaseEvaluator](#llama_index.evaluation.BaseEvaluator \"llama_index.evaluation.base.BaseEvaluator\")\\]_, _workers: int \\= 2_, _show\\_progress: bool \\= False_)[\uf0c1](#llama_index.evaluation.BatchEvalRunner \"Permalink to this definition\")\n\nBatch evaluation runner.\n\nParameters\n\n*   **evaluators** (_Dict__\\[__str__,_ [_BaseEvaluator_](#llama_index.evaluation.BaseEvaluator \"llama_index.evaluation.BaseEvaluator\")_\\]_) \u2013 Dictionary of evaluators.\n    \n*   **workers** (_int_) \u2013 Number of workers to use for parallelization. Defaults to 2.\n    \n*   **show\\_progress** (_bool_) \u2013 Whether to show progress bars. Defaults to False.\n    \n\n_async_ aevaluate\\_queries(_query\\_engine: BaseQueryEngine_, _queries: Optional\\[List\\[str\\]\\] \\= None_, _\\*\\*eval\\_kwargs\\_lists: Dict\\[str, Any\\]_) \u2192 Dict\\[str, List\\[[EvaluationResult](#llama_index.evaluation.EvaluationResult \"llama_index.evaluation.base.EvaluationResult\")\\]\\][\uf0c1](#llama_index.evaluation.BatchEvalRunner.aevaluate_queries \"Permalink to this definition\")\n\nEvaluate queries.\n\nParameters\n\n*   **query\\_engine** (_BaseQueryEngine_) \u2013 Query engine.\n    \n*   **queries** (_Optional__\\[__List__\\[__str__\\]__\\]_) \u2013 List of query strings. Defaults to None.\n    \n*   **\\*\\*eval\\_kwargs\\_lists** (_Dict__\\[__str__,_ _Any__\\]_) \u2013 Dict of lists of kwargs to pass to evaluator. Defaults to None.\n    \n\n_async_ aevaluate\\_response\\_strs(_queries: Optional\\[List\\[str\\]\\] \\= None_, _response\\_strs: Optional\\[List\\[str\\]\\] \\= None_, _contexts\\_list: Optional\\[List\\[List\\[str\\]\\]\\] \\= None_, _\\*\\*eval\\_kwargs\\_lists: List_) \u2192 Dict\\[str, List\\[[EvaluationResult](#llama_index.evaluation.EvaluationResult \"llama_index.evaluation.base.EvaluationResult\")\\]\\][\uf0c1](#llama_index.evaluation.BatchEvalRunner.aevaluate_response_strs \"Permalink to this definition\")\n\nEvaluate query, response pairs.\n\nThis evaluates queries, responses, contexts as string inputs. Can supply additional kwargs to the evaluator in eval\\_kwargs\\_lists.\n\nParameters\n\n*   **queries** (_Optional__\\[__List__\\[__str__\\]__\\]_) \u2013 List of query strings. Defaults to None.\n    \n*   **response\\_strs** (_Optional__\\[__List__\\[__str__\\]__\\]_) \u2013 List of response strings. Defaults to None.\n    \n*   **contexts\\_list** (_Optional__\\[__List__\\[__List__\\[__str__\\]__\\]__\\]_) \u2013 List of context lists. Defaults to None.\n    \n*   **\\*\\*eval\\_kwargs\\_lists** (_Dict__\\[__str__,_ _Any__\\]_) \u2013 Dict of lists of kwargs to pass to evaluator. Defaults to None.\n    \n\n_async_ aevaluate\\_responses(_queries: Optional\\[List\\[str\\]\\] \\= None_, _responses: Optional\\[List\\[[Response](https://docs.llamaindex.ai/en/stable/api_reference/response.html#llama_index.response.schema.Response \"llama_index.response.schema.Response\")\\]\\] \\= None_, _\\*\\*eval\\_kwargs\\_lists: Dict\\[str, Any\\]_) \u2192 Dict\\[str, List\\[[EvaluationResult](#llama_index.evaluation.EvaluationResult \"llama_index.evaluation.base.EvaluationResult\")\\]\\][\uf0c1](#llama_index.evaluation.BatchEvalRunner.aevaluate_responses \"Permalink to this definition\")\n\nEvaluate query, response pairs.\n\nThis evaluates queries and response objects.\n\nParameters\n\n*   **queries** (_Optional__\\[__List__\\[__str__\\]__\\]_) \u2013 List of query strings. Defaults to None.\n    \n*   **responses** (_Optional__\\[__List__\\[_[_Response_](https://docs.llamaindex.ai/en/stable/api_reference/response.html#llama_index.response.schema.Response \"llama_index.response.schema.Response\")_\\]__\\]_) \u2013 List of response objects. Defaults to None.\n    \n*   **\\*\\*eval\\_kwargs\\_lists** (_Dict__\\[__str__,_ _Any__\\]_) \u2013 Dict of lists of kwargs to pass to evaluator. Defaults to None.\n    \n\nevaluate\\_queries(_query\\_engine: BaseQueryEngine_, _queries: Optional\\[List\\[str\\]\\] \\= None_, _\\*\\*eval\\_kwargs\\_lists: Dict\\[str, Any\\]_) \u2192 Dict\\[str, List\\[[EvaluationResult](#llama_index.evaluation.EvaluationResult \"llama_index.evaluation.base.EvaluationResult\")\\]\\][\uf0c1](#llama_index.evaluation.BatchEvalRunner.evaluate_queries \"Permalink to this definition\")\n\nEvaluate queries.\n\nSync version of aevaluate\\_queries.\n\nevaluate\\_response\\_strs(_queries: Optional\\[List\\[str\\]\\] \\= None_, _response\\_strs: Optional\\[List\\[str\\]\\] \\= None_, _contexts\\_list: Optional\\[List\\[List\\[str\\]\\]\\] \\= None_, _\\*\\*eval\\_kwargs\\_lists: List_) \u2192 Dict\\[str, List\\[[EvaluationResult](#llama_index.evaluation.EvaluationResult \"llama_index.evaluation.base.EvaluationResult\")\\]\\][\uf0c1](#llama_index.evaluation.BatchEvalRunner.evaluate_response_strs \"Permalink to this definition\")\n\nEvaluate query, response pairs.\n\nSync version of aevaluate\\_response\\_strs.\n\nevaluate\\_responses(_queries: Optional\\[List\\[str\\]\\] \\= None_, _responses: Optional\\[List\\[[Response](https://docs.llamaindex.ai/en/stable/api_reference/response.html#llama_index.response.schema.Response \"llama_index.response.schema.Response\")\\]\\] \\= None_, _\\*\\*eval\\_kwargs\\_lists: Dict\\[str, Any\\]_) \u2192 Dict\\[str, List\\[[EvaluationResult](#llama_index.evaluation.EvaluationResult \"llama_index.evaluation.base.EvaluationResult\")\\]\\][\uf0c1](#llama_index.evaluation.BatchEvalRunner.evaluate_responses \"Permalink to this definition\")\n\nEvaluate query, response objs.\n\nSync version of aevaluate\\_responses.\n\n_class_ llama\\_index.evaluation.CorrectnessEvaluator(_service\\_context: Optional\\[[ServiceContext](https://docs.llamaindex.ai/en/stable/api_reference/service_context.html#llama_index.indices.service_context.ServiceContext \"llama_index.indices.service_context.ServiceContext\")\\] \\= None_, _eval\\_template: Optional\\[Union\\[[BasePromptTemplate](https://docs.llamaindex.ai/en/stable/api_reference/prompts.html#llama_index.prompts.base.BasePromptTemplate \"llama_index.prompts.base.BasePromptTemplate\"), str\\]\\] \\= None_, _score\\_threshold: float \\= 4.0_)[\uf0c1](#llama_index.evaluation.CorrectnessEvaluator \"Permalink to this definition\")\n\nCorrectness evaluator.\n\nEvaluates the correctness of a question answering system. This evaluator depends on reference answer to be provided, in addition to the query string and response string.\n\nIt outputs a score between 1 and 5, where 1 is the worst and 5 is the best, along with a reasoning for the score. Passing is defined as a score greater than or equal to the given threshold.\n\nParameters\n\n*   **service\\_context** (_Optional__\\[_[_ServiceContext_](https://docs.llamaindex.ai/en/stable/api_reference/service_context.html#llama_index.indices.service_context.ServiceContext \"llama_index.indices.service_context.ServiceContext\")_\\]_) \u2013 Service context.\n    \n*   **eval\\_template** (_Optional__\\[__Union__\\[_[_BasePromptTemplate_](https://docs.llamaindex.ai/en/stable/api_reference/prompts.html#llama_index.prompts.base.BasePromptTemplate \"llama_index.prompts.base.BasePromptTemplate\")_,_ _str__\\]__\\]_) \u2013 Template for the evaluation prompt.\n    \n*   **score\\_threshold** (_float_) \u2013 Numerical threshold for passing the evaluation, defaults to 4.0.\n    \n\n_async_ aevaluate(_query: Optional\\[str\\] \\= None_, _response: Optional\\[str\\] \\= None_, _contexts: Optional\\[Sequence\\[str\\]\\] \\= None_, _reference: Optional\\[str\\] \\= None_, _\\*\\*kwargs: Any_) \u2192 [EvaluationResult](#llama_index.evaluation.EvaluationResult \"llama_index.evaluation.base.EvaluationResult\")[\uf0c1](#llama_index.evaluation.CorrectnessEvaluator.aevaluate \"Permalink to this definition\")\n\nRun evaluation with query string, retrieved contexts, and generated response string.\n\nSubclasses can override this method to provide custom evaluation logic and take in additional arguments.\n\n_async_ aevaluate\\_response(_query: Optional\\[str\\] \\= None_, _response: Optional\\[[Response](https://docs.llamaindex.ai/en/stable/api_reference/response.html#llama_index.response.schema.Response \"llama_index.response.schema.Response\")\\] \\= None_, _\\*\\*kwargs: Any_) \u2192 [EvaluationResult](#llama_index.evaluation.EvaluationResult \"llama_index.evaluation.base.EvaluationResult\")[\uf0c1](#llama_index.evaluation.CorrectnessEvaluator.aevaluate_response \"Permalink to this definition\")\n\nRun evaluation with query string and generated Response object.\n\nSubclasses can override this method to provide custom evaluation logic and take in additional arguments.\n\nevaluate(_query: Optional\\[str\\] \\= None_, _response: Optional\\[str\\] \\= None_, _contexts: Optional\\[Sequence\\[str\\]\\] \\= None_, _\\*\\*kwargs: Any_) \u2192 [EvaluationResult](#llama_index.evaluation.EvaluationResult \"llama_index.evaluation.base.EvaluationResult\")[\uf0c1](#llama_index.evaluation.CorrectnessEvaluator.evaluate \"Permalink to this definition\")\n\nRun evaluation with query string, retrieved contexts, and generated response string.\n\nSubclasses can override this method to provide custom evaluation logic and take in additional arguments.\n\nevaluate\\_response(_query: Optional\\[str\\] \\= None_, _response: Optional\\[[Response](https://docs.llamaindex.ai/en/stable/api_reference/response.html#llama_index.response.schema.Response \"llama_index.response.schema.Response\")\\] \\= None_, _\\*\\*kwargs: Any_) \u2192 [EvaluationResult](#llama_index.evaluation.EvaluationResult \"llama_index.evaluation.base.EvaluationResult\")[\uf0c1](#llama_index.evaluation.CorrectnessEvaluator.evaluate_response \"Permalink to this definition\")\n\nRun evaluation with query string and generated Response object.\n\nSubclasses can override this method to provide custom evaluation logic and take in additional arguments.\n\n_class_ llama\\_index.evaluation.DatasetGenerator(_nodes: List\\[[BaseNode](https://docs.llamaindex.ai/en/stable/api_reference/node.html#llama_index.schema.BaseNode \"llama_index.schema.BaseNode\")\\]_, _service\\_context: [llama\\_index.indices.service\\_context.ServiceContext](https://docs.llamaindex.ai/en/stable/api_reference/service_context.html#llama_index.indices.service_context.ServiceContext \"llama_index.indices.service_context.ServiceContext\") | None \\= None_, _num\\_questions\\_per\\_chunk: int \\= 10_, _text\\_question\\_template: [llama\\_index.prompts.base.BasePromptTemplate](https://docs.llamaindex.ai/en/stable/api_reference/prompts.html#llama_index.prompts.base.BasePromptTemplate \"llama_index.prompts.base.BasePromptTemplate\") | None \\= None_, _text\\_qa\\_template: [llama\\_index.prompts.base.BasePromptTemplate](https://docs.llamaindex.ai/en/stable/api_reference/prompts.html#llama_index.prompts.base.BasePromptTemplate \"llama_index.prompts.base.BasePromptTemplate\") | None \\= None_, _question\\_gen\\_query: str | None \\= None_, _metadata\\_mode: [MetadataMode](https://docs.llamaindex.ai/en/stable/api_reference/node.html#llama_index.schema.MetadataMode \"llama_index.schema.MetadataMode\") \\= MetadataMode.NONE_, _show\\_progress: bool \\= False_)[\uf0c1](#llama_index.evaluation.DatasetGenerator \"Permalink to this definition\")\n\nGenerate dataset (question/ question-answer pairs) based on the given documents.\n\nNOTE: this is a beta feature, subject to change!\n\nParameters\n\n*   **nodes** (_List__\\[__Node__\\]_) \u2013 List of nodes. (Optional)\n    \n*   **service\\_context** ([_ServiceContext_](https://docs.llamaindex.ai/en/stable/api_reference/service_context.html#llama_index.indices.service_context.ServiceContext \"llama_index.indices.service_context.ServiceContext\")) \u2013 Service Context.\n    \n*   **num\\_questions\\_per\\_chunk** \u2013 number of question to be generated per chunk. Each document is chunked of size 512 words.\n    \n*   **text\\_question\\_template** \u2013 Question generation template.\n    \n*   **question\\_gen\\_query** \u2013 Question generation query.\n    \n\n_async_ agenerate\\_dataset\\_from\\_nodes(_num: int | None \\= None_) \u2192 [QueryResponseDataset](#llama_index.evaluation.QueryResponseDataset \"llama_index.evaluation.dataset_generation.QueryResponseDataset\")[\uf0c1](#llama_index.evaluation.DatasetGenerator.agenerate_dataset_from_nodes \"Permalink to this definition\")\n\nGenerates questions for each document.\n\n_async_ agenerate\\_questions\\_from\\_nodes(_num: int | None \\= None_) \u2192 List\\[str\\][\uf0c1](#llama_index.evaluation.DatasetGenerator.agenerate_questions_from_nodes \"Permalink to this definition\")\n\nGenerates questions for each document.\n\n_classmethod_ from\\_documents(_documents: List\\[[Document](https://docs.llamaindex.ai/en/stable/api_reference/node.html#llama_index.schema.Document \"llama_index.schema.Document\")\\]_, _service\\_context: [llama\\_index.indices.service\\_context.ServiceContext](https://docs.llamaindex.ai/en/stable/api_reference/service_context.html#llama_index.indices.service_context.ServiceContext \"llama_index.indices.service_context.ServiceContext\") | None \\= None_, _num\\_questions\\_per\\_chunk: int \\= 10_, _text\\_question\\_template: [llama\\_index.prompts.base.BasePromptTemplate](https://docs.llamaindex.ai/en/stable/api_reference/prompts.html#llama_index.prompts.base.BasePromptTemplate \"llama_index.prompts.base.BasePromptTemplate\") | None \\= None_, _text\\_qa\\_template: [llama\\_index.prompts.base.BasePromptTemplate](https://docs.llamaindex.ai/en/stable/api_reference/prompts.html#llama_index.prompts.base.BasePromptTemplate \"llama_index.prompts.base.BasePromptTemplate\") | None \\= None_, _question\\_gen\\_query: str | None \\= None_, _required\\_keywords: Optional\\[List\\[str\\]\\] \\= None_, _exclude\\_keywords: Optional\\[List\\[str\\]\\] \\= None_, _show\\_progress: bool \\= False_) \u2192 [DatasetGenerator](#llama_index.evaluation.DatasetGenerator \"llama_index.evaluation.dataset_generation.DatasetGenerator\")[\uf0c1](#llama_index.evaluation.DatasetGenerator.from_documents \"Permalink to this definition\")\n\nGenerate dataset from documents.\n\ngenerate\\_dataset\\_from\\_nodes(_num: int | None \\= None_) \u2192 [QueryResponseDataset](#llama_index.evaluation.QueryResponseDataset \"llama_index.evaluation.dataset_generation.QueryResponseDataset\")[\uf0c1](#llama_index.evaluation.DatasetGenerator.generate_dataset_from_nodes \"Permalink to this definition\")\n\nGenerates questions for each document.\n\ngenerate\\_questions\\_from\\_nodes(_num: int | None \\= None_) \u2192 List\\[str\\][\uf0c1](#llama_index.evaluation.DatasetGenerator.generate_questions_from_nodes \"Permalink to this definition\")\n\nGenerates questions for each document.\n\n_pydantic model_ llama\\_index.evaluation.EmbeddingQAFinetuneDataset[\uf0c1](#llama_index.evaluation.EmbeddingQAFinetuneDataset \"Permalink to this definition\")\n\nEmbedding QA Finetuning Dataset.\n\nParameters\n\n*   **queries** (_Dict__\\[__str__,_ _str__\\]_) \u2013 Dict id -> query.\n    \n*   **corpus** (_Dict__\\[__str__,_ _str__\\]_) \u2013 Dict id -> string.\n    \n*   **relevant\\_docs** (_Dict__\\[__str__,_ _List__\\[__str__\\]__\\]_) \u2013 Dict query id -> list of doc ids.\n    \n\nShow JSON schema\n\n{\n   \"title\": \"EmbeddingQAFinetuneDataset\",\n   \"description\": \"Embedding QA Finetuning Dataset.\\\\n\\\\nArgs:\\\\n    queries (Dict\\[str, str\\]): Dict id -> query.\\\\n    corpus (Dict\\[str, str\\]): Dict id -> string.\\\\n    relevant\\_docs (Dict\\[str, List\\[str\\]\\]): Dict query id -> list of doc ids.\",\n   \"type\": \"object\",\n   \"properties\": {\n      \"queries\": {\n         \"title\": \"Queries\",\n         \"type\": \"object\",\n         \"additionalProperties\": {\n            \"type\": \"string\"\n         }\n      },\n      \"corpus\": {\n         \"title\": \"Corpus\",\n         \"type\": \"object\",\n         \"additionalProperties\": {\n            \"type\": \"string\"\n         }\n      },\n      \"relevant\\_docs\": {\n         \"title\": \"Relevant Docs\",\n         \"type\": \"object\",\n         \"additionalProperties\": {\n            \"type\": \"array\",\n            \"items\": {\n               \"type\": \"string\"\n            }\n         }\n      }\n   },\n   \"required\": \\[\n      \"queries\",\n      \"corpus\",\n      \"relevant\\_docs\"\n   \\]\n}\n\nFields\n\n*   `corpus (Dict[str, str])`\n    \n*   `queries (Dict[str, str])`\n    \n*   `relevant_docs (Dict[str, List[str]])`\n    \n\n_field_ corpus_: Dict\\[str, str\\]_ _\\[Required\\]_[\uf0c1](#llama_index.evaluation.EmbeddingQAFinetuneDataset.corpus \"Permalink to this definition\")\n\n_field_ queries_: Dict\\[str, str\\]_ _\\[Required\\]_[\uf0c1](#llama_index.evaluation.EmbeddingQAFinetuneDataset.queries \"Permalink to this definition\")\n\n_field_ relevant\\_docs_: Dict\\[str, List\\[str\\]\\]_ _\\[Required\\]_[\uf0c1](#llama_index.evaluation.EmbeddingQAFinetuneDataset.relevant_docs \"Permalink to this definition\")\n\n_classmethod_ construct(_\\_fields\\_set: Optional\\[SetStr\\] \\= None_, _\\*\\*values: Any_) \u2192 Model[\uf0c1](#llama_index.evaluation.EmbeddingQAFinetuneDataset.construct \"Permalink to this definition\")\n\nCreates a new model setting \\_\\_dict\\_\\_ and \\_\\_fields\\_set\\_\\_ from trusted or pre-validated data. Default values are respected, but no other validation is performed. Behaves as if Config.extra = \u2018allow\u2019 was set since it adds all passed values\n\ncopy(_\\*_, _include: Optional\\[Union\\[AbstractSetIntStr, MappingIntStrAny\\]\\] \\= None_, _exclude: Optional\\[Union\\[AbstractSetIntStr, MappingIntStrAny\\]\\] \\= None_, _update: Optional\\[DictStrAny\\] \\= None_, _deep: bool \\= False_) \u2192 Model[\uf0c1](#llama_index.evaluation.EmbeddingQAFinetuneDataset.copy \"Permalink to this definition\")\n\nDuplicate a model, optionally choose which fields to include, exclude and change.\n\nParameters\n\n*   **include** \u2013 fields to include in new model\n    \n*   **exclude** \u2013 fields to exclude from new model, as with values this takes precedence over include\n    \n*   **update** \u2013 values to change/add in the new model. Note: the data is not validated before creating the new model: you should trust this data\n    \n*   **deep** \u2013 set to True to make a deep copy of the model\n    \n\nReturns\n\nnew model instance\n\ndict(_\\*_, _include: Optional\\[Union\\[AbstractSetIntStr, MappingIntStrAny\\]\\] \\= None_, _exclude: Optional\\[Union\\[AbstractSetIntStr, MappingIntStrAny\\]\\] \\= None_, _by\\_alias: bool \\= False_, _skip\\_defaults: Optional\\[bool\\] \\= None_, _exclude\\_unset: bool \\= False_, _exclude\\_defaults: bool \\= False_, _exclude\\_none: bool \\= False_) \u2192 DictStrAny[\uf0c1](#llama_index.evaluation.EmbeddingQAFinetuneDataset.dict \"Permalink to this definition\")\n\nGenerate a dictionary representation of the model, optionally specifying which fields to include or exclude.\n\n_classmethod_ from\\_json(_path: str_) \u2192 [EmbeddingQAFinetuneDataset](https://docs.llamaindex.ai/en/stable/api_reference/finetuning.html#llama_index.finetuning.EmbeddingQAFinetuneDataset \"llama_index.finetuning.embeddings.common.EmbeddingQAFinetuneDataset\")[\uf0c1](#llama_index.evaluation.EmbeddingQAFinetuneDataset.from_json \"Permalink to this definition\")\n\nLoad json.\n\n_classmethod_ from\\_orm(_obj: Any_) \u2192 Model[\uf0c1](#llama_index.evaluation.EmbeddingQAFinetuneDataset.from_orm \"Permalink to this definition\")\n\njson(_\\*_, _include: Optional\\[Union\\[AbstractSetIntStr, MappingIntStrAny\\]\\] \\= None_, _exclude: Optional\\[Union\\[AbstractSetIntStr, MappingIntStrAny\\]\\] \\= None_, _by\\_alias: bool \\= False_, _skip\\_defaults: Optional\\[bool\\] \\= None_, _exclude\\_unset: bool \\= False_, _exclude\\_defaults: bool \\= False_, _exclude\\_none: bool \\= False_, _encoder: Optional\\[Callable\\[\\[Any\\], Any\\]\\] \\= None_, _models\\_as\\_dict: bool \\= True_, _\\*\\*dumps\\_kwargs: Any_) \u2192 unicode[\uf0c1](#llama_index.evaluation.EmbeddingQAFinetuneDataset.json \"Permalink to this definition\")\n\nGenerate a JSON representation of the model, include and exclude arguments as per dict().\n\nencoder is an optional function to supply as default to json.dumps(), other arguments as per json.dumps().\n\n_classmethod_ parse\\_file(_path: Union\\[str, Path\\]_, _\\*_, _content\\_type: unicode \\= None_, _encoding: unicode \\= 'utf8'_, _proto: Protocol \\= None_, _allow\\_pickle: bool \\= False_) \u2192 Model[\uf0c1](#llama_index.evaluation.EmbeddingQAFinetuneDataset.parse_file \"Permalink to this definition\")\n\n_classmethod_ parse\\_obj(_obj: Any_) \u2192 Model[\uf0c1](#llama_index.evaluation.EmbeddingQAFinetuneDataset.parse_obj \"Permalink to this definition\")\n\n_classmethod_ parse\\_raw(_b: Union\\[str, bytes\\]_, _\\*_, _content\\_type: unicode \\= None_, _encoding: unicode \\= 'utf8'_, _proto: Protocol \\= None_, _allow\\_pickle: bool \\= False_) \u2192 Model[\uf0c1](#llama_index.evaluation.EmbeddingQAFinetuneDataset.parse_raw \"Permalink to this definition\")\n\nsave\\_json(_path: str_) \u2192 None[\uf0c1](#llama_index.evaluation.EmbeddingQAFinetuneDataset.save_json \"Permalink to this definition\")\n\nSave json.\n\n_classmethod_ schema(_by\\_alias: bool \\= True_, _ref\\_template: unicode \\= '#/definitions/{model}'_) \u2192 DictStrAny[\uf0c1](#llama_index.evaluation.EmbeddingQAFinetuneDataset.schema \"Permalink to this definition\")\n\n_classmethod_ schema\\_json(_\\*_, _by\\_alias: bool \\= True_, _ref\\_template: unicode \\= '#/definitions/{model}'_, _\\*\\*dumps\\_kwargs: Any_) \u2192 unicode[\uf0c1](#llama_index.evaluation.EmbeddingQAFinetuneDataset.schema_json \"Permalink to this definition\")\n\n_classmethod_ update\\_forward\\_refs(_\\*\\*localns: Any_) \u2192 None[\uf0c1](#llama_index.evaluation.EmbeddingQAFinetuneDataset.update_forward_refs \"Permalink to this definition\")\n\nTry to update ForwardRefs on fields based on this Model, globalns and localns.\n\n_classmethod_ validate(_value: Any_) \u2192 Model[\uf0c1](#llama_index.evaluation.EmbeddingQAFinetuneDataset.validate \"Permalink to this definition\")\n\n_property_ query\\_docid\\_pairs_: List\\[Tuple\\[str, List\\[str\\]\\]\\]_[\uf0c1](#llama_index.evaluation.EmbeddingQAFinetuneDataset.query_docid_pairs \"Permalink to this definition\")\n\nGet query, relevant doc ids.\n\n_pydantic model_ llama\\_index.evaluation.EvaluationResult[\uf0c1](#llama_index.evaluation.EvaluationResult \"Permalink to this definition\")\n\nEvaluation result.\n\nOutput of an BaseEvaluator.\n\nShow JSON schema\n\n{\n   \"title\": \"EvaluationResult\",\n   \"description\": \"Evaluation result.\\\\n\\\\nOutput of an BaseEvaluator.\",\n   \"type\": \"object\",\n   \"properties\": {\n      \"query\": {\n         \"title\": \"Query\",\n         \"description\": \"Query string\",\n         \"type\": \"string\"\n      },\n      \"contexts\": {\n         \"title\": \"Contexts\",\n         \"description\": \"Context strings\",\n         \"type\": \"array\",\n         \"items\": {\n            \"type\": \"string\"\n         }\n      },\n      \"response\": {\n         \"title\": \"Response\",\n         \"description\": \"Response string\",\n         \"type\": \"string\"\n      },\n      \"passing\": {\n         \"title\": \"Passing\",\n         \"description\": \"Binary evaluation result (passing or not)\",\n         \"type\": \"boolean\"\n      },\n      \"feedback\": {\n         \"title\": \"Feedback\",\n         \"description\": \"Feedback or reasoning for the response\",\n         \"type\": \"string\"\n      },\n      \"score\": {\n         \"title\": \"Score\",\n         \"description\": \"Score for the response\",\n         \"type\": \"number\"\n      }\n   }\n}\n\nFields\n\n*   `contexts (Optional[Sequence[str]])`\n    \n*   `feedback (Optional[str])`\n    \n*   `passing (Optional[bool])`\n    \n*   `query (Optional[str])`\n    \n*   `response (Optional[str])`\n    \n*   `score (Optional[float])`\n    \n\n_field_ contexts_: Optional\\[Sequence\\[str\\]\\]_ _\\= None_[\uf0c1](#llama_index.evaluation.EvaluationResult.contexts \"Permalink to this definition\")\n\nContext strings\n\n_field_ feedback_: Optional\\[str\\]_ _\\= None_[\uf0c1](#llama_index.evaluation.EvaluationResult.feedback \"Permalink to this definition\")\n\nFeedback or reasoning for the response\n\n_field_ passing_: Optional\\[bool\\]_ _\\= None_[\uf0c1](#llama_index.evaluation.EvaluationResult.passing \"Permalink to this definition\")\n\nBinary evaluation result (passing or not)\n\n_field_ query_: Optional\\[str\\]_ _\\= None_[\uf0c1](#llama_index.evaluation.EvaluationResult.query \"Permalink to this definition\")\n\nQuery string\n\n_field_ response_: Optional\\[str\\]_ _\\= None_[\uf0c1](#llama_index.evaluation.EvaluationResult.response \"Permalink to this definition\")\n\nResponse string\n\n_field_ score_: Optional\\[float\\]_ _\\= None_[\uf0c1](#llama_index.evaluation.EvaluationResult.score \"Permalink to this definition\")\n\nScore for the response\n\n_classmethod_ construct(_\\_fields\\_set: Optional\\[SetStr\\] \\= None_, _\\*\\*values: Any_) \u2192 Model[\uf0c1](#llama_index.evaluation.EvaluationResult.construct \"Permalink to this definition\")\n\nCreates a new model setting \\_\\_dict\\_\\_ and \\_\\_fields\\_set\\_\\_ from trusted or pre-validated data. Default values are respected, but no other validation is performed. Behaves as if Config.extra = \u2018allow\u2019 was set since it adds all passed values\n\ncopy(_\\*_, _include: Optional\\[Union\\[AbstractSetIntStr, MappingIntStrAny\\]\\] \\= None_, _exclude: Optional\\[Union\\[AbstractSetIntStr, MappingIntStrAny\\]\\] \\= None_, _update: Optional\\[DictStrAny\\] \\= None_, _deep: bool \\= False_) \u2192 Model[\uf0c1](#llama_index.evaluation.EvaluationResult.copy \"Permalink to this definition\")\n\nDuplicate a model, optionally choose which fields to include, exclude and change.\n\nParameters\n\n*   **include** \u2013 fields to include in new model\n    \n*   **exclude** \u2013 fields to exclude from new model, as with values this takes precedence over include\n    \n*   **update** \u2013 values to change/add in the new model. Note: the data is not validated before creating the new model: you should trust this data\n    \n*   **deep** \u2013 set to True to make a deep copy of the model\n    \n\nReturns\n\nnew model instance\n\ndict(_\\*_, _include: Optional\\[Union\\[AbstractSetIntStr, MappingIntStrAny\\]\\] \\= None_, _exclude: Optional\\[Union\\[AbstractSetIntStr, MappingIntStrAny\\]\\] \\= None_, _by\\_alias: bool \\= False_, _skip\\_defaults: Optional\\[bool\\] \\= None_, _exclude\\_unset: bool \\= False_, _exclude\\_defaults: bool \\= False_, _exclude\\_none: bool \\= False_) \u2192 DictStrAny[\uf0c1](#llama_index.evaluation.EvaluationResult.dict \"Permalink to this definition\")\n\nGenerate a dictionary representation of the model, optionally specifying which fields to include or exclude.\n\n_classmethod_ from\\_orm(_obj: Any_) \u2192 Model[\uf0c1](#llama_index.evaluation.EvaluationResult.from_orm \"Permalink to this definition\")\n\njson(_\\*_, _include: Optional\\[Union\\[AbstractSetIntStr, MappingIntStrAny\\]\\] \\= None_, _exclude: Optional\\[Union\\[AbstractSetIntStr, MappingIntStrAny\\]\\] \\= None_, _by\\_alias: bool \\= False_, _skip\\_defaults: Optional\\[bool\\] \\= None_, _exclude\\_unset: bool \\= False_, _exclude\\_defaults: bool \\= False_, _exclude\\_none: bool \\= False_, _encoder: Optional\\[Callable\\[\\[Any\\], Any\\]\\] \\= None_, _models\\_as\\_dict: bool \\= True_, _\\*\\*dumps\\_kwargs: Any_) \u2192 unicode[\uf0c1](#llama_index.evaluation.EvaluationResult.json \"Permalink to this definition\")\n\nGenerate a JSON representation of the model, include and exclude arguments as per dict().\n\nencoder is an optional function to supply as default to json.dumps(), other arguments as per json.dumps().\n\n_classmethod_ parse\\_file(_path: Union\\[str, Path\\]_, _\\*_, _content\\_type: unicode \\= None_, _encoding: unicode \\= 'utf8'_, _proto: Protocol \\= None_, _allow\\_pickle: bool \\= False_) \u2192 Model[\uf0c1](#llama_index.evaluation.EvaluationResult.parse_file \"Permalink to this definition\")\n\n_classmethod_ parse\\_obj(_obj: Any_) \u2192 Model[\uf0c1](#llama_index.evaluation.EvaluationResult.parse_obj \"Permalink to this definition\")\n\n_classmethod_ parse\\_raw(_b: Union\\[str, bytes\\]_, _\\*_, _content\\_type: unicode \\= None_, _encoding: unicode \\= 'utf8'_, _proto: Protocol \\= None_, _allow\\_pickle: bool \\= False_) \u2192 Model[\uf0c1](#llama_index.evaluation.EvaluationResult.parse_raw \"Permalink to this definition\")\n\n_classmethod_ schema(_by\\_alias: bool \\= True_, _ref\\_template: unicode \\= '#/definitions/{model}'_) \u2192 DictStrAny[\uf0c1](#llama_index.evaluation.EvaluationResult.schema \"Permalink to this definition\")\n\n_classmethod_ schema\\_json(_\\*_, _by\\_alias: bool \\= True_, _ref\\_template: unicode \\= '#/definitions/{model}'_, _\\*\\*dumps\\_kwargs: Any_) \u2192 unicode[\uf0c1](#llama_index.evaluation.EvaluationResult.schema_json \"Permalink to this definition\")\n\n_classmethod_ update\\_forward\\_refs(_\\*\\*localns: Any_) \u2192 None[\uf0c1](#llama_index.evaluation.EvaluationResult.update_forward_refs \"Permalink to this definition\")\n\nTry to update ForwardRefs on fields based on this Model, globalns and localns.\n\n_classmethod_ validate(_value: Any_) \u2192 Model[\uf0c1](#llama_index.evaluation.EvaluationResult.validate \"Permalink to this definition\")\n\n_class_ llama\\_index.evaluation.FaithfulnessEvaluator(_service\\_context: [llama\\_index.indices.service\\_context.ServiceContext](https://docs.llamaindex.ai/en/stable/api_reference/service_context.html#llama_index.indices.service_context.ServiceContext \"llama_index.indices.service_context.ServiceContext\") | None \\= None_, _raise\\_error: bool \\= False_, _eval\\_template: str | [llama\\_index.prompts.base.BasePromptTemplate](https://docs.llamaindex.ai/en/stable/api_reference/prompts.html#llama_index.prompts.base.BasePromptTemplate \"llama_index.prompts.base.BasePromptTemplate\") | None \\= None_, _refine\\_template: str | [llama\\_index.prompts.base.BasePromptTemplate](https://docs.llamaindex.ai/en/stable/api_reference/prompts.html#llama_index.prompts.base.BasePromptTemplate \"llama_index.prompts.base.BasePromptTemplate\") | None \\= None_)[\uf0c1](#llama_index.evaluation.FaithfulnessEvaluator \"Permalink to this definition\")\n\nFaithfulness evaluator.\n\nEvaluates whether a response is faithful to the contexts (i.e. whether the response is supported by the contexts or hallucinated.)\n\nThis evaluator only considers the response string and the list of context strings.\n\nParameters\n\n*   **service\\_context** (_Optional__\\[_[_ServiceContext_](https://docs.llamaindex.ai/en/stable/api_reference/service_context.html#llama_index.indices.service_context.ServiceContext \"llama_index.indices.service_context.ServiceContext\")_\\]_) \u2013 The service context to use for evaluation.\n    \n*   **raise\\_error** (_bool_) \u2013 Whether to raise an error when the response is invalid. Defaults to False.\n    \n*   **eval\\_template** (_Optional__\\[__Union__\\[__str__,_ [_BasePromptTemplate_](https://docs.llamaindex.ai/en/stable/api_reference/prompts.html#llama_index.prompts.base.BasePromptTemplate \"llama_index.prompts.base.BasePromptTemplate\")_\\]__\\]_) \u2013 The template to use for evaluation.\n    \n*   **refine\\_template** (_Optional__\\[__Union__\\[__str__,_ [_BasePromptTemplate_](https://docs.llamaindex.ai/en/stable/api_reference/prompts.html#llama_index.prompts.base.BasePromptTemplate \"llama_index.prompts.base.BasePromptTemplate\")_\\]__\\]_) \u2013 The template to use for refining the evaluation.\n    \n\n_async_ aevaluate(_query: str | None \\= None_, _response: str | None \\= None_, _contexts: Optional\\[Sequence\\[str\\]\\] \\= None_, _\\*\\*kwargs: Any_) \u2192 [EvaluationResult](#llama_index.evaluation.EvaluationResult \"llama_index.evaluation.base.EvaluationResult\")[\uf0c1](#llama_index.evaluation.FaithfulnessEvaluator.aevaluate \"Permalink to this definition\")\n\nEvaluate whether the response is faithful to the contexts.\n\n_async_ aevaluate\\_response(_query: Optional\\[str\\] \\= None_, _response: Optional\\[[Response](https://docs.llamaindex.ai/en/stable/api_reference/response.html#llama_index.response.schema.Response \"llama_index.response.schema.Response\")\\] \\= None_, _\\*\\*kwargs: Any_) \u2192 [EvaluationResult](#llama_index.evaluation.EvaluationResult \"llama_index.evaluation.base.EvaluationResult\")[\uf0c1](#llama_index.evaluation.FaithfulnessEvaluator.aevaluate_response \"Permalink to this definition\")\n\nRun evaluation with query string and generated Response object.\n\nSubclasses can override this method to provide custom evaluation logic and take in additional arguments.\n\nevaluate(_query: Optional\\[str\\] \\= None_, _response: Optional\\[str\\] \\= None_, _contexts: Optional\\[Sequence\\[str\\]\\] \\= None_, _\\*\\*kwargs: Any_) \u2192 [EvaluationResult](#llama_index.evaluation.EvaluationResult \"llama_index.evaluation.base.EvaluationResult\")[\uf0c1](#llama_index.evaluation.FaithfulnessEvaluator.evaluate \"Permalink to this definition\")\n\nRun evaluation with query string, retrieved contexts, and generated response string.\n\nSubclasses can override this method to provide custom evaluation logic and take in additional arguments.\n\nevaluate\\_response(_query: Optional\\[str\\] \\= None_, _response: Optional\\[[Response](https://docs.llamaindex.ai/en/stable/api_reference/response.html#llama_index.response.schema.Response \"llama_index.response.schema.Response\")\\] \\= None_, _\\*\\*kwargs: Any_) \u2192 [EvaluationResult](#llama_index.evaluation.EvaluationResult \"llama_index.evaluation.base.EvaluationResult\")[\uf0c1](#llama_index.evaluation.FaithfulnessEvaluator.evaluate_response \"Permalink to this definition\")\n\nRun evaluation with query string and generated Response object.\n\nSubclasses can override this method to provide custom evaluation logic and take in additional arguments.\n\n_class_ llama\\_index.evaluation.GuidelineEvaluator(_service\\_context: Optional\\[[ServiceContext](https://docs.llamaindex.ai/en/stable/api_reference/service_context.html#llama_index.indices.service_context.ServiceContext \"llama_index.indices.service_context.ServiceContext\")\\] \\= None_, _guidelines: Optional\\[str\\] \\= None_, _eval\\_template: Optional\\[Union\\[[BasePromptTemplate](https://docs.llamaindex.ai/en/stable/api_reference/prompts.html#llama_index.prompts.base.BasePromptTemplate \"llama_index.prompts.base.BasePromptTemplate\"), str\\]\\] \\= None_)[\uf0c1](#llama_index.evaluation.GuidelineEvaluator \"Permalink to this definition\")\n\nGuideline evaluator.\n\nEvaluates whether a query and response pair passes the given guidelines.\n\nThis evaluator only considers the query string and the response string.\n\nParameters\n\n*   **service\\_context** (_Optional__\\[_[_ServiceContext_](https://docs.llamaindex.ai/en/stable/api_reference/service_context.html#llama_index.indices.service_context.ServiceContext \"llama_index.indices.service_context.ServiceContext\")_\\]_) \u2013 The service context to use for evaluation.\n    \n*   **guidelines** (_Optional__\\[__str__\\]_) \u2013 User-added guidelines to use for evaluation. Defaults to None, which uses the default guidelines.\n    \n*   **eval\\_template** (_Optional__\\[__Union__\\[__str__,_ [_BasePromptTemplate_](https://docs.llamaindex.ai/en/stable/api_reference/prompts.html#llama_index.prompts.base.BasePromptTemplate \"llama_index.prompts.base.BasePromptTemplate\")_\\]__\\]_) \u2013 The template to use for evaluation.\n    \n\n_async_ aevaluate(_query: Optional\\[str\\] \\= None_, _response: Optional\\[str\\] \\= None_, _contexts: Optional\\[Sequence\\[str\\]\\] \\= None_, _\\*\\*kwargs: Any_) \u2192 [EvaluationResult](#llama_index.evaluation.EvaluationResult \"llama_index.evaluation.base.EvaluationResult\")[\uf0c1](#llama_index.evaluation.GuidelineEvaluator.aevaluate \"Permalink to this definition\")\n\nEvaluate whether the query and response pair passes the guidelines.\n\n_async_ aevaluate\\_response(_query: Optional\\[str\\] \\= None_, _response: Optional\\[[Response](https://docs.llamaindex.ai/en/stable/api_reference/response.html#llama_index.response.schema.Response \"llama_index.response.schema.Response\")\\] \\= None_, _\\*\\*kwargs: Any_) \u2192 [EvaluationResult](#llama_index.evaluation.EvaluationResult \"llama_index.evaluation.base.EvaluationResult\")[\uf0c1](#llama_index.evaluation.GuidelineEvaluator.aevaluate_response \"Permalink to this definition\")\n\nRun evaluation with query string and generated Response object.\n\nSubclasses can override this method to provide custom evaluation logic and take in additional arguments.\n\nevaluate(_query: Optional\\[str\\] \\= None_, _response: Optional\\[str\\] \\= None_, _contexts: Optional\\[Sequence\\[str\\]\\] \\= None_, _\\*\\*kwargs: Any_) \u2192 [EvaluationResult](#llama_index.evaluation.EvaluationResult \"llama_index.evaluation.base.EvaluationResult\")[\uf0c1](#llama_index.evaluation.GuidelineEvaluator.evaluate \"Permalink to this definition\")\n\nRun evaluation with query string, retrieved contexts, and generated response string.\n\nSubclasses can override this method to provide custom evaluation logic and take in additional arguments.\n\nevaluate\\_response(_query: Optional\\[str\\] \\= None_, _response: Optional\\[[Response](https://docs.llamaindex.ai/en/stable/api_reference/response.html#llama_index.response.schema.Response \"llama_index.response.schema.Response\")\\] \\= None_, _\\*\\*kwargs: Any_) \u2192 [EvaluationResult](#llama_index.evaluation.EvaluationResult \"llama_index.evaluation.base.EvaluationResult\")[\uf0c1](#llama_index.evaluation.GuidelineEvaluator.evaluate_response \"Permalink to this definition\")\n\nRun evaluation with query string and generated Response object.\n\nSubclasses can override this method to provide custom evaluation logic and take in additional arguments.\n\n_class_ llama\\_index.evaluation.HitRate[\uf0c1](#llama_index.evaluation.HitRate \"Permalink to this definition\")\n\nHit rate metric.\n\ncompute(_query: Optional\\[str\\] \\= None_, _expected\\_ids: Optional\\[List\\[str\\]\\] \\= None_, _retrieved\\_ids: Optional\\[List\\[str\\]\\] \\= None_, _\\*\\*kwargs: Any_) \u2192 [RetrievalMetricResult](#llama_index.evaluation.RetrievalMetricResult \"llama_index.evaluation.retrieval.metrics_base.RetrievalMetricResult\")[\uf0c1](#llama_index.evaluation.HitRate.compute \"Permalink to this definition\")\n\nCompute metric.\n\n_class_ llama\\_index.evaluation.MRR[\uf0c1](#llama_index.evaluation.MRR \"Permalink to this definition\")\n\nMRR metric.\n\ncompute(_query: Optional\\[str\\] \\= None_, _expected\\_ids: Optional\\[List\\[str\\]\\] \\= None_, _retrieved\\_ids: Optional\\[List\\[str\\]\\] \\= None_, _\\*\\*kwargs: Any_) \u2192 [RetrievalMetricResult](#llama_index.evaluation.RetrievalMetricResult \"llama_index.evaluation.retrieval.metrics_base.RetrievalMetricResult\")[\uf0c1](#llama_index.evaluation.MRR.compute \"Permalink to this definition\")\n\nCompute metric.\n\n_class_ llama\\_index.evaluation.PairwiseComparisonEvaluator(_service\\_context: Optional\\[[ServiceContext](https://docs.llamaindex.ai/en/stable/api_reference/service_context.html#llama_index.indices.service_context.ServiceContext \"llama_index.indices.service_context.ServiceContext\")\\] \\= None_, _eval\\_template: Optional\\[Union\\[[BasePromptTemplate](https://docs.llamaindex.ai/en/stable/api_reference/prompts.html#llama_index.prompts.base.BasePromptTemplate \"llama_index.prompts.base.BasePromptTemplate\"), str\\]\\] \\= None_, _enforce\\_consensus: bool \\= True_)[\uf0c1](#llama_index.evaluation.PairwiseComparisonEvaluator \"Permalink to this definition\")\n\nPairwise comparison evaluator.\n\nEvaluates the quality of a response vs. a \u201creference\u201d response given a question by having an LLM judge which response is better.\n\nOutputs whether the response given is better than the reference response.\n\nParameters\n\n*   **service\\_context** (_Optional__\\[_[_ServiceContext_](https://docs.llamaindex.ai/en/stable/api_reference/service_context.html#llama_index.indices.service_context.ServiceContext \"llama_index.indices.service_context.ServiceContext\")_\\]_) \u2013 The service context to use for evaluation.\n    \n*   **eval\\_template** (_Optional__\\[__Union__\\[__str__,_ [_BasePromptTemplate_](https://docs.llamaindex.ai/en/stable/api_reference/prompts.html#llama_index.prompts.base.BasePromptTemplate \"llama_index.prompts.base.BasePromptTemplate\")_\\]__\\]_) \u2013 The template to use for evaluation.\n    \n*   **enforce\\_consensus** (_bool_) \u2013 Whether to enforce consensus (consistency if we flip the order of the answers). Defaults to True.\n    \n\n_async_ aevaluate(_query: Optional\\[str\\] \\= None_, _response: Optional\\[str\\] \\= None_, _contexts: Optional\\[Sequence\\[str\\]\\] \\= None_, _reference: Optional\\[str\\] \\= None_, _\\*\\*kwargs: Any_) \u2192 [EvaluationResult](#llama_index.evaluation.EvaluationResult \"llama_index.evaluation.base.EvaluationResult\")[\uf0c1](#llama_index.evaluation.PairwiseComparisonEvaluator.aevaluate \"Permalink to this definition\")\n\nRun evaluation with query string, retrieved contexts, and generated response string.\n\nSubclasses can override this method to provide custom evaluation logic and take in additional arguments.\n\n_async_ aevaluate\\_response(_query: Optional\\[str\\] \\= None_, _response: Optional\\[[Response](https://docs.llamaindex.ai/en/stable/api_reference/response.html#llama_index.response.schema.Response \"llama_index.response.schema.Response\")\\] \\= None_, _\\*\\*kwargs: Any_) \u2192 [EvaluationResult](#llama_index.evaluation.EvaluationResult \"llama_index.evaluation.base.EvaluationResult\")[\uf0c1](#llama_index.evaluation.PairwiseComparisonEvaluator.aevaluate_response \"Permalink to this definition\")\n\nRun evaluation with query string and generated Response object.\n\nSubclasses can override this method to provide custom evaluation logic and take in additional arguments.\n\nevaluate(_query: Optional\\[str\\] \\= None_, _response: Optional\\[str\\] \\= None_, _contexts: Optional\\[Sequence\\[str\\]\\] \\= None_, _\\*\\*kwargs: Any_) \u2192 [EvaluationResult](#llama_index.evaluation.EvaluationResult \"llama_index.evaluation.base.EvaluationResult\")[\uf0c1](#llama_index.evaluation.PairwiseComparisonEvaluator.evaluate \"Permalink to this definition\")\n\nRun evaluation with query string, retrieved contexts, and generated response string.\n\nSubclasses can override this method to provide custom evaluation logic and take in additional arguments.\n\nevaluate\\_response(_query: Optional\\[str\\] \\= None_, _response: Optional\\[[Response](https://docs.llamaindex.ai/en/stable/api_reference/response.html#llama_index.response.schema.Response \"llama_index.response.schema.Response\")\\] \\= None_, _\\*\\*kwargs: Any_) \u2192 [EvaluationResult](#llama_index.evaluation.EvaluationResult \"llama_index.evaluation.base.EvaluationResult\")[\uf0c1](#llama_index.evaluation.PairwiseComparisonEvaluator.evaluate_response \"Permalink to this definition\")\n\nRun evaluation with query string and generated Response object.\n\nSubclasses can override this method to provide custom evaluation logic and take in additional arguments.\n\n_pydantic model_ llama\\_index.evaluation.QueryResponseDataset[\uf0c1](#llama_index.evaluation.QueryResponseDataset \"Permalink to this definition\")\n\nQuery Response Dataset.\n\nThe response can be empty if the dataset is generated from documents.\n\nParameters\n\n*   **queries** (_Dict__\\[__str__,_ _str__\\]_) \u2013 Query id -> query.\n    \n*   **responses** (_Dict__\\[__str__,_ _str__\\]_) \u2013 Query id -> response.\n    \n\nShow JSON schema\n\n{\n   \"title\": \"QueryResponseDataset\",\n   \"description\": \"Query Response Dataset.\\\\n\\\\nThe response can be empty if the dataset is generated from documents.\\\\n\\\\nArgs:\\\\n    queries (Dict\\[str, str\\]): Query id -> query.\\\\n    responses (Dict\\[str, str\\]): Query id -> response.\",\n   \"type\": \"object\",\n   \"properties\": {\n      \"queries\": {\n         \"title\": \"Queries\",\n         \"description\": \"Query id -> query\",\n         \"type\": \"object\",\n         \"additionalProperties\": {\n            \"type\": \"string\"\n         }\n      },\n      \"responses\": {\n         \"title\": \"Responses\",\n         \"description\": \"Query id -> response\",\n         \"type\": \"object\",\n         \"additionalProperties\": {\n            \"type\": \"string\"\n         }\n      }\n   }\n}\n\nFields\n\n*   `queries (Dict[str, str])`\n    \n*   `responses (Dict[str, str])`\n    \n\n_field_ queries_: Dict\\[str, str\\]_ _\\[Optional\\]_[\uf0c1](#llama_index.evaluation.QueryResponseDataset.queries \"Permalink to this definition\")\n\nQuery id -> query\n\n_field_ responses_: Dict\\[str, str\\]_ _\\[Optional\\]_[\uf0c1](#llama_index.evaluation.QueryResponseDataset.responses \"Permalink to this definition\")\n\nQuery id -> response\n\n_classmethod_ construct(_\\_fields\\_set: Optional\\[SetStr\\] \\= None_, _\\*\\*values: Any_) \u2192 Model[\uf0c1](#llama_index.evaluation.QueryResponseDataset.construct \"Permalink to this definition\")\n\nCreates a new model setting \\_\\_dict\\_\\_ and \\_\\_fields\\_set\\_\\_ from trusted or pre-validated data. Default values are respected, but no other validation is performed. Behaves as if Config.extra = \u2018allow\u2019 was set since it adds all passed values\n\ncopy(_\\*_, _include: Optional\\[Union\\[AbstractSetIntStr, MappingIntStrAny\\]\\] \\= None_, _exclude: Optional\\[Union\\[AbstractSetIntStr, MappingIntStrAny\\]\\] \\= None_, _update: Optional\\[DictStrAny\\] \\= None_, _deep: bool \\= False_) \u2192 Model[\uf0c1](#llama_index.evaluation.QueryResponseDataset.copy \"Permalink to this definition\")\n\nDuplicate a model, optionally choose which fields to include, exclude and change.\n\nParameters\n\n*   **include** \u2013 fields to include in new model\n    \n*   **exclude** \u2013 fields to exclude from new model, as with values this takes precedence over include\n    \n*   **update** \u2013 values to change/add in the new model. Note: the data is not validated before creating the new model: you should trust this data\n    \n*   **deep** \u2013 set to True to make a deep copy of the model\n    \n\nReturns\n\nnew model instance\n\ndict(_\\*_, _include: Optional\\[Union\\[AbstractSetIntStr, MappingIntStrAny\\]\\] \\= None_, _exclude: Optional\\[Union\\[AbstractSetIntStr, MappingIntStrAny\\]\\] \\= None_, _by\\_alias: bool \\= False_, _skip\\_defaults: Optional\\[bool\\] \\= None_, _exclude\\_unset: bool \\= False_, _exclude\\_defaults: bool \\= False_, _exclude\\_none: bool \\= False_) \u2192 DictStrAny[\uf0c1](#llama_index.evaluation.QueryResponseDataset.dict \"Permalink to this definition\")\n\nGenerate a dictionary representation of the model, optionally specifying which fields to include or exclude.\n\n_classmethod_ from\\_json(_path: str_) \u2192 [QueryResponseDataset](#llama_index.evaluation.QueryResponseDataset \"llama_index.evaluation.dataset_generation.QueryResponseDataset\")[\uf0c1](#llama_index.evaluation.QueryResponseDataset.from_json \"Permalink to this definition\")\n\nLoad json.\n\n_classmethod_ from\\_orm(_obj: Any_) \u2192 Model[\uf0c1](#llama_index.evaluation.QueryResponseDataset.from_orm \"Permalink to this definition\")\n\n_classmethod_ from\\_qr\\_pairs(_qr\\_pairs: List\\[Tuple\\[str, str\\]\\]_) \u2192 [QueryResponseDataset](#llama_index.evaluation.QueryResponseDataset \"llama_index.evaluation.dataset_generation.QueryResponseDataset\")[\uf0c1](#llama_index.evaluation.QueryResponseDataset.from_qr_pairs \"Permalink to this definition\")\n\nCreate from qr pairs.\n\njson(_\\*_, _include: Optional\\[Union\\[AbstractSetIntStr, MappingIntStrAny\\]\\] \\= None_, _exclude: Optional\\[Union\\[AbstractSetIntStr, MappingIntStrAny\\]\\] \\= None_, _by\\_alias: bool \\= False_, _skip\\_defaults: Optional\\[bool\\] \\= None_, _exclude\\_unset: bool \\= False_, _exclude\\_defaults: bool \\= False_, _exclude\\_none: bool \\= False_, _encoder: Optional\\[Callable\\[\\[Any\\], Any\\]\\] \\= None_, _models\\_as\\_dict: bool \\= True_, _\\*\\*dumps\\_kwargs: Any_) \u2192 unicode[\uf0c1](#llama_index.evaluation.QueryResponseDataset.json \"Permalink to this definition\")\n\nGenerate a JSON representation of the model, include and exclude arguments as per dict().\n\nencoder is an optional function to supply as default to json.dumps(), other arguments as per json.dumps().\n\n_classmethod_ parse\\_file(_path: Union\\[str, Path\\]_, _\\*_, _content\\_type: unicode \\= None_, _encoding: unicode \\= 'utf8'_, _proto: Protocol \\= None_, _allow\\_pickle: bool \\= False_) \u2192 Model[\uf0c1](#llama_index.evaluation.QueryResponseDataset.parse_file \"Permalink to this definition\")\n\n_classmethod_ parse\\_obj(_obj: Any_) \u2192 Model[\uf0c1](#llama_index.evaluation.QueryResponseDataset.parse_obj \"Permalink to this definition\")\n\n_classmethod_ parse\\_raw(_b: Union\\[str, bytes\\]_, _\\*_, _content\\_type: unicode \\= None_, _encoding: unicode \\= 'utf8'_, _proto: Protocol \\= None_, _allow\\_pickle: bool \\= False_) \u2192 Model[\uf0c1](#llama_index.evaluation.QueryResponseDataset.parse_raw \"Permalink to this definition\")\n\nsave\\_json(_path: str_) \u2192 None[\uf0c1](#llama_index.evaluation.QueryResponseDataset.save_json \"Permalink to this definition\")\n\nSave json.\n\n_classmethod_ schema(_by\\_alias: bool \\= True_, _ref\\_template: unicode \\= '#/definitions/{model}'_) \u2192 DictStrAny[\uf0c1](#llama_index.evaluation.QueryResponseDataset.schema \"Permalink to this definition\")\n\n_classmethod_ schema\\_json(_\\*_, _by\\_alias: bool \\= True_, _ref\\_template: unicode \\= '#/definitions/{model}'_, _\\*\\*dumps\\_kwargs: Any_) \u2192 unicode[\uf0c1](#llama_index.evaluation.QueryResponseDataset.schema_json \"Permalink to this definition\")\n\n_classmethod_ update\\_forward\\_refs(_\\*\\*localns: Any_) \u2192 None[\uf0c1](#llama_index.evaluation.QueryResponseDataset.update_forward_refs \"Permalink to this definition\")\n\nTry to update ForwardRefs on fields based on this Model, globalns and localns.\n\n_classmethod_ validate(_value: Any_) \u2192 Model[\uf0c1](#llama_index.evaluation.QueryResponseDataset.validate \"Permalink to this definition\")\n\n_property_ qr\\_pairs_: List\\[Tuple\\[str, str\\]\\]_[\uf0c1](#llama_index.evaluation.QueryResponseDataset.qr_pairs \"Permalink to this definition\")\n\nGet pairs.\n\n_property_ questions_: List\\[str\\]_[\uf0c1](#llama_index.evaluation.QueryResponseDataset.questions \"Permalink to this definition\")\n\nGet questions.\n\nllama\\_index.evaluation.QueryResponseEvaluator[\uf0c1](#llama_index.evaluation.QueryResponseEvaluator \"Permalink to this definition\")\n\nalias of [`RelevancyEvaluator`](#llama_index.evaluation.RelevancyEvaluator \"llama_index.evaluation.relevancy.RelevancyEvaluator\")\n\n_class_ llama\\_index.evaluation.RelevancyEvaluator(_service\\_context: [llama\\_index.indices.service\\_context.ServiceContext](https://docs.llamaindex.ai/en/stable/api_reference/service_context.html#llama_index.indices.service_context.ServiceContext \"llama_index.indices.service_context.ServiceContext\") | None \\= None_, _raise\\_error: bool \\= False_, _eval\\_template: str | [llama\\_index.prompts.base.BasePromptTemplate](https://docs.llamaindex.ai/en/stable/api_reference/prompts.html#llama_index.prompts.base.BasePromptTemplate \"llama_index.prompts.base.BasePromptTemplate\") | None \\= None_, _refine\\_template: str | [llama\\_index.prompts.base.BasePromptTemplate](https://docs.llamaindex.ai/en/stable/api_reference/prompts.html#llama_index.prompts.base.BasePromptTemplate \"llama_index.prompts.base.BasePromptTemplate\") | None \\= None_)[\uf0c1](#llama_index.evaluation.RelevancyEvaluator \"Permalink to this definition\")\n\nRelenvancy evaluator.\n\nEvaluates the relevancy of retrieved contexts and response to a query. This evaluator considers the query string, retrieved contexts, and response string.\n\nParameters\n\n*   **service\\_context** (_Optional__\\[_[_ServiceContext_](https://docs.llamaindex.ai/en/stable/api_reference/service_context.html#llama_index.indices.service_context.ServiceContext \"llama_index.indices.service_context.ServiceContext\")_\\]_) \u2013 The service context to use for evaluation.\n    \n*   **raise\\_error** (_Optional__\\[__bool__\\]_) \u2013 Whether to raise an error if the response is invalid. Defaults to False.\n    \n*   **eval\\_template** (_Optional__\\[__Union__\\[__str__,_ [_BasePromptTemplate_](https://docs.llamaindex.ai/en/stable/api_reference/prompts.html#llama_index.prompts.base.BasePromptTemplate \"llama_index.prompts.base.BasePromptTemplate\")_\\]__\\]_) \u2013 The template to use for evaluation.\n    \n*   **refine\\_template** (_Optional__\\[__Union__\\[__str__,_ [_BasePromptTemplate_](https://docs.llamaindex.ai/en/stable/api_reference/prompts.html#llama_index.prompts.base.BasePromptTemplate \"llama_index.prompts.base.BasePromptTemplate\")_\\]__\\]_) \u2013 The template to use for refinement.\n    \n\n_async_ aevaluate(_query: str | None \\= None_, _response: str | None \\= None_, _contexts: Optional\\[Sequence\\[str\\]\\] \\= None_, _\\*\\*kwargs: Any_) \u2192 [EvaluationResult](#llama_index.evaluation.EvaluationResult \"llama_index.evaluation.base.EvaluationResult\")[\uf0c1](#llama_index.evaluation.RelevancyEvaluator.aevaluate \"Permalink to this definition\")\n\nEvaluate whether the contexts and response are relevant to the query.\n\n_async_ aevaluate\\_response(_query: Optional\\[str\\] \\= None_, _response: Optional\\[[Response](https://docs.llamaindex.ai/en/stable/api_reference/response.html#llama_index.response.schema.Response \"llama_index.response.schema.Response\")\\] \\= None_, _\\*\\*kwargs: Any_) \u2192 [EvaluationResult](#llama_index.evaluation.EvaluationResult \"llama_index.evaluation.base.EvaluationResult\")[\uf0c1](#llama_index.evaluation.RelevancyEvaluator.aevaluate_response \"Permalink to this definition\")\n\nRun evaluation with query string and generated Response object.\n\nSubclasses can override this method to provide custom evaluation logic and take in additional arguments.\n\nevaluate(_query: Optional\\[str\\] \\= None_, _response: Optional\\[str\\] \\= None_, _contexts: Optional\\[Sequence\\[str\\]\\] \\= None_, _\\*\\*kwargs: Any_) \u2192 [EvaluationResult](#llama_index.evaluation.EvaluationResult \"llama_index.evaluation.base.EvaluationResult\")[\uf0c1](#llama_index.evaluation.RelevancyEvaluator.evaluate \"Permalink to this definition\")\n\nRun evaluation with query string, retrieved contexts, and generated response string.\n\nSubclasses can override this method to provide custom evaluation logic and take in additional arguments.\n\nevaluate\\_response(_query: Optional\\[str\\] \\= None_, _response: Optional\\[[Response](https://docs.llamaindex.ai/en/stable/api_reference/response.html#llama_index.response.schema.Response \"llama_index.response.schema.Response\")\\] \\= None_, _\\*\\*kwargs: Any_) \u2192 [EvaluationResult](#llama_index.evaluation.EvaluationResult \"llama_index.evaluation.base.EvaluationResult\")[\uf0c1](#llama_index.evaluation.RelevancyEvaluator.evaluate_response \"Permalink to this definition\")\n\nRun evaluation with query string and generated Response object.\n\nSubclasses can override this method to provide custom evaluation logic and take in additional arguments.\n\nllama\\_index.evaluation.ResponseEvaluator[\uf0c1](#llama_index.evaluation.ResponseEvaluator \"Permalink to this definition\")\n\nalias of [`FaithfulnessEvaluator`](#llama_index.evaluation.FaithfulnessEvaluator \"llama_index.evaluation.faithfulness.FaithfulnessEvaluator\")\n\n_pydantic model_ llama\\_index.evaluation.RetrievalEvalResult[\uf0c1](#llama_index.evaluation.RetrievalEvalResult \"Permalink to this definition\")\n\nRetrieval eval result.\n\nNOTE: this abstraction might change in the future.\n\nquery[\uf0c1](#llama_index.evaluation.RetrievalEvalResult.query \"Permalink to this definition\")\n\nQuery string\n\nType\n\nstr\n\nexpected\\_ids[\uf0c1](#llama_index.evaluation.RetrievalEvalResult.expected_ids \"Permalink to this definition\")\n\nExpected ids\n\nType\n\nList\\[str\\]\n\nretrieved\\_ids[\uf0c1](#llama_index.evaluation.RetrievalEvalResult.retrieved_ids \"Permalink to this definition\")\n\nRetrieved ids\n\nType\n\nList\\[str\\]\n\nmetric\\_dict[\uf0c1](#llama_index.evaluation.RetrievalEvalResult.metric_dict \"Permalink to this definition\")\n\nMetric dictionary for the evaluation\n\nType\n\nDict\\[str, BaseRetrievalMetric\\]\n\nShow JSON schema\n\n{\n   \"title\": \"RetrievalEvalResult\",\n   \"description\": \"Retrieval eval result.\\\\n\\\\nNOTE: this abstraction might change in the future.\\\\n\\\\nAttributes:\\\\n    query (str): Query string\\\\n    expected\\_ids (List\\[str\\]): Expected ids\\\\n    retrieved\\_ids (List\\[str\\]): Retrieved ids\\\\n    metric\\_dict (Dict\\[str, BaseRetrievalMetric\\]):             Metric dictionary for the evaluation\",\n   \"type\": \"object\",\n   \"properties\": {\n      \"query\": {\n         \"title\": \"Query\",\n         \"description\": \"Query string\",\n         \"type\": \"string\"\n      },\n      \"expected\\_ids\": {\n         \"title\": \"Expected Ids\",\n         \"description\": \"Expected ids\",\n         \"type\": \"array\",\n         \"items\": {\n            \"type\": \"string\"\n         }\n      },\n      \"retrieved\\_ids\": {\n         \"title\": \"Retrieved Ids\",\n         \"description\": \"Retrieved ids\",\n         \"type\": \"array\",\n         \"items\": {\n            \"type\": \"string\"\n         }\n      },\n      \"metric\\_dict\": {\n         \"title\": \"Metric Dict\",\n         \"description\": \"Metric dictionary for the evaluation\",\n         \"type\": \"object\",\n         \"additionalProperties\": {\n            \"$ref\": \"#/definitions/RetrievalMetricResult\"\n         }\n      }\n   },\n   \"required\": \\[\n      \"query\",\n      \"expected\\_ids\",\n      \"retrieved\\_ids\",\n      \"metric\\_dict\"\n   \\],\n   \"definitions\": {\n      \"RetrievalMetricResult\": {\n         \"title\": \"RetrievalMetricResult\",\n         \"description\": \"Metric result.\\\\n\\\\nAttributes:\\\\n    score (float): Score for the metric\\\\n    metadata (Dict\\[str, Any\\]): Metadata for the metric result\",\n         \"type\": \"object\",\n         \"properties\": {\n            \"score\": {\n               \"title\": \"Score\",\n               \"description\": \"Score for the metric\",\n               \"type\": \"number\"\n            },\n            \"metadata\": {\n               \"title\": \"Metadata\",\n               \"description\": \"Metadata for the metric result\",\n               \"type\": \"object\"\n            }\n         },\n         \"required\": \\[\n            \"score\"\n         \\]\n      }\n   }\n}\n\nConfig\n\n*   **arbitrary\\_types\\_allowed**: _bool = True_\n    \n\nFields\n\n*   `expected_ids (List[str])`\n    \n*   `metric_dict (Dict[str, llama_index.evaluation.retrieval.metrics_base.RetrievalMetricResult])`\n    \n*   `query (str)`\n    \n*   `retrieved_ids (List[str])`\n    \n\n_field_ expected\\_ids_: List\\[str\\]_ _\\[Required\\]_[\uf0c1](#id0 \"Permalink to this definition\")\n\nExpected ids\n\n_field_ metric\\_dict_: Dict\\[str, [RetrievalMetricResult](#llama_index.evaluation.RetrievalMetricResult \"llama_index.evaluation.retrieval.metrics_base.RetrievalMetricResult\")\\]_ _\\[Required\\]_[\uf0c1](#id1 \"Permalink to this definition\")\n\nMetric dictionary for the evaluation\n\n_field_ query_: str_ _\\[Required\\]_[\uf0c1](#id2 \"Permalink to this definition\")\n\nQuery string\n\n_field_ retrieved\\_ids_: List\\[str\\]_ _\\[Required\\]_[\uf0c1](#id3 \"Permalink to this definition\")\n\nRetrieved ids\n\n_classmethod_ construct(_\\_fields\\_set: Optional\\[SetStr\\] \\= None_, _\\*\\*values: Any_) \u2192 Model[\uf0c1](#llama_index.evaluation.RetrievalEvalResult.construct \"Permalink to this definition\")\n\nCreates a new model setting \\_\\_dict\\_\\_ and \\_\\_fields\\_set\\_\\_ from trusted or pre-validated data. Default values are respected, but no other validation is performed. Behaves as if Config.extra = \u2018allow\u2019 was set since it adds all passed values\n\ncopy(_\\*_, _include: Optional\\[Union\\[AbstractSetIntStr, MappingIntStrAny\\]\\] \\= None_, _exclude: Optional\\[Union\\[AbstractSetIntStr, MappingIntStrAny\\]\\] \\= None_, _update: Optional\\[DictStrAny\\] \\= None_, _deep: bool \\= False_) \u2192 Model[\uf0c1](#llama_index.evaluation.RetrievalEvalResult.copy \"Permalink to this definition\")\n\nDuplicate a model, optionally choose which fields to include, exclude and change.\n\nParameters\n\n*   **include** \u2013 fields to include in new model\n    \n*   **exclude** \u2013 fields to exclude from new model, as with values this takes precedence over include\n    \n*   **update** \u2013 values to change/add in the new model. Note: the data is not validated before creating the new model: you should trust this data\n    \n*   **deep** \u2013 set to True to make a deep copy of the model\n    \n\nReturns\n\nnew model instance\n\ndict(_\\*_, _include: Optional\\[Union\\[AbstractSetIntStr, MappingIntStrAny\\]\\] \\= None_, _exclude: Optional\\[Union\\[AbstractSetIntStr, MappingIntStrAny\\]\\] \\= None_, _by\\_alias: bool \\= False_, _skip\\_defaults: Optional\\[bool\\] \\= None_, _exclude\\_unset: bool \\= False_, _exclude\\_defaults: bool \\= False_, _exclude\\_none: bool \\= False_) \u2192 DictStrAny[\uf0c1](#llama_index.evaluation.RetrievalEvalResult.dict \"Permalink to this definition\")\n\nGenerate a dictionary representation of the model, optionally specifying which fields to include or exclude.\n\n_classmethod_ from\\_orm(_obj: Any_) \u2192 Model[\uf0c1](#llama_index.evaluation.RetrievalEvalResult.from_orm \"Permalink to this definition\")\n\njson(_\\*_, _include: Optional\\[Union\\[AbstractSetIntStr, MappingIntStrAny\\]\\] \\= None_, _exclude: Optional\\[Union\\[AbstractSetIntStr, MappingIntStrAny\\]\\] \\= None_, _by\\_alias: bool \\= False_, _skip\\_defaults: Optional\\[bool\\] \\= None_, _exclude\\_unset: bool \\= False_, _exclude\\_defaults: bool \\= False_, _exclude\\_none: bool \\= False_, _encoder: Optional\\[Callable\\[\\[Any\\], Any\\]\\] \\= None_, _models\\_as\\_dict: bool \\= True_, _\\*\\*dumps\\_kwargs: Any_) \u2192 unicode[\uf0c1](#llama_index.evaluation.RetrievalEvalResult.json \"Permalink to this definition\")\n\nGenerate a JSON representation of the model, include and exclude arguments as per dict().\n\nencoder is an optional function to supply as default to json.dumps(), other arguments as per json.dumps().\n\n_classmethod_ parse\\_file(_path: Union\\[str, Path\\]_, _\\*_, _content\\_type: unicode \\= None_, _encoding: unicode \\= 'utf8'_, _proto: Protocol \\= None_, _allow\\_pickle: bool \\= False_) \u2192 Model[\uf0c1](#llama_index.evaluation.RetrievalEvalResult.parse_file \"Permalink to this definition\")\n\n_classmethod_ parse\\_obj(_obj: Any_) \u2192 Model[\uf0c1](#llama_index.evaluation.RetrievalEvalResult.parse_obj \"Permalink to this definition\")\n\n_classmethod_ parse\\_raw(_b: Union\\[str, bytes\\]_, _\\*_, _content\\_type: unicode \\= None_, _encoding: unicode \\= 'utf8'_, _proto: Protocol \\= None_, _allow\\_pickle: bool \\= False_) \u2192 Model[\uf0c1](#llama_index.evaluation.RetrievalEvalResult.parse_raw \"Permalink to this definition\")\n\n_classmethod_ schema(_by\\_alias: bool \\= True_, _ref\\_template: unicode \\= '#/definitions/{model}'_) \u2192 DictStrAny[\uf0c1](#llama_index.evaluation.RetrievalEvalResult.schema \"Permalink to this definition\")\n\n_classmethod_ schema\\_json(_\\*_, _by\\_alias: bool \\= True_, _ref\\_template: unicode \\= '#/definitions/{model}'_, _\\*\\*dumps\\_kwargs: Any_) \u2192 unicode[\uf0c1](#llama_index.evaluation.RetrievalEvalResult.schema_json \"Permalink to this definition\")\n\n_classmethod_ update\\_forward\\_refs(_\\*\\*localns: Any_) \u2192 None[\uf0c1](#llama_index.evaluation.RetrievalEvalResult.update_forward_refs \"Permalink to this definition\")\n\nTry to update ForwardRefs on fields based on this Model, globalns and localns.\n\n_classmethod_ validate(_value: Any_) \u2192 Model[\uf0c1](#llama_index.evaluation.RetrievalEvalResult.validate \"Permalink to this definition\")\n\n_property_ metric\\_vals\\_dict_: Dict\\[str, float\\]_[\uf0c1](#llama_index.evaluation.RetrievalEvalResult.metric_vals_dict \"Permalink to this definition\")\n\nDictionary of metric values.\n\n_pydantic model_ llama\\_index.evaluation.RetrievalMetricResult[\uf0c1](#llama_index.evaluation.RetrievalMetricResult \"Permalink to this definition\")\n\nMetric result.\n\nscore[\uf0c1](#llama_index.evaluation.RetrievalMetricResult.score \"Permalink to this definition\")\n\nScore for the metric\n\nType\n\nfloat\n\nmetadata[\uf0c1](#llama_index.evaluation.RetrievalMetricResult.metadata \"Permalink to this definition\")\n\nMetadata for the metric result\n\nType\n\nDict\\[str, Any\\]\n\nShow JSON schema\n\n{\n   \"title\": \"RetrievalMetricResult\",\n   \"description\": \"Metric result.\\\\n\\\\nAttributes:\\\\n    score (float): Score for the metric\\\\n    metadata (Dict\\[str, Any\\]): Metadata for the metric result\",\n   \"type\": \"object\",\n   \"properties\": {\n      \"score\": {\n         \"title\": \"Score\",\n         \"description\": \"Score for the metric\",\n         \"type\": \"number\"\n      },\n      \"metadata\": {\n         \"title\": \"Metadata\",\n         \"description\": \"Metadata for the metric result\",\n         \"type\": \"object\"\n      }\n   },\n   \"required\": \\[\n      \"score\"\n   \\]\n}\n\nFields\n\n*   `metadata (Dict[str, Any])`\n    \n*   `score (float)`\n    \n\n_field_ metadata_: Dict\\[str, Any\\]_ _\\[Optional\\]_[\uf0c1](#id4 \"Permalink to this definition\")\n\nMetadata for the metric result\n\n_field_ score_: float_ _\\[Required\\]_[\uf0c1](#id5 \"Permalink to this definition\")\n\nScore for the metric\n\n_classmethod_ construct(_\\_fields\\_set: Optional\\[SetStr\\] \\= None_, _\\*\\*values: Any_) \u2192 Model[\uf0c1](#llama_index.evaluation.RetrievalMetricResult.construct \"Permalink to this definition\")\n\nCreates a new model setting \\_\\_dict\\_\\_ and \\_\\_fields\\_set\\_\\_ from trusted or pre-validated data. Default values are respected, but no other validation is performed. Behaves as if Config.extra = \u2018allow\u2019 was set since it adds all passed values\n\ncopy(_\\*_, _include: Optional\\[Union\\[AbstractSetIntStr, MappingIntStrAny\\]\\] \\= None_, _exclude: Optional\\[Union\\[AbstractSetIntStr, MappingIntStrAny\\]\\] \\= None_, _update: Optional\\[DictStrAny\\] \\= None_, _deep: bool \\= False_) \u2192 Model[\uf0c1](#llama_index.evaluation.RetrievalMetricResult.copy \"Permalink to this definition\")\n\nDuplicate a model, optionally choose which fields to include, exclude and change.\n\nParameters\n\n*   **include** \u2013 fields to include in new model\n    \n*   **exclude** \u2013 fields to exclude from new model, as with values this takes precedence over include\n    \n*   **update** \u2013 values to change/add in the new model. Note: the data is not validated before creating the new model: you should trust this data\n    \n*   **deep** \u2013 set to True to make a deep copy of the model\n    \n\nReturns\n\nnew model instance\n\ndict(_\\*_, _include: Optional\\[Union\\[AbstractSetIntStr, MappingIntStrAny\\]\\] \\= None_, _exclude: Optional\\[Union\\[AbstractSetIntStr, MappingIntStrAny\\]\\] \\= None_, _by\\_alias: bool \\= False_, _skip\\_defaults: Optional\\[bool\\] \\= None_, _exclude\\_unset: bool \\= False_, _exclude\\_defaults: bool \\= False_, _exclude\\_none: bool \\= False_) \u2192 DictStrAny[\uf0c1](#llama_index.evaluation.RetrievalMetricResult.dict \"Permalink to this definition\")\n\nGenerate a dictionary representation of the model, optionally specifying which fields to include or exclude.\n\n_classmethod_ from\\_orm(_obj: Any_) \u2192 Model[\uf0c1](#llama_index.evaluation.RetrievalMetricResult.from_orm \"Permalink to this definition\")\n\njson(_\\*_, _include: Optional\\[Union\\[AbstractSetIntStr, MappingIntStrAny\\]\\] \\= None_, _exclude: Optional\\[Union\\[AbstractSetIntStr, MappingIntStrAny\\]\\] \\= None_, _by\\_alias: bool \\= False_, _skip\\_defaults: Optional\\[bool\\] \\= None_, _exclude\\_unset: bool \\= False_, _exclude\\_defaults: bool \\= False_, _exclude\\_none: bool \\= False_, _encoder: Optional\\[Callable\\[\\[Any\\], Any\\]\\] \\= None_, _models\\_as\\_dict: bool \\= True_, _\\*\\*dumps\\_kwargs: Any_) \u2192 unicode[\uf0c1](#llama_index.evaluation.RetrievalMetricResult.json \"Permalink to this definition\")\n\nGenerate a JSON representation of the model, include and exclude arguments as per dict().\n\nencoder is an optional function to supply as default to json.dumps(), other arguments as per json.dumps().\n\n_classmethod_ parse\\_file(_path: Union\\[str, Path\\]_, _\\*_, _content\\_type: unicode \\= None_, _encoding: unicode \\= 'utf8'_, _proto: Protocol \\= None_, _allow\\_pickle: bool \\= False_) \u2192 Model[\uf0c1](#llama_index.evaluation.RetrievalMetricResult.parse_file \"Permalink to this definition\")\n\n_classmethod_ parse\\_obj(_obj: Any_) \u2192 Model[\uf0c1](#llama_index.evaluation.RetrievalMetricResult.parse_obj \"Permalink to this definition\")\n\n_classmethod_ parse\\_raw(_b: Union\\[str, bytes\\]_, _\\*_, _content\\_type: unicode \\= None_, _encoding: unicode \\= 'utf8'_, _proto: Protocol \\= None_, _allow\\_pickle: bool \\= False_) \u2192 Model[\uf0c1](#llama_index.evaluation.RetrievalMetricResult.parse_raw \"Permalink to this definition\")\n\n_classmethod_ schema(_by\\_alias: bool \\= True_, _ref\\_template: unicode \\= '#/definitions/{model}'_) \u2192 DictStrAny[\uf0c1](#llama_index.evaluation.RetrievalMetricResult.schema \"Permalink to this definition\")\n\n_classmethod_ schema\\_json(_\\*_, _by\\_alias: bool \\= True_, _ref\\_template: unicode \\= '#/definitions/{model}'_, _\\*\\*dumps\\_kwargs: Any_) \u2192 unicode[\uf0c1](#llama_index.evaluation.RetrievalMetricResult.schema_json \"Permalink to this definition\")\n\n_classmethod_ update\\_forward\\_refs(_\\*\\*localns: Any_) \u2192 None[\uf0c1](#llama_index.evaluation.RetrievalMetricResult.update_forward_refs \"Permalink to this definition\")\n\nTry to update ForwardRefs on fields based on this Model, globalns and localns.\n\n_classmethod_ validate(_value: Any_) \u2192 Model[\uf0c1](#llama_index.evaluation.RetrievalMetricResult.validate \"Permalink to this definition\")\n\n_pydantic model_ llama\\_index.evaluation.RetrieverEvaluator[\uf0c1](#llama_index.evaluation.RetrieverEvaluator \"Permalink to this definition\")\n\nRetriever evaluator.\n\nThis module will evaluate a retriever using a set of metrics.\n\nParameters\n\n*   **metrics** (_List__\\[__BaseRetrievalMetric__\\]_) \u2013 Sequence of metrics to evaluate\n    \n*   **retriever** \u2013 Retriever to evaluate.\n    \n\nShow JSON schema\n\n{\n   \"title\": \"RetrieverEvaluator\",\n   \"description\": \"Retriever evaluator.\\\\n\\\\nThis module will evaluate a retriever using a set of metrics.\\\\n\\\\nArgs:\\\\n    metrics (List\\[BaseRetrievalMetric\\]): Sequence of metrics to evaluate\\\\n    retriever: Retriever to evaluate.\",\n   \"type\": \"object\",\n   \"properties\": {\n      \"metrics\": {\n         \"title\": \"Metrics\"\n      },\n      \"retriever\": {\n         \"title\": \"Retriever\"\n      }\n   }\n}\n\nConfig\n\n*   **arbitrary\\_types\\_allowed**: _bool = True_\n    \n\nFields\n\n*   `metrics (List[llama_index.evaluation.retrieval.metrics_base.BaseRetrievalMetric])`\n    \n*   `retriever (llama_index.indices.base_retriever.BaseRetriever)`\n    \n\n_field_ metrics_: List\\[BaseRetrievalMetric\\]_ _\\[Required\\]_[\uf0c1](#llama_index.evaluation.RetrieverEvaluator.metrics \"Permalink to this definition\")\n\nList of metrics to evaluate\n\n_field_ retriever_: [BaseRetriever](https://docs.llamaindex.ai/en/stable/api_reference/query/retrievers.html#llama_index.indices.base_retriever.BaseRetriever \"llama_index.indices.base_retriever.BaseRetriever\")_ _\\[Required\\]_[\uf0c1](#llama_index.evaluation.RetrieverEvaluator.retriever \"Permalink to this definition\")\n\nRetriever to evaluate\n\n_async_ aevaluate(_query: str_, _expected\\_ids: List\\[str\\]_, _\\*\\*kwargs: Any_) \u2192 [RetrievalEvalResult](#llama_index.evaluation.RetrievalEvalResult \"llama_index.evaluation.retrieval.base.RetrievalEvalResult\")[\uf0c1](#llama_index.evaluation.RetrieverEvaluator.aevaluate \"Permalink to this definition\")\n\nRun evaluation with query string, retrieved contexts, and generated response string.\n\nSubclasses can override this method to provide custom evaluation logic and take in additional arguments.\n\n_async_ aevaluate\\_dataset(_dataset: [EmbeddingQAFinetuneDataset](https://docs.llamaindex.ai/en/stable/api_reference/finetuning.html#llama_index.finetuning.EmbeddingQAFinetuneDataset \"llama_index.finetuning.embeddings.common.EmbeddingQAFinetuneDataset\")_, _workers: int \\= 2_, _show\\_progress: bool \\= False_, _\\*\\*kwargs: Any_) \u2192 List\\[[RetrievalEvalResult](#llama_index.evaluation.RetrievalEvalResult \"llama_index.evaluation.retrieval.base.RetrievalEvalResult\")\\][\uf0c1](#llama_index.evaluation.RetrieverEvaluator.aevaluate_dataset \"Permalink to this definition\")\n\nRun evaluation with dataset.\n\n_classmethod_ construct(_\\_fields\\_set: Optional\\[SetStr\\] \\= None_, _\\*\\*values: Any_) \u2192 Model[\uf0c1](#llama_index.evaluation.RetrieverEvaluator.construct \"Permalink to this definition\")\n\nCreates a new model setting \\_\\_dict\\_\\_ and \\_\\_fields\\_set\\_\\_ from trusted or pre-validated data. Default values are respected, but no other validation is performed. Behaves as if Config.extra = \u2018allow\u2019 was set since it adds all passed values\n\ncopy(_\\*_, _include: Optional\\[Union\\[AbstractSetIntStr, MappingIntStrAny\\]\\] \\= None_, _exclude: Optional\\[Union\\[AbstractSetIntStr, MappingIntStrAny\\]\\] \\= None_, _update: Optional\\[DictStrAny\\] \\= None_, _deep: bool \\= False_) \u2192 Model[\uf0c1](#llama_index.evaluation.RetrieverEvaluator.copy \"Permalink to this definition\")\n\nDuplicate a model, optionally choose which fields to include, exclude and change.\n\nParameters\n\n*   **include** \u2013 fields to include in new model\n    \n*   **exclude** \u2013 fields to exclude from new model, as with values this takes precedence over include\n    \n*   **update** \u2013 values to change/add in the new model. Note: the data is not validated before creating the new model: you should trust this data\n    \n*   **deep** \u2013 set to True to make a deep copy of the model\n    \n\nReturns\n\nnew model instance\n\ndict(_\\*_, _include: Optional\\[Union\\[AbstractSetIntStr, MappingIntStrAny\\]\\] \\= None_, _exclude: Optional\\[Union\\[AbstractSetIntStr, MappingIntStrAny\\]\\] \\= None_, _by\\_alias: bool \\= False_, _skip\\_defaults: Optional\\[bool\\] \\= None_, _exclude\\_unset: bool \\= False_, _exclude\\_defaults: bool \\= False_, _exclude\\_none: bool \\= False_) \u2192 DictStrAny[\uf0c1](#llama_index.evaluation.RetrieverEvaluator.dict \"Permalink to this definition\")\n\nGenerate a dictionary representation of the model, optionally specifying which fields to include or exclude.\n\nevaluate(_query: str_, _expected\\_ids: List\\[str\\]_, _\\*\\*kwargs: Any_) \u2192 [RetrievalEvalResult](#llama_index.evaluation.RetrievalEvalResult \"llama_index.evaluation.retrieval.base.RetrievalEvalResult\")[\uf0c1](#llama_index.evaluation.RetrieverEvaluator.evaluate \"Permalink to this definition\")\n\nRun evaluation results with query string and expected ids.\n\nParameters\n\n*   **query** (_str_) \u2013 Query string\n    \n*   **expected\\_ids** (_List__\\[__str__\\]_) \u2013 Expected ids\n    \n\nReturns\n\nEvaluation result\n\nReturn type\n\n[RetrievalEvalResult](#llama_index.evaluation.RetrievalEvalResult \"llama_index.evaluation.RetrievalEvalResult\")\n\n_classmethod_ from\\_metric\\_names(_metric\\_names: List\\[str\\]_, _\\*\\*kwargs: Any_) \u2192 [BaseRetrievalEvaluator](#llama_index.evaluation.BaseRetrievalEvaluator \"llama_index.evaluation.retrieval.base.BaseRetrievalEvaluator\")[\uf0c1](#llama_index.evaluation.RetrieverEvaluator.from_metric_names \"Permalink to this definition\")\n\nCreate evaluator from metric names.\n\nParameters\n\n*   **metric\\_names** (_List__\\[__str__\\]_) \u2013 List of metric names\n    \n*   **\\*\\*kwargs** \u2013 Additional arguments for the evaluator\n    \n\n_classmethod_ from\\_orm(_obj: Any_) \u2192 Model[\uf0c1](#llama_index.evaluation.RetrieverEvaluator.from_orm \"Permalink to this definition\")\n\njson(_\\*_, _include: Optional\\[Union\\[AbstractSetIntStr, MappingIntStrAny\\]\\] \\= None_, _exclude: Optional\\[Union\\[AbstractSetIntStr, MappingIntStrAny\\]\\] \\= None_, _by\\_alias: bool \\= False_, _skip\\_defaults: Optional\\[bool\\] \\= None_, _exclude\\_unset: bool \\= False_, _exclude\\_defaults: bool \\= False_, _exclude\\_none: bool \\= False_, _encoder: Optional\\[Callable\\[\\[Any\\], Any\\]\\] \\= None_, _models\\_as\\_dict: bool \\= True_, _\\*\\*dumps\\_kwargs: Any_) \u2192 unicode[\uf0c1](#llama_index.evaluation.RetrieverEvaluator.json \"Permalink to this definition\")\n\nGenerate a JSON representation of the model, include and exclude arguments as per dict().\n\nencoder is an optional function to supply as default to json.dumps(), other arguments as per json.dumps().\n\n_classmethod_ parse\\_file(_path: Union\\[str, Path\\]_, _\\*_, _content\\_type: unicode \\= None_, _encoding: unicode \\= 'utf8'_, _proto: Protocol \\= None_, _allow\\_pickle: bool \\= False_) \u2192 Model[\uf0c1](#llama_index.evaluation.RetrieverEvaluator.parse_file \"Permalink to this definition\")\n\n_classmethod_ parse\\_obj(_obj: Any_) \u2192 Model[\uf0c1](#llama_index.evaluation.RetrieverEvaluator.parse_obj \"Permalink to this definition\")\n\n_classmethod_ parse\\_raw(_b: Union\\[str, bytes\\]_, _\\*_, _content\\_type: unicode \\= None_, _encoding: unicode \\= 'utf8'_, _proto: Protocol \\= None_, _allow\\_pickle: bool \\= False_) \u2192 Model[\uf0c1](#llama_index.evaluation.RetrieverEvaluator.parse_raw \"Permalink to this definition\")\n\n_classmethod_ schema(_by\\_alias: bool \\= True_, _ref\\_template: unicode \\= '#/definitions/{model}'_) \u2192 DictStrAny[\uf0c1](#llama_index.evaluation.RetrieverEvaluator.schema \"Permalink to this definition\")\n\n_classmethod_ schema\\_json(_\\*_, _by\\_alias: bool \\= True_, _ref\\_template: unicode \\= '#/definitions/{model}'_, _\\*\\*dumps\\_kwargs: Any_) \u2192 unicode[\uf0c1](#llama_index.evaluation.RetrieverEvaluator.schema_json \"Permalink to this definition\")\n\n_classmethod_ update\\_forward\\_refs(_\\*\\*localns: Any_) \u2192 None[\uf0c1](#llama_index.evaluation.RetrieverEvaluator.update_forward_refs \"Permalink to this definition\")\n\nTry to update ForwardRefs on fields based on this Model, globalns and localns.\n\n_classmethod_ validate(_value: Any_) \u2192 Model[\uf0c1](#llama_index.evaluation.RetrieverEvaluator.validate \"Permalink to this definition\")\n\n_class_ llama\\_index.evaluation.SemanticSimilarityEvaluator(_service\\_context: Optional\\[[ServiceContext](https://docs.llamaindex.ai/en/stable/api_reference/service_context.html#llama_index.indices.service_context.ServiceContext \"llama_index.indices.service_context.ServiceContext\")\\] \\= None_, _similarity\\_fn: Optional\\[Callable\\[\\[...\\], float\\]\\] \\= None_, _similarity\\_mode: Optional\\[SimilarityMode\\] \\= None_, _similarity\\_threshold: float \\= 0.8_)[\uf0c1](#llama_index.evaluation.SemanticSimilarityEvaluator \"Permalink to this definition\")\n\nEmbedding similarity evaluator.\n\nEvaluate the quality of a question answering system by comparing the similarity between embeddings of the generated answer and the reference answer.\n\nInspired by this paper: - Semantic Answer Similarity for Evaluating Question Answering Models\n\nParameters\n\n*   **service\\_context** (_Optional__\\[_[_ServiceContext_](https://docs.llamaindex.ai/en/stable/api_reference/service_context.html#llama_index.indices.service_context.ServiceContext \"llama_index.indices.service_context.ServiceContext\")_\\]_) \u2013 Service context.\n    \n*   **similarity\\_threshold** (_float_) \u2013 Embedding similarity threshold for \u201cpassing\u201d. Defaults to 0.8.\n    \n\n_async_ aevaluate(_query: Optional\\[str\\] \\= None_, _response: Optional\\[str\\] \\= None_, _contexts: Optional\\[Sequence\\[str\\]\\] \\= None_, _reference: Optional\\[str\\] \\= None_, _\\*\\*kwargs: Any_) \u2192 [EvaluationResult](#llama_index.evaluation.EvaluationResult \"llama_index.evaluation.base.EvaluationResult\")[\uf0c1](#llama_index.evaluation.SemanticSimilarityEvaluator.aevaluate \"Permalink to this definition\")\n\nRun evaluation with query string, retrieved contexts, and generated response string.\n\nSubclasses can override this method to provide custom evaluation logic and take in additional arguments.\n\n_async_ aevaluate\\_response(_query: Optional\\[str\\] \\= None_, _response: Optional\\[[Response](https://docs.llamaindex.ai/en/stable/api_reference/response.html#llama_index.response.schema.Response \"llama_index.response.schema.Response\")\\] \\= None_, _\\*\\*kwargs: Any_) \u2192 [EvaluationResult](#llama_index.evaluation.EvaluationResult \"llama_index.evaluation.base.EvaluationResult\")[\uf0c1](#llama_index.evaluation.SemanticSimilarityEvaluator.aevaluate_response \"Permalink to this definition\")\n\nRun evaluation with query string and generated Response object.\n\nSubclasses can override this method to provide custom evaluation logic and take in additional arguments.\n\nevaluate(_query: Optional\\[str\\] \\= None_, _response: Optional\\[str\\] \\= None_, _contexts: Optional\\[Sequence\\[str\\]\\] \\= None_, _\\*\\*kwargs: Any_) \u2192 [EvaluationResult](#llama_index.evaluation.EvaluationResult \"llama_index.evaluation.base.EvaluationResult\")[\uf0c1](#llama_index.evaluation.SemanticSimilarityEvaluator.evaluate \"Permalink to this definition\")\n\nRun evaluation with query string, retrieved contexts, and generated response string.\n\nSubclasses can override this method to provide custom evaluation logic and take in additional arguments.\n\nevaluate\\_response(_query: Optional\\[str\\] \\= None_, _response: Optional\\[[Response](https://docs.llamaindex.ai/en/stable/api_reference/response.html#llama_index.response.schema.Response \"llama_index.response.schema.Response\")\\] \\= None_, _\\*\\*kwargs: Any_) \u2192 [EvaluationResult](#llama_index.evaluation.EvaluationResult \"llama_index.evaluation.base.EvaluationResult\")[\uf0c1](#llama_index.evaluation.SemanticSimilarityEvaluator.evaluate_response \"Permalink to this definition\")\n\nRun evaluation with query string and generated Response object.\n\nSubclasses can override this method to provide custom evaluation logic and take in additional arguments.\n\nllama\\_index.evaluation.generate\\_qa\\_embedding\\_pairs(_nodes: List\\[TextNode\\]_, _llm: Optional\\[[LLM](https://docs.llamaindex.ai/en/stable/api_reference/llms.html#llama_index.llms.base.LLM \"llama_index.llms.base.LLM\")\\] \\= None_, _qa\\_generate\\_prompt\\_tmpl: str \\= 'Context information is below.\\\\n\\\\n---------------------\\\\n{context\\_str}\\\\n---------------------\\\\n\\\\nGiven the context information and not prior knowledge.\\\\ngenerate only questions based on the below query.\\\\n\\\\nYou are a Teacher/ Professor. Your task is to setup {num\\_questions\\_per\\_chunk} questions for an upcoming quiz/examination. The questions should be diverse in nature across the document. Restrict the questions to the context information provided.\"\\\\n'_, _num\\_questions\\_per\\_chunk: int \\= 2_) \u2192 [EmbeddingQAFinetuneDataset](https://docs.llamaindex.ai/en/stable/api_reference/finetuning.html#llama_index.finetuning.EmbeddingQAFinetuneDataset \"llama_index.finetuning.embeddings.common.EmbeddingQAFinetuneDataset\")[\uf0c1](#llama_index.evaluation.generate_qa_embedding_pairs \"Permalink to this definition\")\n\nGenerate examples given a set of nodes.\n\nllama\\_index.evaluation.generate\\_question\\_context\\_pairs(_nodes: List\\[TextNode\\]_, _llm: Optional\\[[LLM](https://docs.llamaindex.ai/en/stable/api_reference/llms.html#llama_index.llms.base.LLM \"llama_index.llms.base.LLM\")\\] \\= None_, _qa\\_generate\\_prompt\\_tmpl: str \\= 'Context information is below.\\\\n\\\\n---------------------\\\\n{context\\_str}\\\\n---------------------\\\\n\\\\nGiven the context information and not prior knowledge.\\\\ngenerate only questions based on the below query.\\\\n\\\\nYou are a Teacher/ Professor. Your task is to setup {num\\_questions\\_per\\_chunk} questions for an upcoming quiz/examination. The questions should be diverse in nature across the document. Restrict the questions to the context information provided.\"\\\\n'_, _num\\_questions\\_per\\_chunk: int \\= 2_) \u2192 [EmbeddingQAFinetuneDataset](https://docs.llamaindex.ai/en/stable/api_reference/finetuning.html#llama_index.finetuning.EmbeddingQAFinetuneDataset \"llama_index.finetuning.embeddings.common.EmbeddingQAFinetuneDataset\")[\uf0c1](#llama_index.evaluation.generate_question_context_pairs \"Permalink to this definition\")\n\nGenerate examples given a set of nodes.\n\nllama\\_index.evaluation.get\\_retrieval\\_results\\_df(_names: List\\[str\\]_, _results\\_arr: List\\[List\\[[RetrievalEvalResult](#llama_index.evaluation.RetrievalEvalResult \"llama_index.evaluation.retrieval.base.RetrievalEvalResult\")\\]\\]_, _metric\\_keys: Optional\\[List\\[str\\]\\] \\= None_) \u2192 DataFrame[\uf0c1](#llama_index.evaluation.get_retrieval_results_df \"Permalink to this definition\")\n\nDisplay retrieval results.\n\nllama\\_index.evaluation.resolve\\_metrics(_metrics: List\\[str\\]_) \u2192 List\\[BaseRetrievalMetric\\][\uf0c1](#llama_index.evaluation.resolve_metrics \"Permalink to this definition\")\n\nResolve metrics from list of metric names."
}