{
    "metadata": {
        "type": "web",
        "url": "https://docs.llamaindex.ai/en/stable/examples/node_postprocessor/MetadataReplacementDemo.html",
        "title": "Metadata Replacement + Node Sentence Window - LlamaIndex \ud83e\udd99 0.8.49",
        "description": null
    },
    "text": "In this notebook, we use the `SentenceWindowNodeParser` to parse documents into single sentences per node. Each node also contains a \u201cwindow\u201d with the sentences on either side of the node sentence.\n\nThen, during retrieval, before passing the retrieved sentences to the LLM, the single sentences are replaced with a window containing the surrounding sentences using the `MetadataReplacementNodePostProcessor`.\n\nThis is most useful for large documents/indexes, as it helps to retrieve more fine-grained details.\n\nBy default, the sentence window is 5 sentences on either side of the original sentence.\n\nIn this case, chunk size settings are not used, in favor of following the window settings.\n\n%load\\_ext autoreload\n%autoreload 2\n\n## Setup[\uf0c1](#setup \"Permalink to this heading\")\n\nos.environ\\[\"OPENAI\\_API\\_KEY\"\\] \\= \"sk-...\"\nopenai.api\\_key \\= os.environ\\[\"OPENAI\\_API\\_KEY\"\\]\n\nfrom llama\\_index import ServiceContext, set\\_global\\_service\\_context\nfrom llama\\_index.llms import OpenAI\nfrom llama\\_index.embeddings import OpenAIEmbedding, HuggingFaceEmbedding\nfrom llama\\_index.node\\_parser import SentenceWindowNodeParser, SimpleNodeParser\n\n\\# create the sentence window node parser w/ default settings\nnode\\_parser \\= SentenceWindowNodeParser.from\\_defaults(\n    window\\_size\\=3,\n    window\\_metadata\\_key\\=\"window\",\n    original\\_text\\_metadata\\_key\\=\"original\\_text\",\n)\nsimple\\_node\\_parser \\= SimpleNodeParser.from\\_defaults()\n\nllm \\= OpenAI(model\\=\"gpt-3.5-turbo\", temperature\\=0.1)\nembed\\_model \\= HuggingFaceEmbedding(\n    model\\_name\\=\"sentence-transformers/all-mpnet-base-v2\", max\\_length\\=512\n)\nctx \\= ServiceContext.from\\_defaults(\n    llm\\=llm,\n    embed\\_model\\=embed\\_model,\n    \\# node\\_parser=node\\_parser,\n)\n\n\\# if you wanted to use OpenAIEmbedding, we should also increase the batch size,\n\\# since it involves many more calls to the API\n\\# ctx = ServiceContext.from\\_defaults(llm=llm, embed\\_model=OpenAIEmbedding(embed\\_batch\\_size=50)), node\\_parser=node\\_parser)\n\n## Load Data, Build the Index[\uf0c1](#load-data-build-the-index \"Permalink to this heading\")\n\nIn this section, we load data and build the vector index.\n\n### Load Data[\uf0c1](#load-data \"Permalink to this heading\")\n\nHere, we build an index using chapter 3 of the recent IPCC climate report.\n\n!curl https://www..ch/report/ar6/wg2/downloads/report/IPCC\\_AR6\\_WGII\\_Chapter03.pdf \\--output IPCC\\_AR6\\_WGII\\_Chapter03.pdf\n\n  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n                                 Dload  Upload   Total   Spent    Left  Speed\n  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0curl: (6) Could not resolve host: www..ch\n\nfrom llama\\_index import SimpleDirectoryReader\n\ndocuments \\= SimpleDirectoryReader(\n    input\\_files\\=\\[\"./IPCC\\_AR6\\_WGII\\_Chapter03.pdf\"\\]\n).load\\_data()\n\n### Extract Nodes[\uf0c1](#extract-nodes \"Permalink to this heading\")\n\nWe extract out the set of nodes that will be stored in the VectorIndex. This includes both the nodes with the sentence window parser, as well as the \u201cbase\u201d nodes extracted using the standard parser.\n\nnodes \\= node\\_parser.get\\_nodes\\_from\\_documents(documents)\n\nbase\\_nodes \\= simple\\_node\\_parser.get\\_nodes\\_from\\_documents(documents)\n\n### Build the Indexes[\uf0c1](#build-the-indexes \"Permalink to this heading\")\n\nWe build both the sentence index, as well as the \u201cbase\u201d index (with default chunk sizes).\n\nfrom llama\\_index import VectorStoreIndex\n\nsentence\\_index \\= VectorStoreIndex(nodes, service\\_context\\=ctx)\n\nbase\\_index \\= VectorStoreIndex(base\\_nodes, service\\_context\\=ctx)\n\n## Querying[\uf0c1](#querying \"Permalink to this heading\")\n\n### With MetadataReplacementPostProcessor[\uf0c1](#with-metadatareplacementpostprocessor \"Permalink to this heading\")\n\nHere, we now use the `MetadataReplacementPostProcessor` to replace the sentence in each node with it\u2019s surrounding context.\n\nfrom llama\\_index.indices.postprocessor import MetadataReplacementPostProcessor\n\nquery\\_engine \\= sentence\\_index.as\\_query\\_engine(\n    similarity\\_top\\_k\\=2,\n    \\# the target key defaults to \\`window\\` to match the node\\_parser's default\n    node\\_postprocessors\\=\\[\n        MetadataReplacementPostProcessor(target\\_metadata\\_key\\=\"window\")\n    \\],\n)\nwindow\\_response \\= query\\_engine.query(\n    \"What are the concerns surrounding the AMOC?\"\n)\nprint(window\\_response)\n\nThere is low confidence in the quantification of Atlantic Meridional Overturning Circulation (AMOC) changes in the 20th century due to low agreement in quantitative reconstructed and simulated trends. Additionally, direct observational records since the mid-2000s remain too short to determine the relative contributions of internal variability, natural forcing, and anthropogenic forcing to AMOC change. However, it is very likely that AMOC will decline for all SSP scenarios over the 21st century, but it will not involve an abrupt collapse before 2100.\n\nWe can also check the original sentence that was retrieved for each node, as well as the actual window of sentences that was sent to the LLM.\n\nwindow \\= window\\_response.source\\_nodes\\[0\\].node.metadata\\[\"window\"\\]\nsentence \\= window\\_response.source\\_nodes\\[0\\].node.metadata\\[\"original\\_text\"\\]\n\nprint(f\"Window: {window}\")\nprint(\"------------------\")\nprint(f\"Original Sentence: {sentence}\")\n\nWindow: Nevertheless, projected future annual cumulative upwelling wind \nchanges at most locations and seasons remain within \u00b110\u201320% of \npresent-day values (medium confidence) (WGI AR6 Section\u00a0 9.2.3.5; \nFox-Kemper et\u00a0al., 2021).\n Continuous observation of the Atlantic meridional overturning \ncirculation (AMOC) has improved the understanding of its variability \n(Frajka-Williams et\u00a0 al., 2019), but there is low confidence in the \nquantification of AMOC changes in the 20th\u00a0century because of low \nagreement in quantitative reconstructed and simulated trends (WGI \nAR6 Sections\u00a02.3.3, 9.2.3.1; Fox-Kemper et\u00a0al., 2021; Gulev et\u00a0al., 2021). \n Direct observational records since the mid-2000s remain too short to \ndetermine the relative contributions of internal variability, natural \nforcing and anthropogenic forcing to AMOC change (high confidence) \n(WGI AR6 Sections\u00a02.3.3, 9.2.3.1; Fox-Kemper et\u00a0al., 2021; Gulev et\u00a0al., \n2021).  Over the 21st\u00a0century, AMOC will very likely decline for all SSP \nscenarios but will not involve an abrupt collapse before 2100 (WGI \nAR6 Sections\u00a04.3.2, 9.2.3.1; Fox-Kemper et\u00a0al., 2021; Lee et\u00a0al., 2021).\n 3.2.2.4 Sea Ice Changes\nSea ice is a key driver of polar marine life, hosting unique ecosystems \nand affecting diverse marine organisms and food webs through its \nimpact on light penetration and supplies of nutrients and organic \nmatter (Arrigo, 2014).  Since the late 1970s, Arctic sea ice area has \ndecreased for all months, with an estimated decrease of 2\u00a0million\u00a0km2 \n(or 25%) for summer sea ice (averaged for August, September and \nOctober) in 2010\u20132019 as compared with 1979\u20131988 (WGI AR6 \nSection\u00a09.3.1.1; Fox-Kemper et\u00a0al., 2021). \n------------------\nOriginal Sentence: Over the 21st\u00a0century, AMOC will very likely decline for all SSP \nscenarios but will not involve an abrupt collapse before 2100 (WGI \nAR6 Sections\u00a04.3.2, 9.2.3.1; Fox-Kemper et\u00a0al., 2021; Lee et\u00a0al., 2021).\n\n### Contrast with normal VectorStoreIndex[\uf0c1](#contrast-with-normal-vectorstoreindex \"Permalink to this heading\")\n\nquery\\_engine \\= base\\_index.as\\_query\\_engine(similarity\\_top\\_k\\=2)\nvector\\_response \\= query\\_engine.query(\n    \"What are the concerns surrounding the AMOC?\"\n)\nprint(vector\\_response)\n\nThe concerns surrounding the AMOC are not provided in the given context information.\n\nWell, that didn\u2019t work. Let\u2019s bump up the top k! This will be slower and use more tokens compared to the sentence window index.\n\nquery\\_engine \\= base\\_index.as\\_query\\_engine(similarity\\_top\\_k\\=5)\nvector\\_response \\= query\\_engine.query(\n    \"What are the concerns surrounding the AMOC?\"\n)\nprint(vector\\_response)\n\nThere are concerns surrounding the AMOC (Atlantic Meridional Overturning Circulation). The context information mentions that the AMOC will decline over the 21st century, with high confidence but low confidence for quantitative projections.\n\n## Analysis[\uf0c1](#analysis \"Permalink to this heading\")\n\nSo the `SentenceWindowNodeParser` + `MetadataReplacementNodePostProcessor` combo is the clear winner here. But why?\n\nEmbeddings at a sentence level seem to capture more fine-grained details, like the word `AMOC`.\n\nWe can also compare the retrieved chunks for each index!\n\nfor source\\_node in window\\_response.source\\_nodes:\n    print(source\\_node.node.metadata\\[\"original\\_text\"\\])\n    print(\"--------\")\n\nOver the 21st\u00a0century, AMOC will very likely decline for all SSP \nscenarios but will not involve an abrupt collapse before 2100 (WGI \nAR6 Sections\u00a04.3.2, 9.2.3.1; Fox-Kemper et\u00a0al., 2021; Lee et\u00a0al., 2021).\n\n--------\nDirect observational records since the mid-2000s remain too short to \ndetermine the relative contributions of internal variability, natural \nforcing and anthropogenic forcing to AMOC change (high confidence) \n(WGI AR6 Sections\u00a02.3.3, 9.2.3.1; Fox-Kemper et\u00a0al., 2021; Gulev et\u00a0al., \n2021). \n--------\n\nHere, we can see that the sentence window index easily retrieved two nodes that talk about AMOC. Remember, the embeddings are based purely on the original sentence here, but the LLM actually ends up reading the surrounding context as well!\n\nNow, let\u2019s try and disect why the naive vector index failed.\n\nfor node in vector\\_response.source\\_nodes:\n    print(\"AMOC mentioned?\", \"AMOC\" in node.node.text)\n    print(\"--------\")\n\nAMOC mentioned? False\n--------\nAMOC mentioned? False\n--------\nAMOC mentioned? True\n--------\nAMOC mentioned? False\n--------\nAMOC mentioned? False\n--------\n\nSo source node at index \\[2\\] mentions AMOC, but what did this text actually look like?\n\nprint(vector\\_response.source\\_nodes\\[2\\].node.text)\n\n2021; Gulev et\u00a0al. \n2021)The AMOC will decline over the 21st\u00a0century \n(high confidence, but low confidence for \nquantitative projections).4.3.2.3, 9.2.3 (Fox-Kemper \net\u00a0al. 2021; Lee et\u00a0al. \n2021)\nSea ice\nArctic sea ice \nchanges\u2018Current Arctic sea ice coverage levels are the \nlowest since at least 1850 for both annual mean \nand late-summer values (high confidence).\u20192.3.2.1, 9.3.1 (Fox-Kemper \net\u00a0al. 2021; Gulev et\u00a0al. \n2021)\u2018The Arctic will become practically ice-free in \nSeptember by the end of the 21st\u00a0century under \nSSP2-4.5, SSP3-7.0 and SSP5-8.5\\[\u2026\\](high \nconfidence).\u20194.3.2.1, 9.3.1 (Fox-Kemper \net\u00a0al. 2021; Lee et\u00a0al. \n2021)\nAntarctic sea ice \nchangesThere is no global significant trend in \nAntarctic sea ice area from 1979 to 2020 (high \nconfidence).2.3.2.1, 9.3.2 (Fox-Kemper \net\u00a0al. 2021; Gulev et\u00a0al. \n2021)There is low confidence in model simulations of \nfuture Antarctic sea ice.9.3.2 (Fox-Kemper et\u00a0al. \n2021)\nOcean chemistry\nChanges in salinityThe \u2018large-scale, near-surface salinity contrasts \nhave intensified since at least 1950 \\[\u2026\\] \n(virtually certain).\u20192.3.3.2, 9.2.2.2 \n(Fox-Kemper et\u00a0al. 2021; \nGulev et\u00a0al. 2021)\u2018Fresh ocean regions will continue to get fresher \nand salty ocean regions will continue to get \nsaltier in the 21st\u00a0century (medium confidence).\u20199.2.2.2 (Fox-Kemper et\u00a0al. \n2021)\nOcean acidificationOcean surface pH has declined globally over the \npast four decades (virtually certain).2.3.3.5, 5.3.2.2 (Canadell \net\u00a0al. 2021; Gulev et\u00a0al. \n2021)Ocean surface pH will continue to decrease \n\u2018through the 21st\u00a0century, except for the \nlower-emission scenarios SSP1-1.9 and SSP1-2.6 \n\\[\u2026\\] (high confidence).\u20194.3.2.5, 4.5.2.2, 5.3.4.1 \n(Lee et\u00a0al. 2021; Canadell \net\u00a0al. 2021)\nOcean \ndeoxygenationDeoxygenation has occurred in most open \nocean regions since the mid-20th\u00a0century (high \nconfidence).2.3.3.6, 5.3.3.2 (Canadell \net\u00a0al. 2021; Gulev et\u00a0al. \n2021)Subsurface oxygen content \u2018is projected to \ntransition to historically unprecedented condition \nwith decline over the 21st\u00a0century (medium \nconfidence).\u20195.3.3.2 (Canadell et\u00a0al. \n2021)\nChanges in nutrient \nconcentrationsNot assessed in WGI Not assessed in WGI\n\nSo AMOC is disuccsed, but sadly it is in the middle chunk. With LLMs, it is often observed that text in the middle of retrieved context is often ignored or less useful. A recent paper [\u201cLost in the Middle\u201d discusses this here](https://arxiv.org/abs/2307.03172).\n\n## \\[Optional\\] Evaluation[\uf0c1](#optional-evaluation \"Permalink to this heading\")\n\nWe more rigorously evaluate how well the sentence window retriever works compared to the base retriever.\n\nWe define/load an eval benchmark dataset and then run different evaluations over it.\n\n**WARNING**: This can be _expensive_, especially with GPT-4. Use caution and tune the sample size to fit your budget.\n\nfrom llama\\_index.evaluation import (\n    DatasetGenerator,\n    QueryResponseDataset,\n)\nfrom llama\\_index import ServiceContext\nfrom llama\\_index.llms import OpenAI\nimport nest\\_asyncio\nimport random\n\nnest\\_asyncio.apply()\n\nnum\\_nodes\\_eval \\= 30\n\\# there are 428 nodes total. Take the first 200 to generate questions (the back half of the doc is all references)\nsample\\_eval\\_nodes \\= random.sample(base\\_nodes\\[:200\\], num\\_nodes\\_eval)\n\\# NOTE: run this if the dataset isn't already saved\neval\\_service\\_context \\= ServiceContext.from\\_defaults(llm\\=OpenAI(model\\=\"gpt-4\"))\n\\# generate questions from the largest chunks (1024)\ndataset\\_generator \\= DatasetGenerator(\n    sample\\_eval\\_nodes,\n    service\\_context\\=eval\\_service\\_context,\n    show\\_progress\\=True,\n    num\\_questions\\_per\\_chunk\\=2,\n)\n\neval\\_dataset \\= await dataset\\_generator.agenerate\\_dataset\\_from\\_nodes()\n\neval\\_dataset.save\\_json(\"data/ipcc\\_eval\\_qr\\_dataset.json\")\n\n\\# optional\neval\\_dataset \\= QueryResponseDataset.from\\_json(\"data/ipcc\\_eval\\_qr\\_dataset.json\")\n\n### Compare Results[\uf0c1](#compare-results \"Permalink to this heading\")\n\nimport asyncio\nimport nest\\_asyncio\n\nnest\\_asyncio.apply()\n\nfrom llama\\_index.evaluation import (\n    CorrectnessEvaluator,\n    SemanticSimilarityEvaluator,\n    RelevancyEvaluator,\n    FaithfulnessEvaluator,\n    PairwiseComparisonEvaluator,\n)\n\nfrom collections import defaultdict\nimport pandas as pd\n\n\\# NOTE: can uncomment other evaluators\nevaluator\\_c \\= CorrectnessEvaluator(service\\_context\\=eval\\_service\\_context)\nevaluator\\_s \\= SemanticSimilarityEvaluator(service\\_context\\=eval\\_service\\_context)\nevaluator\\_r \\= RelevancyEvaluator(service\\_context\\=eval\\_service\\_context)\nevaluator\\_f \\= FaithfulnessEvaluator(service\\_context\\=eval\\_service\\_context)\n\\# pairwise\\_evaluator = PairwiseComparisonEvaluator(service\\_context=eval\\_service\\_context)\n\nfrom llama\\_index.evaluation.eval\\_utils import get\\_responses, get\\_results\\_df\nfrom llama\\_index.evaluation import BatchEvalRunner\n\nmax\\_samples \\= 30\n\neval\\_qs \\= eval\\_dataset.questions\nref\\_response\\_strs \\= \\[r for (\\_, r) in eval\\_dataset.qr\\_pairs\\]\n\n\\# resetup base query engine and sentence window query engine\n\\# base query engine\nbase\\_query\\_engine \\= base\\_index.as\\_query\\_engine(similarity\\_top\\_k\\=2)\n\\# sentence window query engine\nquery\\_engine \\= sentence\\_index.as\\_query\\_engine(\n    similarity\\_top\\_k\\=2,\n    \\# the target key defaults to \\`window\\` to match the node\\_parser's default\n    node\\_postprocessors\\=\\[\n        MetadataReplacementPostProcessor(target\\_metadata\\_key\\=\"window\")\n    \\],\n)\n\nimport numpy as np\n\nbase\\_pred\\_responses \\= get\\_responses(\n    eval\\_qs\\[:max\\_samples\\], base\\_query\\_engine, show\\_progress\\=True\n)\npred\\_responses \\= get\\_responses(\n    eval\\_qs\\[:max\\_samples\\], query\\_engine, show\\_progress\\=True\n)\n\npred\\_response\\_strs \\= \\[str(p) for p in pred\\_responses\\]\nbase\\_pred\\_response\\_strs \\= \\[str(p) for p in base\\_pred\\_responses\\]\n\nevaluator\\_dict \\= {\n    \"correctness\": evaluator\\_c,\n    \"faithfulness\": evaluator\\_f,\n    \"relevancy\": evaluator\\_r,\n    \"semantic\\_similarity\": evaluator\\_s,\n}\nbatch\\_runner \\= BatchEvalRunner(evaluator\\_dict, workers\\=2, show\\_progress\\=True)\n\nRun evaluations over faithfulness/semantic similarity.\n\neval\\_results \\= await batch\\_runner.aevaluate\\_responses(\n    queries\\=eval\\_qs\\[:max\\_samples\\],\n    responses\\=pred\\_responses\\[:max\\_samples\\],\n    reference\\=ref\\_response\\_strs\\[:max\\_samples\\],\n)\n\nbase\\_eval\\_results \\= await batch\\_runner.aevaluate\\_responses(\n    queries\\=eval\\_qs\\[:max\\_samples\\],\n    responses\\=base\\_pred\\_responses\\[:max\\_samples\\],\n    reference\\=ref\\_response\\_strs\\[:max\\_samples\\],\n)\n\nresults\\_df \\= get\\_results\\_df(\n    \\[eval\\_results, base\\_eval\\_results\\],\n    \\[\"Sentence Window Retriever\", \"Base Retriever\"\\],\n    \\[\"correctness\", \"relevancy\", \"faithfulness\", \"semantic\\_similarity\"\\],\n)\ndisplay(results\\_df)\n\n|     | names | correctness | relevancy | faithfulness | semantic\\_similarity |\n| --- | --- | --- | --- | --- | --- |\n| 0   | Sentence Window Retriever | 4.366667 | 0.933333 | 0.933333 | 0.959583 |\n| 1   | Base Retriever | 4.216667 | 0.900000 | 0.933333 | 0.958664 |"
}