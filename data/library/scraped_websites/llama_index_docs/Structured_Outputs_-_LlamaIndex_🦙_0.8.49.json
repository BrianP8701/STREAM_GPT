{
    "metadata": {
        "type": "web",
        "url": "https://docs.llamaindex.ai/en/stable/core_modules/query_modules/structured_outputs/root.html",
        "title": "Structured Outputs - LlamaIndex \ud83e\udd99 0.8.49",
        "description": null
    },
    "text": "[Back to top](#)\n\nToggle table of contents sidebar\n\n## Structured Outputs[\uf0c1](#structured-outputs \"Permalink to this heading\")\n\nThe ability of LLMs to produce structured outputs are important for downstream applications that rely on reliably parsing output values. LlamaIndex itself also relies on structured output in the following ways.\n\n*   **Document retrieval**: Many data structures within LlamaIndex rely on LLM calls with a specific schema for Document retrieval. For instance, the tree index expects LLM calls to be in the format \u201cANSWER: (number)\u201d.\n    \n*   **Response synthesis**: Users may expect that the final response contains some degree of structure (e.g. a JSON output, a formatted SQL query, etc.)\n    \n\nLlamaIndex provides a variety of modules enabling LLMs to produce outputs in a structured format. We provide modules at different levels of abstraction:\n\n*   **Output Parsers**: These are modules that operate before and after an LLM text completion endpoint. They are not used with LLM function calling endpoints (since those contain structured outputs out of the box).\n    \n*   **Pydantic Programs**: These are generic modules that map an input prompt to a structured output, represented by a Pydantic object. They may use function calling APIs or text completion APIs + output parsers. These can also be integrated with query engines.\n    \n*   **Pre-defined Pydantic Program**: We have pre-defined Pydantic programs that map inputs to specific output types (like dataframes).\n    \n\nSee the sections below for an overview of output parsers and Pydantic programs.\n\n## \ud83d\udd2c Anatomy of a Structured Output Function[\uf0c1](#anatomy-of-a-structured-output-function \"Permalink to this heading\")\n\nHere we describe the different components of an LLM-powered structured output function. The pipeline depends on whether you\u2019re using a **generic LLM text completion API** or an **LLM function calling API**.\n\n![](https://docs.llamaindex.ai/en/stable/_images/diagram1.png)\n\nWith generic completion APIs, the inputs and outputs are handled by text prompts. The output parser plays a role before and after the LLM call in ensuring structured outputs. Before the LLM call, the output parser can append format instructions to the prompt. After the LLM call, the output parser can parse the output to the specified instructions.\n\nWith function calling APIs, the output is inherently in a structured format, and the input can take in the signature of the desired object. The structured output just needs to be cast in the right object format (e.g. Pydantic).\n\n## Query Engine Modules[\uf0c1](#query-engine-modules \"Permalink to this heading\")\n\n*   [Query Engines + Pydantic Outputs](https://docs.llamaindex.ai/en/stable/core_modules/query_modules/structured_outputs/query_engine.html)\n    *   [Usage Pattern](https://docs.llamaindex.ai/en/stable/core_modules/query_modules/structured_outputs/query_engine.html#usage-pattern)\n    *   [Modules](https://docs.llamaindex.ai/en/stable/core_modules/query_modules/structured_outputs/query_engine.html#modules)\n\n## Output Parser Modules[\uf0c1](#output-parser-modules \"Permalink to this heading\")\n\n*   [Output Parsing](https://docs.llamaindex.ai/en/stable/core_modules/query_modules/structured_outputs/output_parser.html)\n    *   [Guardrails](https://docs.llamaindex.ai/en/stable/core_modules/query_modules/structured_outputs/output_parser.html#guardrails)\n    *   [Langchain](https://docs.llamaindex.ai/en/stable/core_modules/query_modules/structured_outputs/output_parser.html#langchain)\n    *   [Guides](https://docs.llamaindex.ai/en/stable/core_modules/query_modules/structured_outputs/output_parser.html#guides)\n\n## Pydantic Program Modules[\uf0c1](#pydantic-program-modules \"Permalink to this heading\")\n\n*   [Pydantic Program](https://docs.llamaindex.ai/en/stable/core_modules/query_modules/structured_outputs/pydantic_program.html)\n    *   [LLM Text Completion Pydantic Programs](https://docs.llamaindex.ai/en/stable/core_modules/query_modules/structured_outputs/pydantic_program.html#llm-text-completion-pydantic-programs)\n    *   [LLM Function Calling Pydantic Programs](https://docs.llamaindex.ai/en/stable/core_modules/query_modules/structured_outputs/pydantic_program.html#llm-function-calling-pydantic-programs)\n    *   [Prepackaged Pydantic Programs](https://docs.llamaindex.ai/en/stable/core_modules/query_modules/structured_outputs/pydantic_program.html#prepackaged-pydantic-programs)"
}