{
    "metadata": {
        "type": "web",
        "url": "https://docs.llamaindex.ai/en/stable/api_reference/llms/gradient_model_adapter.html",
        "title": "Gradient Model Adapter - LlamaIndex \ud83e\udd99 0.8.49",
        "description": null
    },
    "text": "[Back to top](#)\n\nToggle table of contents sidebar\n\n## Gradient Model Adapter[\uf0c1](#gradient-model-adapter \"Permalink to this heading\")\n\n_pydantic model_ llama\\_index.llms.gradient.GradientModelAdapterLLM[\uf0c1](#llama_index.llms.gradient.GradientModelAdapterLLM \"Permalink to this definition\")\n\nShow JSON schema\n\n{\n   \"title\": \"GradientModelAdapterLLM\",\n   \"description\": \"Simple abstract base class for custom LLMs.\\\\n\\\\nSubclasses must implement the \\`\\_\\_init\\_\\_\\`, \\`complete\\`,\\\\n    \\`stream\\_complete\\`, and \\`metadata\\` methods.\",\n   \"type\": \"object\",\n   \"properties\": {\n      \"callback\\_manager\": {\n         \"title\": \"Callback Manager\"\n      },\n      \"max\\_tokens\": {\n         \"title\": \"Max Tokens\",\n         \"description\": \"The number of tokens to generate.\",\n         \"exclusiveMinimum\": 0,\n         \"exclusiveMaximum\": 512,\n         \"type\": \"integer\"\n      },\n      \"access\\_token\": {\n         \"title\": \"Access Token\",\n         \"description\": \"The Gradient access token to use.\",\n         \"type\": \"string\"\n      },\n      \"host\": {\n         \"title\": \"Host\",\n         \"description\": \"The url of the Gradient service to access.\",\n         \"type\": \"string\"\n      },\n      \"workspace\\_id\": {\n         \"title\": \"Workspace Id\",\n         \"description\": \"The Gradient workspace id to use.\",\n         \"type\": \"string\"\n      },\n      \"model\\_adapter\\_id\": {\n         \"title\": \"Model Adapter Id\",\n         \"description\": \"The id of the model adapter to use.\",\n         \"type\": \"string\"\n      }\n   },\n   \"required\": \\[\n      \"model\\_adapter\\_id\"\n   \\]\n}\n\nConfig\n\n*   **arbitrary\\_types\\_allowed**: _bool = True_\n    \n\nFields\n\n*   [`access_token (Optional[str])`](#llama_index.llms.gradient.GradientModelAdapterLLM.access_token \"llama_index.llms.gradient.GradientModelAdapterLLM.access_token\")\n    \n*   `callback_manager (llama_index.callbacks.base.CallbackManager)`\n    \n*   [`host (Optional[str])`](#llama_index.llms.gradient.GradientModelAdapterLLM.host \"llama_index.llms.gradient.GradientModelAdapterLLM.host\")\n    \n*   [`max_tokens (Optional[int])`](#llama_index.llms.gradient.GradientModelAdapterLLM.max_tokens \"llama_index.llms.gradient.GradientModelAdapterLLM.max_tokens\")\n    \n*   [`model_adapter_id (str)`](#llama_index.llms.gradient.GradientModelAdapterLLM.model_adapter_id \"llama_index.llms.gradient.GradientModelAdapterLLM.model_adapter_id\")\n    \n*   [`workspace_id (Optional[str])`](#llama_index.llms.gradient.GradientModelAdapterLLM.workspace_id \"llama_index.llms.gradient.GradientModelAdapterLLM.workspace_id\")\n    \n\nValidators\n\n*   `_validate_callback_manager` \u00bb `callback_manager`\n    \n\n_field_ access\\_token_: Optional\\[str\\]_ _\\= None_[\uf0c1](#llama_index.llms.gradient.GradientModelAdapterLLM.access_token \"Permalink to this definition\")\n\nThe Gradient access token to use.\n\n_field_ host_: Optional\\[str\\]_ _\\= None_[\uf0c1](#llama_index.llms.gradient.GradientModelAdapterLLM.host \"Permalink to this definition\")\n\nThe url of the Gradient service to access.\n\n_field_ max\\_tokens_: Optional\\[int\\]_ _\\= None_[\uf0c1](#llama_index.llms.gradient.GradientModelAdapterLLM.max_tokens \"Permalink to this definition\")\n\nThe number of tokens to generate.\n\nConstraints\n\n*   **exclusiveMinimum** = 0\n    \n*   **exclusiveMaximum** = 512\n    \n\n_field_ model\\_adapter\\_id_: str_ _\\[Required\\]_[\uf0c1](#llama_index.llms.gradient.GradientModelAdapterLLM.model_adapter_id \"Permalink to this definition\")\n\nThe id of the model adapter to use.\n\n_field_ workspace\\_id_: Optional\\[str\\]_ _\\= None_[\uf0c1](#llama_index.llms.gradient.GradientModelAdapterLLM.workspace_id \"Permalink to this definition\")\n\nThe Gradient workspace id to use.\n\nclose() \u2192 None[\uf0c1](#llama_index.llms.gradient.GradientModelAdapterLLM.close \"Permalink to this definition\")\n\ncomplete(_\\*args: Any_, _\\*\\*kwargs: Any_) \u2192 Any[\uf0c1](#llama_index.llms.gradient.GradientModelAdapterLLM.complete \"Permalink to this definition\")\n\nCompletion endpoint for LLM.\n\nstream\\_complete(_prompt: str_, _\\*\\*kwargs: Any_) \u2192 Generator\\[[CompletionResponse](https://docs.llamaindex.ai/en/stable/api_reference/llms.html#llama_index.llms.base.CompletionResponse \"llama_index.llms.base.CompletionResponse\"), None, None\\][\uf0c1](#llama_index.llms.gradient.GradientModelAdapterLLM.stream_complete \"Permalink to this definition\")\n\nStreaming completion endpoint for LLM.\n\n_property_ metadata_: [LLMMetadata](https://docs.llamaindex.ai/en/stable/api_reference/llms.html#llama_index.llms.base.LLMMetadata \"llama_index.llms.base.LLMMetadata\")_[\uf0c1](#llama_index.llms.gradient.GradientModelAdapterLLM.metadata \"Permalink to this definition\")\n\nLLM metadata."
}