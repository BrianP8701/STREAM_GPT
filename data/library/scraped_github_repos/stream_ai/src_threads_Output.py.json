{
    "metadata": {
        "type": "repo",
        "path": "src/threads/Output.py"
    },
    "text": "'''\n    Output is responsible for displaying the video and saving the video.\n    \n    It also draws labels and boxes to help visualize the tracker and classification\n'''\nimport src.variables.global_vars as GV\nimport src.helpers.helper_functions as helpers\nimport src.helpers.drawing_functions as d\nimport src.helpers.preprocessing as preprocessing\nfrom src.threads.Analytics import Analytics\nimport queue\nimport cv2\n\nclass Output:\n    def __init__(self, display_video, display_fps, save_video, save_path, save_fps, resolution_percentage):\n        self.display_video = display_video\n        self.save_video = save_video\n        self.save_path = save_path\n        self.resolution_percentage = resolution_percentage\n        if save_video:\n            fourcc = cv2.VideoWriter_fourcc(*'mp4v') \n            self.out = cv2.VideoWriter(save_path, fourcc, save_fps, (int(3840*(resolution_percentage/100)), int(2160*(resolution_percentage/100))))\n        self.save_divisor = 30 / save_fps\n        self.display_divisor = 30 / display_fps\n        self.Analytics = Analytics()\n    \n    def start(self):\n        helpers.print_text('Analytics thread started', 'blue')\n        frame_index = 0\n        \n        # Main Loop until video is done\n        while True:\n            try:\n                raw_frame = GV.video_queue.get(timeout=10) # Unedited frame\n            except queue.Empty:\n                helpers.print_text('End of tracker', 'red')\n                break\n            \n            frame = raw_frame.copy() # Frame with boxes and labels\n            \n            # Draw boxes and labels\n            d.write_text_on_image(frame, f'Frame: {frame_index}', )\n            if self.can_draw_box(frame_index):\n                self.draw_tip_box(frame, frame_index)\n                line = self.draw_line(frame, frame_index)\n                extrusion_box_coords = self.draw_extrusion_box(frame, frame_index, line)\n                if self.infer(frame_index): \n                    # Preprocess and run MobileNet on image\n                    extrusion_img = self.get_recently_extruded_material(raw_frame, extrusion_box_coords)\n                    gmms_img = self.Analytics.apply_gmms(extrusion_img)\n                    transformed_img = self.Analytics.transform_img(gmms_img)\n                    extrusion_class = self.Analytics.get_extrusion_class(transformed_img)\n\n                    self.draw_extrusion_class(frame, extrusion_class)\n                    GV.data_queue.put((extrusion_img, gmms_img, extrusion_class, frame_index))\n                    GV.measure_speed_queue.put(frame_index)\n                    GV.measure_classification_queue.put([frame_index, extrusion_class])\n                \n            # Resize image for faster processing\n            if self.save_video or self.display_video:\n                frame = helpers.resize_image(frame, self.resolution_percentage)\n            # Display video\n            if self.display_video and frame_index % self.display_divisor == 0:\n                cv2.imshow('frame', frame)\n                if cv2.waitKey(1) & 0xFF == ord('q'):\n                    break\n            # Save video\n            if self.save_video and frame_index % self.save_divisor == 0:\n                self.out.write(frame)\n                \n            frame_index += 1\n            \n        if self.save_video: self.out.release()\n        cv2.destroyAllWindows\n        \n        helpers.print_text('Tracking done', 'red')\n        GV.tracking_done = True\n            \n    def can_draw_box(self, frame_index):\n        return (\n            GV.tracking and \n            len(GV.screen_predictions) > frame_index and \n            GV.screen_predictions[frame_index][0] != -1 and\n            len(GV.angles) > frame_index\n        )\n\n    def draw_line(self, frame, frame_index):\n        line = helpers.get_line(GV.screen_predictions[frame_index], GV.angles[frame_index]) \n        frame = d.draw_line(frame, line)\n        return line\n        \n    def draw_tip_box(self, frame, frame_index):\n        box = helpers.get_bounding_box(GV.screen_predictions[frame_index], 50)\n        frame = d.draw_return(frame, round(box[0]), round(box[1]), round(box[2]), round(box[3]), thickness=3)\n        return box\n    \n    def draw_extrusion_class(self, frame, extrusion_class):\n        frame = d.write_text_on_image(frame, extrusion_class, position=(500, 300), font_scale=5, thickness=6)\n        \n    def draw_extrusion_box(self, frame, frame_index, line):\n        box = helpers.crop_in_direction(GV.screen_predictions[frame_index], line, GV.angles[frame_index])\n        box = [round(box[0]), round(box[1]), round(box[2]), round(box[3])]\n        frame = d.draw_return(frame, box[0], box[1], box[2], box[3], color=(0, 255, 0), thickness=3)\n        return box\n    \n    def infer(self, frame_index):\n        return ((frame_index % self.display_divisor == 0 or \n                frame_index % self.save_divisor == 0) and\n                (abs(GV.angles[frame_index] + 90) >= 10) and\n                len(GV.video_queue.queue) < 2) # Only run inference when displaying or saving frame and when there is no backlog of frames\n        \n    def get_recently_extruded_material(self, raw_frame, extrusion_box_coords):\n        sub_img = helpers.crop_box_on_image(extrusion_box_coords, raw_frame)\n        return sub_img"
}