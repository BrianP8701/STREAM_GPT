{
    "metadata": {
        "type": "web",
        "url": "https://docs.llamaindex.ai/en/stable/core_modules/query_modules/query_engine/advanced/query_transformations.html",
        "title": "Query Transformations - LlamaIndex \ud83e\udd99 0.8.49",
        "description": null
    },
    "text": "[Back to top](#)\n\nToggle table of contents sidebar\n\n## Query Transformations[\uf0c1](#query-transformations \"Permalink to this heading\")\n\nLlamaIndex allows you to perform _query transformations_ over your index structures. Query transformations are modules that will convert a query into another query. They can be **single-step**, as in the transformation is run once before the query is executed against an index.\n\nThey can also be **multi-step**, as in:\n\n1.  The query is transformed, executed against an index,\n    \n2.  The response is retrieved.\n    \n3.  Subsequent queries are transformed/executed in a sequential fashion.\n    \n\nWe list some of our query transformations in more detail below.\n\n## Use Cases[\uf0c1](#use-cases \"Permalink to this heading\")\n\nQuery transformations have multiple use cases:\n\n*   Transforming an initial query into a form that can be more easily embedded (e.g. HyDE)\n    \n*   Transforming an initial query into a subquestion that can be more easily answered from the data (single-step query decomposition)\n    \n*   Breaking an initial query into multiple subquestions that can be more easily answered on their own. (multi-step query decomposition)\n    \n\n## HyDE (Hypothetical Document Embeddings)[\uf0c1](#hyde-hypothetical-document-embeddings \"Permalink to this heading\")\n\n[HyDE](http://boston.lti.cs.cmu.edu/luyug/HyDE/HyDE.pdf) is a technique where given a natural language query, a hypothetical document/answer is generated first. This hypothetical document is then used for embedding lookup rather than the raw query.\n\nTo use HyDE, an example code snippet is shown below.\n\nfrom llama\\_index import VectorStoreIndex, SimpleDirectoryReader\nfrom llama\\_index.indices.query.query\\_transform.base import HyDEQueryTransform\nfrom llama\\_index.query\\_engine.transform\\_query\\_engine import TransformQueryEngine\n\n\\# load documents, build index\ndocuments \\= SimpleDirectoryReader('../paul\\_graham\\_essay/data').load\\_data()\nindex \\= VectorStoreIndex(documents)\n\n\\# run query with HyDE query transform\nquery\\_str \\= \"what did paul graham do after going to RISD\"\nhyde \\= HyDEQueryTransform(include\\_original\\=True)\nquery\\_engine \\= index.as\\_query\\_engine()\nquery\\_engine \\= TransformQueryEngine(query\\_engine, query\\_transform\\=hyde)\nresponse \\= query\\_engine.query(query\\_str)\nprint(response)\n\nCheck out our [example notebook](https://github.com/jerryjliu/llama_index/blob/main/docs/examples/query_transformations/HyDEQueryTransformDemo.ipynb) for a full walkthrough.\n\n## Single-Step Query Decomposition[\uf0c1](#single-step-query-decomposition \"Permalink to this heading\")\n\nSome recent approaches (e.g. [self-ask](https://ofir.io/self-ask.pdf), [ReAct](https://arxiv.org/abs/2210.03629)) have suggested that LLM\u2019s perform better at answering complex questions when they break the question into smaller steps. We have found that this is true for queries that require knowledge augmentation as well.\n\nIf your query is complex, different parts of your knowledge base may answer different \u201csubqueries\u201d around the overall query.\n\nOur single-step query decomposition feature transforms a **complicated** question into a simpler one over the data collection to help provide a sub-answer to the original question.\n\nThis is especially helpful over a composed graph. Within a composed graph, a query can be routed to multiple subindexes, each representing a subset of the overall knowledge corpus. Query decomposition allows us to transform the query into a more suitable question over any given index.\n\nAn example image is shown below.\n\n![](https://docs.llamaindex.ai/en/stable/_images/single_step_diagram.png)\n\nHere\u2019s a corresponding example code snippet over a composed graph.\n\n\\# Setting: a summary index composed over multiple vector indices\n\\# llm\\_predictor\\_chatgpt corresponds to the ChatGPT LLM interface\nfrom llama\\_index.indices.query.query\\_transform.base import DecomposeQueryTransform\ndecompose\\_transform \\= DecomposeQueryTransform(\n    llm\\_predictor\\_chatgpt, verbose\\=True\n)\n\n\\# initialize indexes and graph\n...\n\n\\# configure retrievers\nvector\\_query\\_engine \\= vector\\_index.as\\_query\\_engine()\nvector\\_query\\_engine \\= TransformQueryEngine(\n    vector\\_query\\_engine,\n    query\\_transform\\=decompose\\_transform\n    transform\\_extra\\_info\\={'index\\_summary': vector\\_index.index\\_struct.summary}\n)\ncustom\\_query\\_engines \\= {\n    vector\\_index.index\\_id: vector\\_query\\_engine\n}\n\n\\# query\nquery\\_str \\= (\n    \"Compare and contrast the airports in Seattle, Houston, and Toronto. \"\n)\nquery\\_engine \\= graph.as\\_query\\_engine(custom\\_query\\_engines\\=custom\\_query\\_engines)\nresponse \\= query\\_engine.query(query\\_str)\n\nCheck out our [example notebook](https://github.com/jerryjliu/llama_index/blob/main/docs/examples/composable_indices/city_analysis/City_Analysis-Decompose.ipynb) for a full walkthrough.\n\n## Multi-Step Query Transformations[\uf0c1](#multi-step-query-transformations \"Permalink to this heading\")\n\nMulti-step query transformations are a generalization on top of existing single-step query transformation approaches.\n\nGiven an initial, complex query, the query is transformed and executed against an index. The response is retrieved from the query. Given the response (along with prior responses) and the query, followup questions may be asked against the index as well. This technique allows a query to be run against a single knowledge source until that query has satisfied all questions.\n\nAn example image is shown below.\n\n![](https://docs.llamaindex.ai/en/stable/_images/multi_step_diagram.png)\n\nHere\u2019s a corresponding example code snippet.\n\nfrom llama\\_index.indices.query.query\\_transform.base import StepDecomposeQueryTransform\n\\# gpt-4\nstep\\_decompose\\_transform \\= StepDecomposeQueryTransform(\n    llm\\_predictor, verbose\\=True\n)\n\nquery\\_engine \\= index.as\\_query\\_engine()\nquery\\_engine \\= MultiStepQueryEngine(query\\_engine, query\\_transform\\=step\\_decompose\\_transform)\n\nresponse \\= query\\_engine.query(\n    \"Who was in the first batch of the accelerator program the author started?\",\n)\nprint(str(response))\n\nCheck out our [example notebook](https://github.com/jerryjliu/llama_index/blob/main/examples/vector_indices/SimpleIndexDemo-multistep.ipynb) for a full walkthrough."
}