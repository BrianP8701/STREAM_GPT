{
    "metadata": {
        "type": "web",
        "url": "https://docs.llamaindex.ai/en/stable/examples/node_postprocessor/TimeWeightedPostprocessorDemo.html",
        "title": "Time-Weighted Rerank - LlamaIndex \ud83e\udd99 0.8.49",
        "description": null
    },
    "text": "[Back to top](#)\n\nToggle table of contents sidebar\n\n## Time-Weighted Rerank[\uf0c1](#time-weighted-rerank \"Permalink to this heading\")\n\nShowcase capabilities of time-weighted node postprocessor\n\nfrom llama\\_index import VectorStoreIndex, SimpleDirectoryReader, ServiceContext\nfrom llama\\_index.indices.postprocessor import (\n    TimeWeightedPostprocessor,\n)\nfrom llama\\_index.node\\_parser import SimpleNodeParser\nfrom llama\\_index.storage.docstore import SimpleDocumentStore\nfrom llama\\_index.response.notebook\\_utils import display\\_response\nfrom datetime import datetime, timedelta\n\n/home/loganm/miniconda3/envs/llama-index/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user\\_install.html\n  from .autonotebook import tqdm as notebook\\_tqdm\n\n## Parse Documents into Nodes, add to Docstore[\uf0c1](#parse-documents-into-nodes-add-to-docstore \"Permalink to this heading\")\n\nIn this example, there are 3 different versions of PG\u2019s essay. They are largely identical **except** for one specific section, which details the amount of funding they raised for Viaweb.\n\nV1: 50k, V2: 30k, V3: 10K\n\nV1: -1 day, V2: -2 days, V3: -3 days\n\nThe idea is to encourage index to fetch the most recent info (which is V3)\n\n\\# load documents\nfrom llama\\_index.storage.storage\\_context import StorageContext\n\nnow \\= datetime.now()\nkey \\= \"\\_\\_last\\_accessed\\_\\_\"\n\ndoc1 \\= SimpleDirectoryReader(\n    input\\_files\\=\\[\"./test\\_versioned\\_data/paul\\_graham\\_essay\\_v1.txt\"\\]\n).load\\_data()\\[0\\]\n\ndoc2 \\= SimpleDirectoryReader(\n    input\\_files\\=\\[\"./test\\_versioned\\_data/paul\\_graham\\_essay\\_v2.txt\"\\]\n).load\\_data()\\[0\\]\n\ndoc3 \\= SimpleDirectoryReader(\n    input\\_files\\=\\[\"./test\\_versioned\\_data/paul\\_graham\\_essay\\_v3.txt\"\\]\n).load\\_data()\\[0\\]\n\n\\# define service context (wrapper container around current classes)\nservice\\_context \\= ServiceContext.from\\_defaults(chunk\\_size\\=512)\nnode\\_parser \\= service\\_context.node\\_parser\n\n\\# use node parser in service context to parse docs into nodes\nnodes1 \\= node\\_parser.get\\_nodes\\_from\\_documents(\\[doc1\\])\nnodes2 \\= node\\_parser.get\\_nodes\\_from\\_documents(\\[doc2\\])\nnodes3 \\= node\\_parser.get\\_nodes\\_from\\_documents(\\[doc3\\])\n\n\\# fetch the modified chunk from each document, set metadata\n\\# also exclude the date from being read by the LLM\nnodes1\\[14\\].metadata\\[key\\] \\= (now \\- timedelta(hours\\=3)).timestamp()\nnodes1\\[14\\].excluded\\_llm\\_metadata\\_keys \\= \\[key\\]\n\nnodes2\\[14\\].metadata\\[key\\] \\= (now \\- timedelta(hours\\=2)).timestamp()\nnodes2\\[14\\].excluded\\_llm\\_metadata\\_keys \\= \\[key\\]\n\nnodes3\\[14\\].metadata\\[key\\] \\= (now \\- timedelta(hours\\=1)).timestamp()\nnodes2\\[14\\].excluded\\_llm\\_metadata\\_keys \\= \\[key\\]\n\n\\# add to docstore\ndocstore \\= SimpleDocumentStore()\nnodes \\= \\[nodes1\\[14\\], nodes2\\[14\\], nodes3\\[14\\]\\]\ndocstore.add\\_documents(nodes)\n\nstorage\\_context \\= StorageContext.from\\_defaults(docstore\\=docstore)\n\n## Build Index[\uf0c1](#build-index \"Permalink to this heading\")\n\n\\# build index\nindex \\= VectorStoreIndex(nodes, storage\\_context\\=storage\\_context)\n\n## Define Recency Postprocessors[\uf0c1](#define-recency-postprocessors \"Permalink to this heading\")\n\nnode\\_postprocessor \\= TimeWeightedPostprocessor(\n    time\\_decay\\=0.5, time\\_access\\_refresh\\=False, top\\_k\\=1\n)\n\n## Query Index[\uf0c1](#query-index \"Permalink to this heading\")\n\n\\# naive query\nquery\\_engine \\= index.as\\_query\\_engine(\n    similarity\\_top\\_k\\=3,\n)\nresponse \\= query\\_engine.query(\n    \"How much did the author raise in seed funding from Idelle's husband\"\n    \" (Julian) for Viaweb?\",\n)\n\ndisplay\\_response(response)\n\n**`Final Response:`** $50,000\n\n\\# query using time weighted node postprocessor\n\nquery\\_engine \\= index.as\\_query\\_engine(\n    similarity\\_top\\_k\\=3, node\\_postprocessors\\=\\[node\\_postprocessor\\]\n)\nresponse \\= query\\_engine.query(\n    \"How much did the author raise in seed funding from Idelle's husband\"\n    \" (Julian) for Viaweb?\",\n)\n\ndisplay\\_response(response)\n\n**`Final Response:`** The author raised $10,000 in seed funding from Idelle\u2019s husband (Julian) for Viaweb.\n\n## Query Index (Lower-Level Usage)[\uf0c1](#query-index-lower-level-usage \"Permalink to this heading\")\n\nIn this example we first get the full set of nodes from a query call, and then send to node postprocessor, and then finally synthesize response through a summary index.\n\nfrom llama\\_index import SummaryIndex\n\nquery\\_str \\= (\n    \"How much did the author raise in seed funding from Idelle's husband\"\n    \" (Julian) for Viaweb?\"\n)\n\nquery\\_engine \\= index.as\\_query\\_engine(\n    similarity\\_top\\_k\\=3, response\\_mode\\=\"no\\_text\"\n)\ninit\\_response \\= query\\_engine.query(\n    query\\_str,\n)\nresp\\_nodes \\= \\[n for n in init\\_response.source\\_nodes\\]\n\n\\# get the post-processed nodes -- which should be the top-1 sorted by date\nnew\\_resp\\_nodes \\= node\\_postprocessor.postprocess\\_nodes(resp\\_nodes)\n\nsummary\\_index \\= SummaryIndex(\\[n.node for n in new\\_resp\\_nodes\\])\nquery\\_engine \\= summary\\_index.as\\_query\\_engine()\nresponse \\= query\\_engine.query(query\\_str)\n\ndisplay\\_response(response)\n\n**`Final Response:`** The author raised $10,000 in seed funding from Idelle\u2019s husband (Julian) for Viaweb."
}