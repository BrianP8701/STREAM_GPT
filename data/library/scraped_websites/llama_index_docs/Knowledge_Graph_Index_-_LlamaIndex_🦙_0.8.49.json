{
    "metadata": {
        "type": "web",
        "url": "https://docs.llamaindex.ai/en/stable/api_reference/indices/kg.html",
        "title": "Knowledge Graph Index - LlamaIndex \ud83e\udd99 0.8.49",
        "description": null
    },
    "text": "[Back to top](#)\n\nToggle table of contents sidebar\n\n## Knowledge Graph Index[\uf0c1](#knowledge-graph-index \"Permalink to this heading\")\n\nBuilding the Knowledge Graph Index\n\nKG-based data structures.\n\nllama\\_index.indices.knowledge\\_graph.GPTKnowledgeGraphIndex[\uf0c1](#llama_index.indices.knowledge_graph.GPTKnowledgeGraphIndex \"Permalink to this definition\")\n\nalias of [`KnowledgeGraphIndex`](#llama_index.indices.knowledge_graph.KnowledgeGraphIndex \"llama_index.indices.knowledge_graph.base.KnowledgeGraphIndex\")\n\n_class_ llama\\_index.indices.knowledge\\_graph.KGTableRetriever(_index: [KnowledgeGraphIndex](#llama_index.indices.knowledge_graph.KnowledgeGraphIndex \"llama_index.indices.knowledge_graph.base.KnowledgeGraphIndex\")_, _query\\_keyword\\_extract\\_template: Optional\\[[BasePromptTemplate](https://docs.llamaindex.ai/en/stable/api_reference/prompts.html#llama_index.prompts.base.BasePromptTemplate \"llama_index.prompts.base.BasePromptTemplate\")\\] \\= None_, _max\\_keywords\\_per\\_query: int \\= 10_, _num\\_chunks\\_per\\_query: int \\= 10_, _include\\_text: bool \\= True_, _retriever\\_mode: Optional\\[[KGRetrieverMode](https://docs.llamaindex.ai/en/stable/api_reference/query/retrievers/kg.html#llama_index.indices.knowledge_graph.retrievers.KGRetrieverMode \"llama_index.indices.knowledge_graph.retrievers.KGRetrieverMode\")\\] \\= KGRetrieverMode.KEYWORD_, _similarity\\_top\\_k: int \\= 2_, _graph\\_store\\_query\\_depth: int \\= 2_, _use\\_global\\_node\\_triplets: bool \\= False_, _max\\_knowledge\\_sequence: int \\= 30_, _\\*\\*kwargs: Any_)[\uf0c1](#llama_index.indices.knowledge_graph.KGTableRetriever \"Permalink to this definition\")\n\nKG Table Retriever.\n\nArguments are shared among subclasses.\n\nParameters\n\n*   **query\\_keyword\\_extract\\_template** (_Optional__\\[__QueryKGExtractPrompt__\\]_) \u2013 A Query KG Extraction Prompt (see [Prompt Templates](https://docs.llamaindex.ai/en/stable/api_reference/prompts.html#prompt-templates)).\n    \n*   **refine\\_template** (_Optional__\\[_[_BasePromptTemplate_](https://docs.llamaindex.ai/en/stable/api_reference/prompts.html#llama_index.prompts.base.BasePromptTemplate \"llama_index.prompts.base.BasePromptTemplate\")_\\]_) \u2013 A Refinement Prompt (see [Prompt Templates](https://docs.llamaindex.ai/en/stable/api_reference/prompts.html#prompt-templates)).\n    \n*   **text\\_qa\\_template** (_Optional__\\[_[_BasePromptTemplate_](https://docs.llamaindex.ai/en/stable/api_reference/prompts.html#llama_index.prompts.base.BasePromptTemplate \"llama_index.prompts.base.BasePromptTemplate\")_\\]_) \u2013 A Question Answering Prompt (see [Prompt Templates](https://docs.llamaindex.ai/en/stable/api_reference/prompts.html#prompt-templates)).\n    \n*   **max\\_keywords\\_per\\_query** (_int_) \u2013 Maximum number of keywords to extract from query.\n    \n*   **num\\_chunks\\_per\\_query** (_int_) \u2013 Maximum number of text chunks to query.\n    \n*   **include\\_text** (_bool_) \u2013 Use the document text source from each relevant triplet during queries.\n    \n*   **retriever\\_mode** ([_KGRetrieverMode_](https://docs.llamaindex.ai/en/stable/api_reference/query/retrievers/kg.html#llama_index.indices.knowledge_graph.retrievers.KGRetrieverMode \"llama_index.indices.knowledge_graph.retrievers.KGRetrieverMode\")) \u2013 Specifies whether to use keywords, embeddings, or both to find relevant triplets. Should be one of \u201ckeyword\u201d, \u201cembedding\u201d, or \u201chybrid\u201d.\n    \n*   **similarity\\_top\\_k** (_int_) \u2013 The number of top embeddings to use (if embeddings are used).\n    \n*   **graph\\_store\\_query\\_depth** (_int_) \u2013 The depth of the graph store query.\n    \n*   **use\\_global\\_node\\_triplets** (_bool_) \u2013 Whether to get more keywords(entities) from text chunks matched by keywords. This helps introduce more global knowledge. While it\u2019s more expensive, thus to be turned off by default.\n    \n*   **max\\_knowledge\\_sequence** (_int_) \u2013 The maximum number of knowledge sequence to include in the response. By default, it\u2019s 30.\n    \n\nget\\_service\\_context() \u2192 Optional\\[[ServiceContext](https://docs.llamaindex.ai/en/stable/api_reference/service_context.html#llama_index.indices.service_context.ServiceContext \"llama_index.indices.service_context.ServiceContext\")\\][\uf0c1](#llama_index.indices.knowledge_graph.KGTableRetriever.get_service_context \"Permalink to this definition\")\n\nAttempts to resolve a service context. Short-circuits at self.service\\_context, self.\\_service\\_context, or self.\\_index.service\\_context.\n\nretrieve(_str\\_or\\_query\\_bundle: Union\\[str, [QueryBundle](https://docs.llamaindex.ai/en/stable/api_reference/query/query_bundle.html#llama_index.indices.query.schema.QueryBundle \"llama_index.indices.query.schema.QueryBundle\")\\]_) \u2192 List\\[[NodeWithScore](https://docs.llamaindex.ai/en/stable/api_reference/node.html#llama_index.schema.NodeWithScore \"llama_index.schema.NodeWithScore\")\\][\uf0c1](#llama_index.indices.knowledge_graph.KGTableRetriever.retrieve \"Permalink to this definition\")\n\nRetrieve nodes given query.\n\nParameters\n\n**str\\_or\\_query\\_bundle** (_QueryType_) \u2013 Either a query string or a QueryBundle object.\n\n_class_ llama\\_index.indices.knowledge\\_graph.KnowledgeGraphIndex(_nodes: Optional\\[Sequence\\[[BaseNode](https://docs.llamaindex.ai/en/stable/api_reference/node.html#llama_index.schema.BaseNode \"llama_index.schema.BaseNode\")\\]\\] \\= None_, _index\\_struct: Optional\\[KG\\] \\= None_, _service\\_context: Optional\\[[ServiceContext](https://docs.llamaindex.ai/en/stable/api_reference/service_context.html#llama_index.indices.service_context.ServiceContext \"llama_index.indices.service_context.ServiceContext\")\\] \\= None_, _storage\\_context: Optional\\[[StorageContext](https://docs.llamaindex.ai/en/stable/api_reference/storage.html#llama_index.storage.storage_context.StorageContext \"llama_index.storage.storage_context.StorageContext\")\\] \\= None_, _kg\\_triple\\_extract\\_template: Optional\\[[BasePromptTemplate](https://docs.llamaindex.ai/en/stable/api_reference/prompts.html#llama_index.prompts.base.BasePromptTemplate \"llama_index.prompts.base.BasePromptTemplate\")\\] \\= None_, _max\\_triplets\\_per\\_chunk: int \\= 10_, _include\\_embeddings: bool \\= False_, _show\\_progress: bool \\= False_, _max\\_object\\_length: int \\= 128_, _kg\\_triplet\\_extract\\_fn: Optional\\[Callable\\] \\= None_, _\\*\\*kwargs: Any_)[\uf0c1](#llama_index.indices.knowledge_graph.KnowledgeGraphIndex \"Permalink to this definition\")\n\nKnowledge Graph Index.\n\nBuild a KG by extracting triplets, and leveraging the KG during query-time.\n\nParameters\n\n*   **kg\\_triple\\_extract\\_template** ([_BasePromptTemplate_](https://docs.llamaindex.ai/en/stable/api_reference/prompts.html#llama_index.prompts.base.BasePromptTemplate \"llama_index.prompts.base.BasePromptTemplate\")) \u2013 The prompt to use for extracting triplets.\n    \n*   **max\\_triplets\\_per\\_chunk** (_int_) \u2013 The maximum number of triplets to extract.\n    \n*   **service\\_context** (_Optional__\\[_[_ServiceContext_](https://docs.llamaindex.ai/en/stable/api_reference/service_context.html#llama_index.indices.service_context.ServiceContext \"llama_index.indices.service_context.ServiceContext\")_\\]_) \u2013 The service context to use.\n    \n*   **storage\\_context** (_Optional__\\[_[_StorageContext_](https://docs.llamaindex.ai/en/stable/api_reference/storage.html#llama_index.storage.storage_context.StorageContext \"llama_index.storage.storage_context.StorageContext\")_\\]_) \u2013 The storage context to use.\n    \n*   **graph\\_store** (_Optional__\\[__GraphStore__\\]_) \u2013 The graph store to use.\n    \n*   **show\\_progress** (_bool_) \u2013 Whether to show tqdm progress bars. Defaults to False.\n    \n*   **include\\_embeddings** (_bool_) \u2013 Whether to include embeddings in the index. Defaults to False.\n    \n*   **max\\_object\\_length** (_int_) \u2013 The maximum length of the object in a triplet. Defaults to 128.\n    \n*   **kg\\_triplet\\_extract\\_fn** (_Optional__\\[__Callable__\\]_) \u2013 The function to use for extracting triplets. Defaults to None.\n    \n\nadd\\_node(_keywords: List\\[str\\]_, _node: [BaseNode](https://docs.llamaindex.ai/en/stable/api_reference/node.html#llama_index.schema.BaseNode \"llama_index.schema.BaseNode\")_) \u2192 None[\uf0c1](#llama_index.indices.knowledge_graph.KnowledgeGraphIndex.add_node \"Permalink to this definition\")\n\nAdd node.\n\nUsed for manual insertion of nodes (keyed by keywords).\n\nParameters\n\n*   **keywords** (_List__\\[__str__\\]_) \u2013 Keywords to index the node.\n    \n*   **node** (_Node_) \u2013 Node to be indexed.\n    \n\nbuild\\_index\\_from\\_nodes(_nodes: Sequence\\[[BaseNode](https://docs.llamaindex.ai/en/stable/api_reference/node.html#llama_index.schema.BaseNode \"llama_index.schema.BaseNode\")\\]_) \u2192 IS[\uf0c1](#llama_index.indices.knowledge_graph.KnowledgeGraphIndex.build_index_from_nodes \"Permalink to this definition\")\n\nBuild the index from nodes.\n\ndelete\\_nodes(_node\\_ids: List\\[str\\]_, _delete\\_from\\_docstore: bool \\= False_, _\\*\\*delete\\_kwargs: Any_) \u2192 None[\uf0c1](#llama_index.indices.knowledge_graph.KnowledgeGraphIndex.delete_nodes \"Permalink to this definition\")\n\nDelete a list of nodes from the index.\n\nParameters\n\n**doc\\_ids** (_List__\\[__str__\\]_) \u2013 A list of doc\\_ids from the nodes to delete\n\ndelete\\_ref\\_doc(_ref\\_doc\\_id: str_, _delete\\_from\\_docstore: bool \\= False_, _\\*\\*delete\\_kwargs: Any_) \u2192 None[\uf0c1](#llama_index.indices.knowledge_graph.KnowledgeGraphIndex.delete_ref_doc \"Permalink to this definition\")\n\nDelete a document and it\u2019s nodes by using ref\\_doc\\_id.\n\n_classmethod_ from\\_documents(_documents: Sequence\\[[Document](https://docs.llamaindex.ai/en/stable/api_reference/node.html#llama_index.schema.Document \"llama_index.schema.Document\")\\]_, _storage\\_context: Optional\\[[StorageContext](https://docs.llamaindex.ai/en/stable/api_reference/storage.html#llama_index.storage.storage_context.StorageContext \"llama_index.storage.storage_context.StorageContext\")\\] \\= None_, _service\\_context: Optional\\[[ServiceContext](https://docs.llamaindex.ai/en/stable/api_reference/service_context.html#llama_index.indices.service_context.ServiceContext \"llama_index.indices.service_context.ServiceContext\")\\] \\= None_, _show\\_progress: bool \\= False_, _\\*\\*kwargs: Any_) \u2192 IndexType[\uf0c1](#llama_index.indices.knowledge_graph.KnowledgeGraphIndex.from_documents \"Permalink to this definition\")\n\nCreate index from documents.\n\nParameters\n\n**documents** (_Optional__\\[__Sequence__\\[__BaseDocument__\\]__\\]_) \u2013 List of documents to build the index from.\n\nget\\_networkx\\_graph(_limit: int \\= 100_) \u2192 Any[\uf0c1](#llama_index.indices.knowledge_graph.KnowledgeGraphIndex.get_networkx_graph \"Permalink to this definition\")\n\nGet networkx representation of the graph structure.\n\nParameters\n\n**limit** (_int_) \u2013 Number of starting nodes to be included in the graph.\n\nNOTE: This function requires networkx to be installed. NOTE: This is a beta feature.\n\n_property_ index\\_id_: str_[\uf0c1](#llama_index.indices.knowledge_graph.KnowledgeGraphIndex.index_id \"Permalink to this definition\")\n\nGet the index struct.\n\ninsert(_document: [Document](https://docs.llamaindex.ai/en/stable/api_reference/node.html#llama_index.schema.Document \"llama_index.schema.Document\")_, _\\*\\*insert\\_kwargs: Any_) \u2192 None[\uf0c1](#llama_index.indices.knowledge_graph.KnowledgeGraphIndex.insert \"Permalink to this definition\")\n\nInsert a document.\n\ninsert\\_nodes(_nodes: Sequence\\[[BaseNode](https://docs.llamaindex.ai/en/stable/api_reference/node.html#llama_index.schema.BaseNode \"llama_index.schema.BaseNode\")\\]_, _\\*\\*insert\\_kwargs: Any_) \u2192 None[\uf0c1](#llama_index.indices.knowledge_graph.KnowledgeGraphIndex.insert_nodes \"Permalink to this definition\")\n\nInsert nodes.\n\n_property_ ref\\_doc\\_info_: Dict\\[str, RefDocInfo\\]_[\uf0c1](#llama_index.indices.knowledge_graph.KnowledgeGraphIndex.ref_doc_info \"Permalink to this definition\")\n\nRetrieve a dict mapping of ingested documents and their nodes+metadata.\n\nrefresh(_documents: Sequence\\[[Document](https://docs.llamaindex.ai/en/stable/api_reference/node.html#llama_index.schema.Document \"llama_index.schema.Document\")\\]_, _\\*\\*update\\_kwargs: Any_) \u2192 List\\[bool\\][\uf0c1](#llama_index.indices.knowledge_graph.KnowledgeGraphIndex.refresh \"Permalink to this definition\")\n\nRefresh an index with documents that have changed.\n\nThis allows users to save LLM and Embedding model calls, while only updating documents that have any changes in text or metadata. It will also insert any documents that previously were not stored.\n\nrefresh\\_ref\\_docs(_documents: Sequence\\[[Document](https://docs.llamaindex.ai/en/stable/api_reference/node.html#llama_index.schema.Document \"llama_index.schema.Document\")\\]_, _\\*\\*update\\_kwargs: Any_) \u2192 List\\[bool\\][\uf0c1](#llama_index.indices.knowledge_graph.KnowledgeGraphIndex.refresh_ref_docs \"Permalink to this definition\")\n\nRefresh an index with documents that have changed.\n\nThis allows users to save LLM and Embedding model calls, while only updating documents that have any changes in text or metadata. It will also insert any documents that previously were not stored.\n\nset\\_index\\_id(_index\\_id: str_) \u2192 None[\uf0c1](#llama_index.indices.knowledge_graph.KnowledgeGraphIndex.set_index_id \"Permalink to this definition\")\n\nSet the index id.\n\nNOTE: if you decide to set the index\\_id on the index\\_struct manually, you will need to explicitly call add\\_index\\_struct on the index\\_store to update the index store.\n\nParameters\n\n**index\\_id** (_str_) \u2013 Index id to set.\n\nupdate(_document: [Document](https://docs.llamaindex.ai/en/stable/api_reference/node.html#llama_index.schema.Document \"llama_index.schema.Document\")_, _\\*\\*update\\_kwargs: Any_) \u2192 None[\uf0c1](#llama_index.indices.knowledge_graph.KnowledgeGraphIndex.update \"Permalink to this definition\")\n\nUpdate a document and it\u2019s corresponding nodes.\n\nThis is equivalent to deleting the document and then inserting it again.\n\nParameters\n\n*   **document** (_Union__\\[__BaseDocument__,_ [_BaseIndex_](https://docs.llamaindex.ai/en/stable/api_reference/indices.html#llama_index.indices.base.BaseIndex \"llama_index.indices.base.BaseIndex\")_\\]_) \u2013 document to update\n    \n*   **insert\\_kwargs** (_Dict_) \u2013 kwargs to pass to insert\n    \n*   **delete\\_kwargs** (_Dict_) \u2013 kwargs to pass to delete\n    \n\nupdate\\_ref\\_doc(_document: [Document](https://docs.llamaindex.ai/en/stable/api_reference/node.html#llama_index.schema.Document \"llama_index.schema.Document\")_, _\\*\\*update\\_kwargs: Any_) \u2192 None[\uf0c1](#llama_index.indices.knowledge_graph.KnowledgeGraphIndex.update_ref_doc \"Permalink to this definition\")\n\nUpdate a document and it\u2019s corresponding nodes.\n\nThis is equivalent to deleting the document and then inserting it again.\n\nParameters\n\n*   **document** (_Union__\\[__BaseDocument__,_ [_BaseIndex_](https://docs.llamaindex.ai/en/stable/api_reference/indices.html#llama_index.indices.base.BaseIndex \"llama_index.indices.base.BaseIndex\")_\\]_) \u2013 document to update\n    \n*   **insert\\_kwargs** (_Dict_) \u2013 kwargs to pass to insert\n    \n*   **delete\\_kwargs** (_Dict_) \u2013 kwargs to pass to delete\n    \n\nupsert\\_triplet(_triplet: Tuple\\[str, str, str\\]_) \u2192 None[\uf0c1](#llama_index.indices.knowledge_graph.KnowledgeGraphIndex.upsert_triplet \"Permalink to this definition\")\n\nInsert triplets.\n\nUsed for manual insertion of KG triplets (in the form of (subject, relationship, object)).\n\nParameters\n\n**triplet** (_str_) \u2013 Knowledge triplet\n\nupsert\\_triplet\\_and\\_node(_triplet: Tuple\\[str, str, str\\]_, _node: [BaseNode](https://docs.llamaindex.ai/en/stable/api_reference/node.html#llama_index.schema.BaseNode \"llama_index.schema.BaseNode\")_) \u2192 None[\uf0c1](#llama_index.indices.knowledge_graph.KnowledgeGraphIndex.upsert_triplet_and_node \"Permalink to this definition\")\n\nUpsert KG triplet and node.\n\nCalls both upsert\\_triplet and add\\_node. Behavior is idempotent; if Node already exists, only triplet will be added.\n\nParameters\n\n*   **keywords** (_List__\\[__str__\\]_) \u2013 Keywords to index the node.\n    \n*   **node** (_Node_) \u2013 Node to be indexed.\n    \n\n_class_ llama\\_index.indices.knowledge\\_graph.KnowledgeGraphRAGRetriever(_service\\_context: Optional\\[[ServiceContext](https://docs.llamaindex.ai/en/stable/api_reference/service_context.html#llama_index.indices.service_context.ServiceContext \"llama_index.indices.service_context.ServiceContext\")\\] \\= None_, _storage\\_context: Optional\\[[StorageContext](https://docs.llamaindex.ai/en/stable/api_reference/storage.html#llama_index.storage.storage_context.StorageContext \"llama_index.storage.storage_context.StorageContext\")\\] \\= None_, _entity\\_extract\\_fn: Optional\\[Callable\\] \\= None_, _entity\\_extract\\_template: Optional\\[[BasePromptTemplate](https://docs.llamaindex.ai/en/stable/api_reference/prompts.html#llama_index.prompts.base.BasePromptTemplate \"llama_index.prompts.base.BasePromptTemplate\")\\] \\= None_, _entity\\_extract\\_policy: Optional\\[str\\] \\= 'union'_, _synonym\\_expand\\_fn: Optional\\[Callable\\] \\= None_, _synonym\\_expand\\_template: Optional\\[[BasePromptTemplate](https://docs.llamaindex.ai/en/stable/api_reference/prompts.html#llama_index.prompts.base.BasePromptTemplate \"llama_index.prompts.base.BasePromptTemplate\")\\] \\= None_, _synonym\\_expand\\_policy: Optional\\[str\\] \\= 'union'_, _max\\_entities: int \\= 5_, _max\\_synonyms: int \\= 5_, _retriever\\_mode: Optional\\[str\\] \\= 'keyword'_, _with\\_nl2graphquery: bool \\= False_, _graph\\_traversal\\_depth: int \\= 2_, _max\\_knowledge\\_sequence: int \\= 30_, _verbose: bool \\= False_, _\\*\\*kwargs: Any_)[\uf0c1](#llama_index.indices.knowledge_graph.KnowledgeGraphRAGRetriever \"Permalink to this definition\")\n\nKnowledge Graph RAG retriever.\n\nRetriever that perform SubGraph RAG towards knowledge graph.\n\nParameters\n\n*   **service\\_context** (_Optional__\\[_[_ServiceContext_](https://docs.llamaindex.ai/en/stable/api_reference/service_context.html#llama_index.indices.service_context.ServiceContext \"llama_index.indices.service_context.ServiceContext\")_\\]_) \u2013 A service context to use.\n    \n*   **storage\\_context** (_Optional__\\[_[_StorageContext_](https://docs.llamaindex.ai/en/stable/api_reference/storage.html#llama_index.storage.storage_context.StorageContext \"llama_index.storage.storage_context.StorageContext\")_\\]_) \u2013 A storage context to use.\n    \n*   **entity\\_extract\\_fn** (_Optional__\\[__Callable__\\]_) \u2013 A function to extract entities.\n    \n*   **Optional****\\[****BasePromptTemplate****\\]****)** (_entity\\_extract\\_template_) \u2013 A Query Key Entity Extraction Prompt (see [Prompt Templates](https://docs.llamaindex.ai/en/stable/api_reference/prompts.html#prompt-templates)).\n    \n*   **entity\\_extract\\_policy** (_Optional__\\[__str__\\]_) \u2013 The entity extraction policy to use. default: \u201cunion\u201d possible values: \u201cunion\u201d, \u201cintersection\u201d\n    \n*   **synonym\\_expand\\_fn** (_Optional__\\[__Callable__\\]_) \u2013 A function to expand synonyms.\n    \n*   **synonym\\_expand\\_template** (_Optional__\\[__QueryKeywordExpandPrompt__\\]_) \u2013 A Query Key Entity Expansion Prompt (see [Prompt Templates](https://docs.llamaindex.ai/en/stable/api_reference/prompts.html#prompt-templates)).\n    \n*   **synonym\\_expand\\_policy** (_Optional__\\[__str__\\]_) \u2013 The synonym expansion policy to use. default: \u201cunion\u201d possible values: \u201cunion\u201d, \u201cintersection\u201d\n    \n*   **max\\_entities** (_int_) \u2013 The maximum number of entities to extract. default: 5\n    \n*   **max\\_synonyms** (_int_) \u2013 The maximum number of synonyms to expand per entity. default: 5\n    \n*   **retriever\\_mode** (_Optional__\\[__str__\\]_) \u2013 The retriever mode to use. default: \u201ckeyword\u201d possible values: \u201ckeyword\u201d, \u201cembedding\u201d, \u201ckeyword\\_embedding\u201d\n    \n*   **with\\_nl2graphquery** (_bool_) \u2013 Whether to combine NL2GraphQuery in context. default: False\n    \n*   **graph\\_traversal\\_depth** (_int_) \u2013 The depth of graph traversal. default: 2\n    \n*   **max\\_knowledge\\_sequence** (_int_) \u2013 The maximum number of knowledge sequence to include in the response. By default, it\u2019s 30.\n    \n*   **verbose** (_bool_) \u2013 Whether to print out debug info.\n    \n\nget\\_service\\_context() \u2192 Optional\\[[ServiceContext](https://docs.llamaindex.ai/en/stable/api_reference/service_context.html#llama_index.indices.service_context.ServiceContext \"llama_index.indices.service_context.ServiceContext\")\\][\uf0c1](#llama_index.indices.knowledge_graph.KnowledgeGraphRAGRetriever.get_service_context \"Permalink to this definition\")\n\nAttempts to resolve a service context. Short-circuits at self.service\\_context, self.\\_service\\_context, or self.\\_index.service\\_context.\n\nretrieve(_str\\_or\\_query\\_bundle: Union\\[str, [QueryBundle](https://docs.llamaindex.ai/en/stable/api_reference/query/query_bundle.html#llama_index.indices.query.schema.QueryBundle \"llama_index.indices.query.schema.QueryBundle\")\\]_) \u2192 List\\[[NodeWithScore](https://docs.llamaindex.ai/en/stable/api_reference/node.html#llama_index.schema.NodeWithScore \"llama_index.schema.NodeWithScore\")\\][\uf0c1](#llama_index.indices.knowledge_graph.KnowledgeGraphRAGRetriever.retrieve \"Permalink to this definition\")\n\nRetrieve nodes given query.\n\nParameters\n\n**str\\_or\\_query\\_bundle** (_QueryType_) \u2013 Either a query string or a QueryBundle object."
}