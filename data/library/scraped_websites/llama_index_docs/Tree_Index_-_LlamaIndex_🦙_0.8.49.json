{
    "metadata": {
        "type": "web",
        "url": "https://docs.llamaindex.ai/en/stable/api_reference/indices/tree.html",
        "title": "Tree Index - LlamaIndex \ud83e\udd99 0.8.49",
        "description": null
    },
    "text": "[Back to top](#)\n\nToggle table of contents sidebar\n\n## Tree Index[\uf0c1](#tree-index \"Permalink to this heading\")\n\nBuilding the Tree Index\n\nTree-structured Index Data Structures.\n\nllama\\_index.indices.tree.GPTTreeIndex[\uf0c1](#llama_index.indices.tree.GPTTreeIndex \"Permalink to this definition\")\n\nalias of [`TreeIndex`](#llama_index.indices.tree.TreeIndex \"llama_index.indices.tree.base.TreeIndex\")\n\n_class_ llama\\_index.indices.tree.TreeAllLeafRetriever(_index: [TreeIndex](#llama_index.indices.tree.TreeIndex \"llama_index.indices.tree.base.TreeIndex\")_, _\\*\\*kwargs: Any_)[\uf0c1](#llama_index.indices.tree.TreeAllLeafRetriever \"Permalink to this definition\")\n\nGPT all leaf retriever.\n\nThis class builds a query-specific tree from leaf nodes to return a response. Using this query mode means that the tree index doesn\u2019t need to be built when initialized, since we rebuild the tree for each query.\n\nParameters\n\n**text\\_qa\\_template** (_Optional__\\[_[_BasePromptTemplate_](https://docs.llamaindex.ai/en/stable/api_reference/prompts.html#llama_index.prompts.base.BasePromptTemplate \"llama_index.prompts.base.BasePromptTemplate\")_\\]_) \u2013 Question-Answer Prompt (see [Prompt Templates](https://docs.llamaindex.ai/en/stable/api_reference/prompts.html#prompt-templates)).\n\nget\\_service\\_context() \u2192 Optional\\[[ServiceContext](https://docs.llamaindex.ai/en/stable/api_reference/service_context.html#llama_index.indices.service_context.ServiceContext \"llama_index.indices.service_context.ServiceContext\")\\][\uf0c1](#llama_index.indices.tree.TreeAllLeafRetriever.get_service_context \"Permalink to this definition\")\n\nAttempts to resolve a service context. Short-circuits at self.service\\_context, self.\\_service\\_context, or self.\\_index.service\\_context.\n\nretrieve(_str\\_or\\_query\\_bundle: Union\\[str, [QueryBundle](https://docs.llamaindex.ai/en/stable/api_reference/query/query_bundle.html#llama_index.indices.query.schema.QueryBundle \"llama_index.indices.query.schema.QueryBundle\")\\]_) \u2192 List\\[[NodeWithScore](https://docs.llamaindex.ai/en/stable/api_reference/node.html#llama_index.schema.NodeWithScore \"llama_index.schema.NodeWithScore\")\\][\uf0c1](#llama_index.indices.tree.TreeAllLeafRetriever.retrieve \"Permalink to this definition\")\n\nRetrieve nodes given query.\n\nParameters\n\n**str\\_or\\_query\\_bundle** (_QueryType_) \u2013 Either a query string or a QueryBundle object.\n\n_class_ llama\\_index.indices.tree.TreeIndex(_nodes: Optional\\[Sequence\\[[BaseNode](https://docs.llamaindex.ai/en/stable/api_reference/node.html#llama_index.schema.BaseNode \"llama_index.schema.BaseNode\")\\]\\] \\= None_, _index\\_struct: Optional\\[IndexGraph\\] \\= None_, _service\\_context: Optional\\[[ServiceContext](https://docs.llamaindex.ai/en/stable/api_reference/service_context.html#llama_index.indices.service_context.ServiceContext \"llama_index.indices.service_context.ServiceContext\")\\] \\= None_, _summary\\_template: Optional\\[[BasePromptTemplate](https://docs.llamaindex.ai/en/stable/api_reference/prompts.html#llama_index.prompts.base.BasePromptTemplate \"llama_index.prompts.base.BasePromptTemplate\")\\] \\= None_, _insert\\_prompt: Optional\\[[BasePromptTemplate](https://docs.llamaindex.ai/en/stable/api_reference/prompts.html#llama_index.prompts.base.BasePromptTemplate \"llama_index.prompts.base.BasePromptTemplate\")\\] \\= None_, _num\\_children: int \\= 10_, _build\\_tree: bool \\= True_, _use\\_async: bool \\= False_, _show\\_progress: bool \\= False_, _\\*\\*kwargs: Any_)[\uf0c1](#llama_index.indices.tree.TreeIndex \"Permalink to this definition\")\n\nTree Index.\n\nThe tree index is a tree-structured index, where each node is a summary of the children nodes. During index construction, the tree is constructed in a bottoms-up fashion until we end up with a set of root\\_nodes.\n\nThere are a few different options during query time (see [Querying an Index](https://docs.llamaindex.ai/en/stable/api_reference/query.html#ref-query)). The main option is to traverse down the tree from the root nodes. A secondary answer is to directly synthesize the answer from the root nodes.\n\nParameters\n\n*   **summary\\_template** (_Optional__\\[_[_BasePromptTemplate_](https://docs.llamaindex.ai/en/stable/api_reference/prompts.html#llama_index.prompts.base.BasePromptTemplate \"llama_index.prompts.base.BasePromptTemplate\")_\\]_) \u2013 A Summarization Prompt (see [Prompt Templates](https://docs.llamaindex.ai/en/stable/api_reference/prompts.html#prompt-templates)).\n    \n*   **insert\\_prompt** (_Optional__\\[_[_BasePromptTemplate_](https://docs.llamaindex.ai/en/stable/api_reference/prompts.html#llama_index.prompts.base.BasePromptTemplate \"llama_index.prompts.base.BasePromptTemplate\")_\\]_) \u2013 An Tree Insertion Prompt (see [Prompt Templates](https://docs.llamaindex.ai/en/stable/api_reference/prompts.html#prompt-templates)).\n    \n*   **num\\_children** (_int_) \u2013 The number of children each node should have.\n    \n*   **build\\_tree** (_bool_) \u2013 Whether to build the tree during index construction.\n    \n*   **show\\_progress** (_bool_) \u2013 Whether to show progress bars. Defaults to False.\n    \n\nbuild\\_index\\_from\\_nodes(_nodes: Sequence\\[[BaseNode](https://docs.llamaindex.ai/en/stable/api_reference/node.html#llama_index.schema.BaseNode \"llama_index.schema.BaseNode\")\\]_) \u2192 IS[\uf0c1](#llama_index.indices.tree.TreeIndex.build_index_from_nodes \"Permalink to this definition\")\n\nBuild the index from nodes.\n\ndelete(_doc\\_id: str_, _\\*\\*delete\\_kwargs: Any_) \u2192 None[\uf0c1](#llama_index.indices.tree.TreeIndex.delete \"Permalink to this definition\")\n\nDelete a document from the index. All nodes in the index related to the index will be deleted.\n\nParameters\n\n**doc\\_id** (_str_) \u2013 A doc\\_id of the ingested document\n\ndelete\\_nodes(_node\\_ids: List\\[str\\]_, _delete\\_from\\_docstore: bool \\= False_, _\\*\\*delete\\_kwargs: Any_) \u2192 None[\uf0c1](#llama_index.indices.tree.TreeIndex.delete_nodes \"Permalink to this definition\")\n\nDelete a list of nodes from the index.\n\nParameters\n\n**doc\\_ids** (_List__\\[__str__\\]_) \u2013 A list of doc\\_ids from the nodes to delete\n\ndelete\\_ref\\_doc(_ref\\_doc\\_id: str_, _delete\\_from\\_docstore: bool \\= False_, _\\*\\*delete\\_kwargs: Any_) \u2192 None[\uf0c1](#llama_index.indices.tree.TreeIndex.delete_ref_doc \"Permalink to this definition\")\n\nDelete a document and it\u2019s nodes by using ref\\_doc\\_id.\n\n_property_ docstore_: [BaseDocumentStore](https://docs.llamaindex.ai/en/stable/api_reference/storage/docstore.html#llama_index.storage.docstore.BaseDocumentStore \"llama_index.storage.docstore.types.BaseDocumentStore\")_[\uf0c1](#llama_index.indices.tree.TreeIndex.docstore \"Permalink to this definition\")\n\nGet the docstore corresponding to the index.\n\n_classmethod_ from\\_documents(_documents: Sequence\\[[Document](https://docs.llamaindex.ai/en/stable/api_reference/node.html#llama_index.schema.Document \"llama_index.schema.Document\")\\]_, _storage\\_context: Optional\\[[StorageContext](https://docs.llamaindex.ai/en/stable/api_reference/storage.html#llama_index.storage.storage_context.StorageContext \"llama_index.storage.storage_context.StorageContext\")\\] \\= None_, _service\\_context: Optional\\[[ServiceContext](https://docs.llamaindex.ai/en/stable/api_reference/service_context.html#llama_index.indices.service_context.ServiceContext \"llama_index.indices.service_context.ServiceContext\")\\] \\= None_, _show\\_progress: bool \\= False_, _\\*\\*kwargs: Any_) \u2192 IndexType[\uf0c1](#llama_index.indices.tree.TreeIndex.from_documents \"Permalink to this definition\")\n\nCreate index from documents.\n\nParameters\n\n**documents** (_Optional__\\[__Sequence__\\[__BaseDocument__\\]__\\]_) \u2013 List of documents to build the index from.\n\n_property_ index\\_id_: str_[\uf0c1](#llama_index.indices.tree.TreeIndex.index_id \"Permalink to this definition\")\n\nGet the index struct.\n\n_property_ index\\_struct_: IS_[\uf0c1](#llama_index.indices.tree.TreeIndex.index_struct \"Permalink to this definition\")\n\nGet the index struct.\n\nindex\\_struct\\_cls[\uf0c1](#llama_index.indices.tree.TreeIndex.index_struct_cls \"Permalink to this definition\")\n\nalias of `IndexGraph`\n\ninsert(_document: [Document](https://docs.llamaindex.ai/en/stable/api_reference/node.html#llama_index.schema.Document \"llama_index.schema.Document\")_, _\\*\\*insert\\_kwargs: Any_) \u2192 None[\uf0c1](#llama_index.indices.tree.TreeIndex.insert \"Permalink to this definition\")\n\nInsert a document.\n\ninsert\\_nodes(_nodes: Sequence\\[[BaseNode](https://docs.llamaindex.ai/en/stable/api_reference/node.html#llama_index.schema.BaseNode \"llama_index.schema.BaseNode\")\\]_, _\\*\\*insert\\_kwargs: Any_) \u2192 None[\uf0c1](#llama_index.indices.tree.TreeIndex.insert_nodes \"Permalink to this definition\")\n\nInsert nodes.\n\n_property_ ref\\_doc\\_info_: Dict\\[str, RefDocInfo\\]_[\uf0c1](#llama_index.indices.tree.TreeIndex.ref_doc_info \"Permalink to this definition\")\n\nRetrieve a dict mapping of ingested documents and their nodes+metadata.\n\nrefresh(_documents: Sequence\\[[Document](https://docs.llamaindex.ai/en/stable/api_reference/node.html#llama_index.schema.Document \"llama_index.schema.Document\")\\]_, _\\*\\*update\\_kwargs: Any_) \u2192 List\\[bool\\][\uf0c1](#llama_index.indices.tree.TreeIndex.refresh \"Permalink to this definition\")\n\nRefresh an index with documents that have changed.\n\nThis allows users to save LLM and Embedding model calls, while only updating documents that have any changes in text or metadata. It will also insert any documents that previously were not stored.\n\nrefresh\\_ref\\_docs(_documents: Sequence\\[[Document](https://docs.llamaindex.ai/en/stable/api_reference/node.html#llama_index.schema.Document \"llama_index.schema.Document\")\\]_, _\\*\\*update\\_kwargs: Any_) \u2192 List\\[bool\\][\uf0c1](#llama_index.indices.tree.TreeIndex.refresh_ref_docs \"Permalink to this definition\")\n\nRefresh an index with documents that have changed.\n\nThis allows users to save LLM and Embedding model calls, while only updating documents that have any changes in text or metadata. It will also insert any documents that previously were not stored.\n\nset\\_index\\_id(_index\\_id: str_) \u2192 None[\uf0c1](#llama_index.indices.tree.TreeIndex.set_index_id \"Permalink to this definition\")\n\nSet the index id.\n\nNOTE: if you decide to set the index\\_id on the index\\_struct manually, you will need to explicitly call add\\_index\\_struct on the index\\_store to update the index store.\n\nParameters\n\n**index\\_id** (_str_) \u2013 Index id to set.\n\nupdate(_document: [Document](https://docs.llamaindex.ai/en/stable/api_reference/node.html#llama_index.schema.Document \"llama_index.schema.Document\")_, _\\*\\*update\\_kwargs: Any_) \u2192 None[\uf0c1](#llama_index.indices.tree.TreeIndex.update \"Permalink to this definition\")\n\nUpdate a document and it\u2019s corresponding nodes.\n\nThis is equivalent to deleting the document and then inserting it again.\n\nParameters\n\n*   **document** (_Union__\\[__BaseDocument__,_ [_BaseIndex_](https://docs.llamaindex.ai/en/stable/api_reference/indices.html#llama_index.indices.base.BaseIndex \"llama_index.indices.base.BaseIndex\")_\\]_) \u2013 document to update\n    \n*   **insert\\_kwargs** (_Dict_) \u2013 kwargs to pass to insert\n    \n*   **delete\\_kwargs** (_Dict_) \u2013 kwargs to pass to delete\n    \n\nupdate\\_ref\\_doc(_document: [Document](https://docs.llamaindex.ai/en/stable/api_reference/node.html#llama_index.schema.Document \"llama_index.schema.Document\")_, _\\*\\*update\\_kwargs: Any_) \u2192 None[\uf0c1](#llama_index.indices.tree.TreeIndex.update_ref_doc \"Permalink to this definition\")\n\nUpdate a document and it\u2019s corresponding nodes.\n\nThis is equivalent to deleting the document and then inserting it again.\n\nParameters\n\n*   **document** (_Union__\\[__BaseDocument__,_ [_BaseIndex_](https://docs.llamaindex.ai/en/stable/api_reference/indices.html#llama_index.indices.base.BaseIndex \"llama_index.indices.base.BaseIndex\")_\\]_) \u2013 document to update\n    \n*   **insert\\_kwargs** (_Dict_) \u2013 kwargs to pass to insert\n    \n*   **delete\\_kwargs** (_Dict_) \u2013 kwargs to pass to delete\n    \n\n_class_ llama\\_index.indices.tree.TreeRootRetriever(_index: [TreeIndex](#llama_index.indices.tree.TreeIndex \"llama_index.indices.tree.base.TreeIndex\")_, _\\*\\*kwargs: Any_)[\uf0c1](#llama_index.indices.tree.TreeRootRetriever \"Permalink to this definition\")\n\nTree root retriever.\n\nThis class directly retrieves the answer from the root nodes.\n\nUnlike GPTTreeIndexLeafQuery, this class assumes the graph already stores the answer (because it was constructed with a query\\_str), so it does not attempt to parse information down the graph in order to synthesize an answer.\n\nget\\_service\\_context() \u2192 Optional\\[[ServiceContext](https://docs.llamaindex.ai/en/stable/api_reference/service_context.html#llama_index.indices.service_context.ServiceContext \"llama_index.indices.service_context.ServiceContext\")\\][\uf0c1](#llama_index.indices.tree.TreeRootRetriever.get_service_context \"Permalink to this definition\")\n\nAttempts to resolve a service context. Short-circuits at self.service\\_context, self.\\_service\\_context, or self.\\_index.service\\_context.\n\nretrieve(_str\\_or\\_query\\_bundle: Union\\[str, [QueryBundle](https://docs.llamaindex.ai/en/stable/api_reference/query/query_bundle.html#llama_index.indices.query.schema.QueryBundle \"llama_index.indices.query.schema.QueryBundle\")\\]_) \u2192 List\\[[NodeWithScore](https://docs.llamaindex.ai/en/stable/api_reference/node.html#llama_index.schema.NodeWithScore \"llama_index.schema.NodeWithScore\")\\][\uf0c1](#llama_index.indices.tree.TreeRootRetriever.retrieve \"Permalink to this definition\")\n\nRetrieve nodes given query.\n\nParameters\n\n**str\\_or\\_query\\_bundle** (_QueryType_) \u2013 Either a query string or a QueryBundle object.\n\n_class_ llama\\_index.indices.tree.TreeSelectLeafEmbeddingRetriever(_index: [TreeIndex](#llama_index.indices.tree.TreeIndex \"llama_index.indices.tree.base.TreeIndex\")_, _query\\_template: Optional\\[[BasePromptTemplate](https://docs.llamaindex.ai/en/stable/api_reference/prompts.html#llama_index.prompts.base.BasePromptTemplate \"llama_index.prompts.base.BasePromptTemplate\")\\] \\= None_, _text\\_qa\\_template: Optional\\[[BasePromptTemplate](https://docs.llamaindex.ai/en/stable/api_reference/prompts.html#llama_index.prompts.base.BasePromptTemplate \"llama_index.prompts.base.BasePromptTemplate\")\\] \\= None_, _refine\\_template: Optional\\[[BasePromptTemplate](https://docs.llamaindex.ai/en/stable/api_reference/prompts.html#llama_index.prompts.base.BasePromptTemplate \"llama_index.prompts.base.BasePromptTemplate\")\\] \\= None_, _query\\_template\\_multiple: Optional\\[[BasePromptTemplate](https://docs.llamaindex.ai/en/stable/api_reference/prompts.html#llama_index.prompts.base.BasePromptTemplate \"llama_index.prompts.base.BasePromptTemplate\")\\] \\= None_, _child\\_branch\\_factor: int \\= 1_, _verbose: bool \\= False_, _\\*\\*kwargs: Any_)[\uf0c1](#llama_index.indices.tree.TreeSelectLeafEmbeddingRetriever \"Permalink to this definition\")\n\nTree select leaf embedding retriever.\n\nThis class traverses the index graph using the embedding similarity between the query and the node text.\n\nParameters\n\n*   **query\\_template** (_Optional__\\[_[_BasePromptTemplate_](https://docs.llamaindex.ai/en/stable/api_reference/prompts.html#llama_index.prompts.base.BasePromptTemplate \"llama_index.prompts.base.BasePromptTemplate\")_\\]_) \u2013 Tree Select Query Prompt (see [Prompt Templates](https://docs.llamaindex.ai/en/stable/api_reference/prompts.html#prompt-templates)).\n    \n*   **query\\_template\\_multiple** (_Optional__\\[_[_BasePromptTemplate_](https://docs.llamaindex.ai/en/stable/api_reference/prompts.html#llama_index.prompts.base.BasePromptTemplate \"llama_index.prompts.base.BasePromptTemplate\")_\\]_) \u2013 Tree Select Query Prompt (Multiple) (see [Prompt Templates](https://docs.llamaindex.ai/en/stable/api_reference/prompts.html#prompt-templates)).\n    \n*   **text\\_qa\\_template** (_Optional__\\[_[_BasePromptTemplate_](https://docs.llamaindex.ai/en/stable/api_reference/prompts.html#llama_index.prompts.base.BasePromptTemplate \"llama_index.prompts.base.BasePromptTemplate\")_\\]_) \u2013 Question-Answer Prompt (see [Prompt Templates](https://docs.llamaindex.ai/en/stable/api_reference/prompts.html#prompt-templates)).\n    \n*   **refine\\_template** (_Optional__\\[_[_BasePromptTemplate_](https://docs.llamaindex.ai/en/stable/api_reference/prompts.html#llama_index.prompts.base.BasePromptTemplate \"llama_index.prompts.base.BasePromptTemplate\")_\\]_) \u2013 Refinement Prompt (see [Prompt Templates](https://docs.llamaindex.ai/en/stable/api_reference/prompts.html#prompt-templates)).\n    \n*   **child\\_branch\\_factor** (_int_) \u2013 Number of child nodes to consider at each level. If child\\_branch\\_factor is 1, then the query will only choose one child node to traverse for any given parent node. If child\\_branch\\_factor is 2, then the query will choose two child nodes.\n    \n*   **embed\\_model** (_Optional__\\[__BaseEmbedding__\\]_) \u2013 Embedding model to use for embedding similarity.\n    \n\nget\\_service\\_context() \u2192 Optional\\[[ServiceContext](https://docs.llamaindex.ai/en/stable/api_reference/service_context.html#llama_index.indices.service_context.ServiceContext \"llama_index.indices.service_context.ServiceContext\")\\][\uf0c1](#llama_index.indices.tree.TreeSelectLeafEmbeddingRetriever.get_service_context \"Permalink to this definition\")\n\nAttempts to resolve a service context. Short-circuits at self.service\\_context, self.\\_service\\_context, or self.\\_index.service\\_context.\n\nretrieve(_str\\_or\\_query\\_bundle: Union\\[str, [QueryBundle](https://docs.llamaindex.ai/en/stable/api_reference/query/query_bundle.html#llama_index.indices.query.schema.QueryBundle \"llama_index.indices.query.schema.QueryBundle\")\\]_) \u2192 List\\[[NodeWithScore](https://docs.llamaindex.ai/en/stable/api_reference/node.html#llama_index.schema.NodeWithScore \"llama_index.schema.NodeWithScore\")\\][\uf0c1](#llama_index.indices.tree.TreeSelectLeafEmbeddingRetriever.retrieve \"Permalink to this definition\")\n\nRetrieve nodes given query.\n\nParameters\n\n**str\\_or\\_query\\_bundle** (_QueryType_) \u2013 Either a query string or a QueryBundle object.\n\n_class_ llama\\_index.indices.tree.TreeSelectLeafRetriever(_index: [TreeIndex](#llama_index.indices.tree.TreeIndex \"llama_index.indices.tree.base.TreeIndex\")_, _query\\_template: Optional\\[[BasePromptTemplate](https://docs.llamaindex.ai/en/stable/api_reference/prompts.html#llama_index.prompts.base.BasePromptTemplate \"llama_index.prompts.base.BasePromptTemplate\")\\] \\= None_, _text\\_qa\\_template: Optional\\[[BasePromptTemplate](https://docs.llamaindex.ai/en/stable/api_reference/prompts.html#llama_index.prompts.base.BasePromptTemplate \"llama_index.prompts.base.BasePromptTemplate\")\\] \\= None_, _refine\\_template: Optional\\[[BasePromptTemplate](https://docs.llamaindex.ai/en/stable/api_reference/prompts.html#llama_index.prompts.base.BasePromptTemplate \"llama_index.prompts.base.BasePromptTemplate\")\\] \\= None_, _query\\_template\\_multiple: Optional\\[[BasePromptTemplate](https://docs.llamaindex.ai/en/stable/api_reference/prompts.html#llama_index.prompts.base.BasePromptTemplate \"llama_index.prompts.base.BasePromptTemplate\")\\] \\= None_, _child\\_branch\\_factor: int \\= 1_, _verbose: bool \\= False_, _\\*\\*kwargs: Any_)[\uf0c1](#llama_index.indices.tree.TreeSelectLeafRetriever \"Permalink to this definition\")\n\nTree select leaf retriever.\n\nThis class traverses the index graph and searches for a leaf node that can best answer the query.\n\nParameters\n\n*   **query\\_template** (_Optional__\\[_[_BasePromptTemplate_](https://docs.llamaindex.ai/en/stable/api_reference/prompts.html#llama_index.prompts.base.BasePromptTemplate \"llama_index.prompts.base.BasePromptTemplate\")_\\]_) \u2013 Tree Select Query Prompt (see [Prompt Templates](https://docs.llamaindex.ai/en/stable/api_reference/prompts.html#prompt-templates)).\n    \n*   **query\\_template\\_multiple** (_Optional__\\[_[_BasePromptTemplate_](https://docs.llamaindex.ai/en/stable/api_reference/prompts.html#llama_index.prompts.base.BasePromptTemplate \"llama_index.prompts.base.BasePromptTemplate\")_\\]_) \u2013 Tree Select Query Prompt (Multiple) (see [Prompt Templates](https://docs.llamaindex.ai/en/stable/api_reference/prompts.html#prompt-templates)).\n    \n*   **child\\_branch\\_factor** (_int_) \u2013 Number of child nodes to consider at each level. If child\\_branch\\_factor is 1, then the query will only choose one child node to traverse for any given parent node. If child\\_branch\\_factor is 2, then the query will choose two child nodes.\n    \n\nget\\_service\\_context() \u2192 Optional\\[[ServiceContext](https://docs.llamaindex.ai/en/stable/api_reference/service_context.html#llama_index.indices.service_context.ServiceContext \"llama_index.indices.service_context.ServiceContext\")\\][\uf0c1](#llama_index.indices.tree.TreeSelectLeafRetriever.get_service_context \"Permalink to this definition\")\n\nAttempts to resolve a service context. Short-circuits at self.service\\_context, self.\\_service\\_context, or self.\\_index.service\\_context.\n\nretrieve(_str\\_or\\_query\\_bundle: Union\\[str, [QueryBundle](https://docs.llamaindex.ai/en/stable/api_reference/query/query_bundle.html#llama_index.indices.query.schema.QueryBundle \"llama_index.indices.query.schema.QueryBundle\")\\]_) \u2192 List\\[[NodeWithScore](https://docs.llamaindex.ai/en/stable/api_reference/node.html#llama_index.schema.NodeWithScore \"llama_index.schema.NodeWithScore\")\\][\uf0c1](#llama_index.indices.tree.TreeSelectLeafRetriever.retrieve \"Permalink to this definition\")\n\nRetrieve nodes given query.\n\nParameters\n\n**str\\_or\\_query\\_bundle** (_QueryType_) \u2013 Either a query string or a QueryBundle object."
}