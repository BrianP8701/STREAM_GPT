{
    "metadata": {
        "type": "web",
        "url": "https://docs.llamaindex.ai/en/stable/examples/vector_stores/ZepIndexDemo.html",
        "title": "Zep Vector Store - LlamaIndex \ud83e\udd99 0.8.49",
        "description": null
    },
    "text": "[Back to top](#)\n\nToggle table of contents sidebar\n\n## Zep Vector Store[\uf0c1](#zep-vector-store \"Permalink to this heading\")\n\n## A long-term memory store for LLM applications[\uf0c1](#a-long-term-memory-store-for-llm-applications \"Permalink to this heading\")\n\nThis notebook demonstrates how to use the Zep Vector Store with LlamaIndex.\n\n## About Zep[\uf0c1](#about-zep \"Permalink to this heading\")\n\nZep makes it easy for developers to add relevant documents, chat history memory & rich user data to their LLM app\u2019s prompts.\n\n## Note[\uf0c1](#note \"Permalink to this heading\")\n\nZep can automatically embed your documents. The LlamaIndex implementation of the Zep Vector Store utilizes LlamaIndex\u2019s embedders to do so.\n\n## Getting Started[\uf0c1](#getting-started \"Permalink to this heading\")\n\n**Quick Start Guide:** https://docs.getzep.com/deployment/quickstart/ **GitHub:** https://github.com/getzep/zep\n\n\\# !pip install zep-python\n\nimport logging\nimport sys\nfrom uuid import uuid4\n\nlogging.basicConfig(stream\\=sys.stdout, level\\=logging.INFO)\nlogging.getLogger().addHandler(logging.StreamHandler(stream\\=sys.stdout))\n\nimport os\nimport openai\nfrom dotenv import load\\_dotenv\n\nload\\_dotenv()\n\n\\# os.environ\\[\"OPENAI\\_API\\_KEY\"\\] = \"sk-...\"\nopenai.api\\_key \\= os.environ\\[\"OPENAI\\_API\\_KEY\"\\]\n\nfrom llama\\_index import VectorStoreIndex, SimpleDirectoryReader\nfrom llama\\_index.vector\\_stores.zep import ZepVectorStore\n\nINFO:numexpr.utils:NumExpr defaulting to 8 threads.\nNumExpr defaulting to 8 threads.\n\n\\# load documents\ndocuments \\= SimpleDirectoryReader(\"../data/paul\\_graham\").load\\_data()\n\n## Create a Zep Vector Store and Index[\uf0c1](#create-a-zep-vector-store-and-index \"Permalink to this heading\")\n\nYou can use an existing Zep Collection, or create a new one.\n\nfrom llama\\_index.storage.storage\\_context import StorageContext\n\nzep\\_api\\_url \\= \"http://localhost:8000\"\ncollection\\_name \\= f\"graham{uuid4().hex}\"\n\nvector\\_store \\= ZepVectorStore(\n    api\\_url\\=zep\\_api\\_url,\n    collection\\_name\\=collection\\_name,\n    embedding\\_dimensions\\=1536,\n)\n\nstorage\\_context \\= StorageContext.from\\_defaults(vector\\_store\\=vector\\_store)\n\nindex \\= VectorStoreIndex.from\\_documents(\n    documents, storage\\_context\\=storage\\_context\n)\n\nINFO:httpx:HTTP Request: GET http://localhost:8000/healthz \"HTTP/1.1 200 OK\"\nHTTP Request: GET http://localhost:8000/healthz \"HTTP/1.1 200 OK\"\nINFO:httpx:HTTP Request: GET http://localhost:8000/api/v1/collection/grahamfbf0c456a2ad46c2887a707ccc7bb5df \"HTTP/1.1 404 Not Found\"\nHTTP Request: GET http://localhost:8000/api/v1/collection/grahamfbf0c456a2ad46c2887a707ccc7bb5df \"HTTP/1.1 404 Not Found\"\nINFO:llama\\_index.vector\\_stores.zep:Collection grahamfbf0c456a2ad46c2887a707ccc7bb5df does not exist, will try creating one with dimensions=1536\nCollection grahamfbf0c456a2ad46c2887a707ccc7bb5df does not exist, will try creating one with dimensions=1536\nINFO:httpx:HTTP Request: POST http://localhost:8000/api/v1/collection/grahamfbf0c456a2ad46c2887a707ccc7bb5df \"HTTP/1.1 200 OK\"\nHTTP Request: POST http://localhost:8000/api/v1/collection/grahamfbf0c456a2ad46c2887a707ccc7bb5df \"HTTP/1.1 200 OK\"\nINFO:httpx:HTTP Request: GET http://localhost:8000/api/v1/collection/grahamfbf0c456a2ad46c2887a707ccc7bb5df \"HTTP/1.1 200 OK\"\nHTTP Request: GET http://localhost:8000/api/v1/collection/grahamfbf0c456a2ad46c2887a707ccc7bb5df \"HTTP/1.1 200 OK\"\nINFO:httpx:HTTP Request: POST http://localhost:8000/api/v1/collection/grahamfbf0c456a2ad46c2887a707ccc7bb5df/document \"HTTP/1.1 200 OK\"\nHTTP Request: POST http://localhost:8000/api/v1/collection/grahamfbf0c456a2ad46c2887a707ccc7bb5df/document \"HTTP/1.1 200 OK\"\n\nquery\\_engine \\= index.as\\_query\\_engine()\nresponse \\= query\\_engine.query(\"What did the author do growing up?\")\n\nprint(str(response))\n\nINFO:httpx:HTTP Request: POST http://localhost:8000/api/v1/collection/grahamfbf0c456a2ad46c2887a707ccc7bb5df/search?limit=2 \"HTTP/1.1 200 OK\"\nHTTP Request: POST http://localhost:8000/api/v1/collection/grahamfbf0c456a2ad46c2887a707ccc7bb5df/search?limit=2 \"HTTP/1.1 200 OK\"\nThe author worked on writing and programming outside of school before college. They wrote short stories and tried writing programs on an IBM 1401 computer using an early version of Fortran. They later got a microcomputer and started programming more extensively, writing simple games, a program to predict rocket heights, and a word processor. They initially planned to study philosophy in college but switched to AI. They also started publishing essays online and realized the potential of the web as a medium for publishing."
}