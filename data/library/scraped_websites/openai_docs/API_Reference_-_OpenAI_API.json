{
    "metadata": {
        "type": "web",
        "url": "https://platform.openai.com/docs/api-reference/images/create-variation",
        "title": "API Reference - OpenAI API",
        "description": "Explore resources, tutorials, API docs, and dynamic examples to get the most out of OpenAI's developer platform."
    },
    "text": "[](https://platform.openai.com/docs/api-reference/introduction)\n\n## [Introduction](https://platform.openai.com/docs/api-reference/introduction)\n\nYou can interact with the API through HTTP requests from any language, via our official Python bindings, our official Node.js library, or a [community-maintained library](https://platform.openai.com/docs/libraries/community-libraries).\n\nTo install the official Python bindings, run the following command:\n\nTo install the official Node.js library, run the following command in your Node.js project directory:\n\n```\nnpm install openai@^4.0.0\n```\n\n[](https://platform.openai.com/docs/api-reference/authentication)\n\n## [Authentication](https://platform.openai.com/docs/api-reference/authentication)\n\nThe OpenAI API uses API keys for authentication. Visit your [API Keys](https://platform.openai.com/account/api-keys) page to retrieve the API key you'll use in your requests.\n\n**Remember that your API key is a secret!** Do not share it with others or expose it in any client-side code (browsers, apps). Production requests must be routed through your own backend server where your API key can be securely loaded from an environment variable or key management service.\n\nAll API requests should include your API key in an `Authorization` HTTP header as follows:\n\n```\nAuthorization: Bearer OPENAI_API_KEY\n```\n\n[](https://platform.openai.com/docs/api-reference/organization-optional)\n\n### [Organization (optional)](https://platform.openai.com/docs/api-reference/organization-optional)\n\nFor users who belong to multiple organizations, you can pass a header to specify which organization is used for an API request. Usage from these API requests will count against the specified organization's subscription quota.\n\nExample curl command:\n\n```\n1\n2\n3\ncurl https://api.openai.com/v1/models \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\" \\\n  -H \"OpenAI-Organization: YOUR_ORG_ID\"\n```\n\nExample with the `openai` Python package:\n\n```\n1\n2\n3\n4\n5\nimport os\nimport openai\nopenai.organization = \"YOUR_ORG_ID\"\nopenai.api_key = os.getenv(\"OPENAI_API_KEY\")\nopenai.Model.list()\n```\n\nExample with the `openai` Node.js package:\n\n```\n1\n2\n3\n4\n5\n6\n7\nimport { Configuration, OpenAIApi } from \"openai\";\nconst configuration = new Configuration({\n    organization: \"YOUR_ORG_ID\",\n    apiKey: process.env.OPENAI_API_KEY,\n});\nconst openai = new OpenAIApi(configuration);\nconst response = await openai.listEngines();\n```\n\nOrganization IDs can be found on your [Organization settings](https://platform.openai.com/account/org-settings) page.\n\n[](https://platform.openai.com/docs/api-reference/making-requests)\n\n## [Making requests](https://platform.openai.com/docs/api-reference/making-requests)\n\nYou can paste the command below into your terminal to run your first API request. Make sure to replace `$OPENAI_API_KEY` with your secret API key.\n\n```\n1\n2\n3\n4\n5\n6\n7\n8\ncurl https://api.openai.com/v1/chat/completions \\\n  -H \"Content-Type: application/json\" \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\" \\\n  -d '{\n     \"model\": \"gpt-3.5-turbo\",\n     \"messages\": [{\"role\": \"user\", \"content\": \"Say this is a test!\"}],\n     \"temperature\": 0.7\n   }'\n```\n\nThis request queries the `gpt-3.5-turbo` model (which under the hood points to the [latest `gpt-3.5-turbo` model variant](https://platform.openai.com/docs/models/gpt-3-5)) to complete the text starting with a prompt of \"_Say this is a test_\". You should get a response back that resembles the following:\n\n```\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n{\n    \"id\": \"chatcmpl-abc123\",\n    \"object\": \"chat.completion\",\n    \"created\": 1677858242,\n    \"model\": \"gpt-3.5-turbo-0613\",\n    \"usage\": {\n        \"prompt_tokens\": 13,\n        \"completion_tokens\": 7,\n        \"total_tokens\": 20\n    },\n    \"choices\": [\n        {\n            \"message\": {\n                \"role\": \"assistant\",\n                \"content\": \"\\n\\nThis is a test!\"\n            },\n            \"finish_reason\": \"stop\",\n            \"index\": 0\n        }\n    ]\n}\n```\n\nNow that you've generated your first chat completion, let's break down the [response object](https://platform.openai.com/docs/api-reference/chat/object). We can see the `finish_reason` is `stop` which means the API returned the full chat completion generated by the model without running into any limits. In the choices list, we only generated a single message but you can set the `n` parameter to generate multiple messages choices.\n\n[](https://platform.openai.com/docs/api-reference/audio/createTranscription)\n\n## [Create transcription](https://platform.openai.com/docs/api-reference/audio/createTranscription)\n\npost\u00a0https://api.openai.com/v1/audio/transcriptions\n\nTranscribes audio into the input language.\n\n### Request body\n\nThe audio file object (not file name) to transcribe, in one of these formats: flac, mp3, mp4, mpeg, mpga, m4a, ogg, wav, or webm.\n\nID of the model to use. Only `whisper-1` is currently available.\n\nThe language of the input audio. Supplying the input language in [ISO-639-1](https://en.wikipedia.org/wiki/List_of_ISO_639-1_codes) format will improve accuracy and latency.\n\nAn optional text to guide the model's style or continue a previous audio segment. The [prompt](https://platform.openai.com/docs/guides/speech-to-text/prompting) should match the audio language.\n\nThe format of the transcript output, in one of these options: json, text, srt, verbose\\_json, or vtt.\n\nThe sampling temperature, between 0 and 1. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic. If set to 0, the model will use [log probability](https://en.wikipedia.org/wiki/Log_probability) to automatically increase the temperature until certain thresholds are hit.\n\n### Returns\n\n```\n1\n2\n3\n4\n5\ncurl https://api.openai.com/v1/audio/transcriptions \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\" \\\n  -H \"Content-Type: multipart/form-data\" \\\n  -F file=\"@/path/to/file/audio.mp3\" \\\n  -F model=\"whisper-1\"\n```\n\n```\n1\n2\n3\n{\n  \"text\": \"Imagine the wildest idea that you've ever had, and you're curious about how it might scale to something that's a 100, a 1,000 times bigger. This is a place where you can get to do that.\"\n}\n```\n\n[](https://platform.openai.com/docs/api-reference/audio/createTranslation)\n\n## [Create translation](https://platform.openai.com/docs/api-reference/audio/createTranslation)\n\npost\u00a0https://api.openai.com/v1/audio/translations\n\nTranslates audio into English.\n\n### Request body\n\nThe audio file object (not file name) translate, in one of these formats: flac, mp3, mp4, mpeg, mpga, m4a, ogg, wav, or webm.\n\nID of the model to use. Only `whisper-1` is currently available.\n\nAn optional text to guide the model's style or continue a previous audio segment. The [prompt](https://platform.openai.com/docs/guides/speech-to-text/prompting) should be in English.\n\nThe format of the transcript output, in one of these options: json, text, srt, verbose\\_json, or vtt.\n\nThe sampling temperature, between 0 and 1. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic. If set to 0, the model will use [log probability](https://en.wikipedia.org/wiki/Log_probability) to automatically increase the temperature until certain thresholds are hit.\n\n### Returns\n\n```\n1\n2\n3\n4\n5\ncurl https://api.openai.com/v1/audio/translations \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\" \\\n  -H \"Content-Type: multipart/form-data\" \\\n  -F file=\"@/path/to/file/german.m4a\" \\\n  -F model=\"whisper-1\"\n```\n\n```\n1\n2\n3\n{\n  \"text\": \"Hello, my name is Wolfgang and I come from Germany. Where are you heading today?\"\n}\n```\n\n[](https://platform.openai.com/docs/api-reference/chat)\n\n## [Chat](https://platform.openai.com/docs/api-reference/chat)\n\nGiven a list of messages comprising a conversation, the model will return a response.\n\nRelated guide: [Chat completions](https://platform.openai.com/docs/guides/gpt)\n\n[](https://platform.openai.com/docs/api-reference/chat/object)\n\n## [The chat completion object](https://platform.openai.com/docs/api-reference/chat/object)\n\nRepresents a chat completion response returned by model, based on the provided input.\n\nA unique identifier for the chat completion.\n\nA list of chat completion choices. Can be more than one if `n` is greater than 1.\n\nThe Unix timestamp (in seconds) of when the chat completion was created.\n\nThe model used for the chat completion.\n\nThe object type, which is always `chat.completion`.\n\nUsage statistics for the completion request.\n\n```\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n{\n  \"id\": \"chatcmpl-123\",\n  \"object\": \"chat.completion\",\n  \"created\": 1677652288,\n  \"model\": \"gpt-3.5-turbo-0613\",\n  \"choices\": [{\n    \"index\": 0,\n    \"message\": {\n      \"role\": \"assistant\",\n      \"content\": \"\\n\\nHello there, how may I assist you today?\",\n    },\n    \"finish_reason\": \"stop\"\n  }],\n  \"usage\": {\n    \"prompt_tokens\": 9,\n    \"completion_tokens\": 12,\n    \"total_tokens\": 21\n  }\n}\n```\n\n[](https://platform.openai.com/docs/api-reference/chat/streaming)\n\n## [The chat completion chunk object](https://platform.openai.com/docs/api-reference/chat/streaming)\n\nRepresents a streamed chunk of a chat completion response returned by model, based on the provided input.\n\nA unique identifier for the chat completion. Each chunk has the same ID.\n\nA list of chat completion choices. Can be more than one if `n` is greater than 1.\n\nThe Unix timestamp (in seconds) of when the chat completion was created. Each chunk has the same timestamp.\n\nThe model to generate the completion.\n\nThe object type, which is always `chat.completion.chunk`.\n\n```\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n{\"id\":\"chatcmpl-123\",\"object\":\"chat.completion.chunk\",\"created\":1694268190,\"model\":\"gpt-3.5-turbo-0613\",\"choices\":[{\"index\":0,\"delta\":{\"role\":\"assistant\",\"content\":\"\"},\"finish_reason\":null}]}\n\n{\"id\":\"chatcmpl-123\",\"object\":\"chat.completion.chunk\",\"created\":1694268190,\"model\":\"gpt-3.5-turbo-0613\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\"Hello\"},\"finish_reason\":null}]}\n\n{\"id\":\"chatcmpl-123\",\"object\":\"chat.completion.chunk\",\"created\":1694268190,\"model\":\"gpt-3.5-turbo-0613\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\"!\"},\"finish_reason\":null}]}\n\n....\n\n{\"id\":\"chatcmpl-123\",\"object\":\"chat.completion.chunk\",\"created\":1694268190,\"model\":\"gpt-3.5-turbo-0613\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\" today\"},\"finish_reason\":null}]}\n\n{\"id\":\"chatcmpl-123\",\"object\":\"chat.completion.chunk\",\"created\":1694268190,\"model\":\"gpt-3.5-turbo-0613\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\"?\"},\"finish_reason\":null}]}\n\n{\"id\":\"chatcmpl-123\",\"object\":\"chat.completion.chunk\",\"created\":1694268190,\"model\":\"gpt-3.5-turbo-0613\",\"choices\":[{\"index\":0,\"delta\":{},\"finish_reason\":\"stop\"}]}\n```\n\n[](https://platform.openai.com/docs/api-reference/chat/create)\n\n## [Create chat completion](https://platform.openai.com/docs/api-reference/chat/create)\n\npost\u00a0https://api.openai.com/v1/chat/completions\n\nCreates a model response for the given chat conversation.\n\n### Request body\n\nControls how the model calls functions. \"none\" means the model will not call a function and instead generates a message. \"auto\" means the model can pick between generating a message or calling a function. Specifying a particular function via `{\"name\": \"my_function\"}` forces the model to call that function. \"none\" is the default when no functions are present. \"auto\" is the default if functions are present.\n\nA list of functions the model may generate JSON inputs for.\n\nModify the likelihood of specified tokens appearing in the completion.\n\nAccepts a json object that maps tokens (specified by their token ID in the tokenizer) to an associated bias value from -100 to 100. Mathematically, the bias is added to the logits generated by the model prior to sampling. The exact effect will vary per model, but values between -1 and 1 should decrease or increase likelihood of selection; values like -100 or 100 should result in a ban or exclusive selection of the relevant token.\n\nThe maximum number of [tokens](https://platform.openai.com/tokenizer) to generate in the chat completion.\n\nThe total length of input tokens and generated tokens is limited by the model's context length. [Example Python code](https://cookbook.openai.com/examples/how_to_count_tokens_with_tiktoken) for counting tokens.\n\nHow many chat completion choices to generate for each input message.\n\nUp to 4 sequences where the API will stop generating further tokens.\n\nIf set, partial message deltas will be sent, like in ChatGPT. Tokens will be sent as data-only [server-sent events](https://developer.mozilla.org/en-US/docs/Web/API/Server-sent_events/Using_server-sent_events#Event_stream_format) as they become available, with the stream terminated by a `data: [DONE]` message. [Example Python code](https://cookbook.openai.com/examples/how_to_stream_completions).\n\nWhat sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic.\n\nWe generally recommend altering this or `top_p` but not both.\n\nAn alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top\\_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered.\n\nWe generally recommend altering this or `temperature` but not both.\n\nA unique identifier representing your end-user, which can help OpenAI to monitor and detect abuse. [Learn more](https://platform.openai.com/docs/guides/safety-best-practices/end-user-ids).\n\n### Returns\n\nNo StreamingStreamingFunction calling\n\n```\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\ncurl https://api.openai.com/v1/chat/completions \\\n  -H \"Content-Type: application/json\" \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\" \\\n  -d '{\n    \"model\": \"gpt-3.5-turbo\",\n    \"messages\": [\n      {\n        \"role\": \"system\",\n        \"content\": \"You are a helpful assistant.\"\n      },\n      {\n        \"role\": \"user\",\n        \"content\": \"Hello!\"\n      }\n    ]\n  }'\n```\n\n```\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n{\n  \"id\": \"chatcmpl-123\",\n  \"object\": \"chat.completion\",\n  \"created\": 1677652288,\n  \"model\": \"gpt-3.5-turbo-0613\",\n  \"choices\": [{\n    \"index\": 0,\n    \"message\": {\n      \"role\": \"assistant\",\n      \"content\": \"\\n\\nHello there, how may I assist you today?\",\n    },\n    \"finish_reason\": \"stop\"\n  }],\n  \"usage\": {\n    \"prompt_tokens\": 9,\n    \"completion_tokens\": 12,\n    \"total_tokens\": 21\n  }\n}\n```\n\nGiven a prompt, the model will return one or more predicted completions, and can also return the probabilities of alternative tokens at each position. We recommend most users use our Chat completions API. [Learn more](https://platform.openai.com/docs/deprecations/2023-07-06-gpt-and-embeddings)\n\nRelated guide: [Legacy Completions](https://platform.openai.com/docs/guides/gpt/completions-api)\n\nRepresents a completion response from the API. Note: both the streamed and non-streamed response objects share the same shape (unlike the chat endpoint).\n\nA unique identifier for the completion.\n\nThe list of completion choices the model generated for the input prompt.\n\nThe Unix timestamp (in seconds) of when the completion was created.\n\nThe model used for completion.\n\nThe object type, which is always \"text\\_completion\"\n\nUsage statistics for the completion request.\n\n```\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n{\n  \"id\": \"cmpl-uqkvlQyYK7bGYrRHQ0eXlWi7\",\n  \"object\": \"text_completion\",\n  \"created\": 1589478378,\n  \"model\": \"gpt-3.5-turbo\",\n  \"choices\": [\n    {\n      \"text\": \"\\n\\nThis is indeed a test\",\n      \"index\": 0,\n      \"logprobs\": null,\n      \"finish_reason\": \"length\"\n    }\n  ],\n  \"usage\": {\n    \"prompt_tokens\": 5,\n    \"completion_tokens\": 7,\n    \"total_tokens\": 12\n  }\n}\n```\n\npost\u00a0https://api.openai.com/v1/completions\n\nCreates a completion for the provided prompt and parameters.\n\n### Request body\n\nID of the model to use. You can use the [List models](https://platform.openai.com/docs/api-reference/models/list) API to see all of your available models, or see our [Model overview](https://platform.openai.com/docs/models/overview) for descriptions of them.\n\nThe prompt(s) to generate completions for, encoded as a string, array of strings, array of tokens, or array of token arrays.\n\nNote that <|endoftext|> is the document separator that the model sees during training, so if a prompt is not specified the model will generate as if from the beginning of a new document.\n\nGenerates `best_of` completions server-side and returns the \"best\" (the one with the highest log probability per token). Results cannot be streamed.\n\nWhen used with `n`, `best_of` controls the number of candidate completions and `n` specifies how many to return \u2013 `best_of` must be greater than `n`.\n\n**Note:** Because this parameter generates many completions, it can quickly consume your token quota. Use carefully and ensure that you have reasonable settings for `max_tokens` and `stop`.\n\nEcho back the prompt in addition to the completion\n\nModify the likelihood of specified tokens appearing in the completion.\n\nAccepts a json object that maps tokens (specified by their token ID in the GPT tokenizer) to an associated bias value from -100 to 100. You can use this [tokenizer tool](https://platform.openai.com/tokenizer?view=bpe) (which works for both GPT-2 and GPT-3) to convert text to token IDs. Mathematically, the bias is added to the logits generated by the model prior to sampling. The exact effect will vary per model, but values between -1 and 1 should decrease or increase likelihood of selection; values like -100 or 100 should result in a ban or exclusive selection of the relevant token.\n\nAs an example, you can pass `{\"50256\": -100}` to prevent the <|endoftext|> token from being generated.\n\nInclude the log probabilities on the `logprobs` most likely tokens, as well the chosen tokens. For example, if `logprobs` is 5, the API will return a list of the 5 most likely tokens. The API will always return the `logprob` of the sampled token, so there may be up to `logprobs+1` elements in the response.\n\nThe maximum value for `logprobs` is 5.\n\nThe maximum number of [tokens](https://platform.openai.com/tokenizer) to generate in the completion.\n\nThe token count of your prompt plus `max_tokens` cannot exceed the model's context length. [Example Python code](https://cookbook.openai.com/examples/how_to_count_tokens_with_tiktoken) for counting tokens.\n\nHow many completions to generate for each prompt.\n\n**Note:** Because this parameter generates many completions, it can quickly consume your token quota. Use carefully and ensure that you have reasonable settings for `max_tokens` and `stop`.\n\nUp to 4 sequences where the API will stop generating further tokens. The returned text will not contain the stop sequence.\n\nWhether to stream back partial progress. If set, tokens will be sent as data-only [server-sent events](https://developer.mozilla.org/en-US/docs/Web/API/Server-sent_events/Using_server-sent_events#Event_stream_format) as they become available, with the stream terminated by a `data: [DONE]` message. [Example Python code](https://cookbook.openai.com/examples/how_to_stream_completions).\n\nThe suffix that comes after a completion of inserted text.\n\nWhat sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic.\n\nWe generally recommend altering this or `top_p` but not both.\n\nAn alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top\\_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered.\n\nWe generally recommend altering this or `temperature` but not both.\n\nA unique identifier representing your end-user, which can help OpenAI to monitor and detect abuse. [Learn more](https://platform.openai.com/docs/guides/safety-best-practices/end-user-ids).\n\n### Returns\n\nReturns a [completion](https://platform.openai.com/docs/api-reference/completions/object) object, or a sequence of completion objects if the request is streamed.\n\n```\n1\n2\n3\n4\n5\n6\n7\n8\n9\ncurl https://api.openai.com/v1/completions \\\n  -H \"Content-Type: application/json\" \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\" \\\n  -d '{\n    \"model\": \"gpt-3.5-turbo-instruct\",\n    \"prompt\": \"Say this is a test\",\n    \"max_tokens\": 7,\n    \"temperature\": 0\n  }'\n```\n\n```\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n{\n  \"id\": \"cmpl-uqkvlQyYK7bGYrRHQ0eXlWi7\",\n  \"object\": \"text_completion\",\n  \"created\": 1589478378,\n  \"model\": \"gpt-3.5-turbo-instruct\",\n  \"choices\": [\n    {\n      \"text\": \"\\n\\nThis is indeed a test\",\n      \"index\": 0,\n      \"logprobs\": null,\n      \"finish_reason\": \"length\"\n    }\n  ],\n  \"usage\": {\n    \"prompt_tokens\": 5,\n    \"completion_tokens\": 7,\n    \"total_tokens\": 12\n  }\n}\n```\n\n[](https://platform.openai.com/docs/api-reference/embeddings)\n\n## [Embeddings](https://platform.openai.com/docs/api-reference/embeddings)\n\nGet a vector representation of a given input that can be easily consumed by machine learning models and algorithms.\n\nRelated guide: [Embeddings](https://platform.openai.com/docs/guides/embeddings)\n\n[](https://platform.openai.com/docs/api-reference/embeddings/object)\n\n## [The embedding object](https://platform.openai.com/docs/api-reference/embeddings/object)\n\nRepresents an embedding vector returned by embedding endpoint.\n\nThe index of the embedding in the list of embeddings.\n\nThe embedding vector, which is a list of floats. The length of vector depends on the model as listed in the [embedding guide](https://platform.openai.com/docs/guides/embeddings).\n\nThe object type, which is always \"embedding\".\n\n```\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n{\n  \"object\": \"embedding\",\n  \"embedding\": [\n    0.0023064255,\n    -0.009327292,\n    .... (1536 floats total for ada-002)\n    -0.0028842222,\n  ],\n  \"index\": 0\n}\n```\n\n[](https://platform.openai.com/docs/api-reference/embeddings/create)\n\n## [Create embeddings](https://platform.openai.com/docs/api-reference/embeddings/create)\n\npost\u00a0https://api.openai.com/v1/embeddings\n\nCreates an embedding vector representing the input text.\n\n### Request body\n\nInput text to embed, encoded as a string or array of tokens. To embed multiple inputs in a single request, pass an array of strings or array of token arrays. The input must not exceed the max input tokens for the model (8192 tokens for `text-embedding-ada-002`) and cannot be an empty string. [Example Python code](https://cookbook.openai.com/examples/how_to_count_tokens_with_tiktoken) for counting tokens.\n\nID of the model to use. You can use the [List models](https://platform.openai.com/docs/api-reference/models/list) API to see all of your available models, or see our [Model overview](https://platform.openai.com/docs/models/overview) for descriptions of them.\n\nThe format to return the embeddings in. Can be either `float` or [`base64`](https://pypi.org/project/pybase64/).\n\nA unique identifier representing your end-user, which can help OpenAI to monitor and detect abuse. [Learn more](https://platform.openai.com/docs/guides/safety-best-practices/end-user-ids).\n\n### Returns\n\n```\n1\n2\n3\n4\n5\n6\n7\n8\ncurl https://api.openai.com/v1/embeddings \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\" \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"input\": \"The food was delicious and the waiter...\",\n    \"model\": \"text-embedding-ada-002\",\n    \"encoding_format\": \"float\"\n  }'\n```\n\n```\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n{\n  \"object\": \"list\",\n  \"data\": [\n    {\n      \"object\": \"embedding\",\n      \"embedding\": [\n        0.0023064255,\n        -0.009327292,\n        .... (1536 floats total for ada-002)\n        -0.0028842222,\n      ],\n      \"index\": 0\n    }\n  ],\n  \"model\": \"text-embedding-ada-002\",\n  \"usage\": {\n    \"prompt_tokens\": 8,\n    \"total_tokens\": 8\n  }\n}\n```\n\n[](https://platform.openai.com/docs/api-reference/fine-tuning/object)\n\n## [The fine-tuning job object](https://platform.openai.com/docs/api-reference/fine-tuning/object)\n\nThe `fine_tuning.job` object represents a fine-tuning job that has been created through the API.\n\nThe object identifier, which can be referenced in the API endpoints.\n\nThe Unix timestamp (in seconds) for when the fine-tuning job was created.\n\nFor fine-tuning jobs that have `failed`, this will contain more information on the cause of the failure.\n\nThe name of the fine-tuned model that is being created. The value will be null if the fine-tuning job is still running.\n\nThe Unix timestamp (in seconds) for when the fine-tuning job was finished. The value will be null if the fine-tuning job is still running.\n\nThe hyperparameters used for the fine-tuning job. See the [fine-tuning guide](https://platform.openai.com/docs/guides/fine-tuning) for more details.\n\nThe base model that is being fine-tuned.\n\nThe object type, which is always \"fine\\_tuning.job\".\n\nThe organization that owns the fine-tuning job.\n\nThe compiled results file ID(s) for the fine-tuning job. You can retrieve the results with the [Files API](https://platform.openai.com/docs/api-reference/files/retrieve-contents).\n\nThe current status of the fine-tuning job, which can be either `validating_files`, `queued`, `running`, `succeeded`, `failed`, or `cancelled`.\n\nThe total number of billable tokens processed by this fine-tuning job. The value will be null if the fine-tuning job is still running.\n\nThe file ID used for training. You can retrieve the training data with the [Files API](https://platform.openai.com/docs/api-reference/files/retrieve-contents).\n\nThe file ID used for validation. You can retrieve the validation results with the [Files API](https://platform.openai.com/docs/api-reference/files/retrieve-contents).\n\n```\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n{\n  \"object\": \"fine_tuning.job\",\n  \"id\": \"ftjob-abc123\",\n  \"model\": \"davinci-002\",\n  \"created_at\": 1692661014,\n  \"finished_at\": 1692661190,\n  \"fine_tuned_model\": \"ft:davinci-002:my-org:custom_suffix:7q8mpxmy\",\n  \"organization_id\": \"org-123\",\n  \"result_files\": [\n      \"file-abc123\"\n  ],\n  \"status\": \"succeeded\",\n  \"validation_file\": null,\n  \"training_file\": \"file-abc123\",\n  \"hyperparameters\": {\n      \"n_epochs\": 4,\n  },\n  \"trained_tokens\": 5768\n}\n```\n\n[](https://platform.openai.com/docs/api-reference/fine-tuning/create)\n\n## [Create fine-tuning job](https://platform.openai.com/docs/api-reference/fine-tuning/create)\n\npost\u00a0https://api.openai.com/v1/fine\\_tuning/jobs\n\nCreates a job that fine-tunes a specified model from a given dataset.\n\nResponse includes details of the enqueued job including job status and the name of the fine-tuned models once complete.\n\n[Learn more about fine-tuning](https://platform.openai.com/docs/guides/fine-tuning)\n\n### Request body\n\nThe ID of an uploaded file that contains training data.\n\nSee [upload file](https://platform.openai.com/docs/api-reference/files/upload) for how to upload a file.\n\nYour dataset must be formatted as a JSONL file. Additionally, you must upload your file with the purpose `fine-tune`.\n\nSee the [fine-tuning guide](https://platform.openai.com/docs/guides/fine-tuning) for more details.\n\nThe hyperparameters used for the fine-tuning job.\n\nA string of up to 18 characters that will be added to your fine-tuned model name.\n\nFor example, a `suffix` of \"custom-model-name\" would produce a model name like `ft:gpt-3.5-turbo:openai:custom-model-name:7p4lURel`.\n\nThe ID of an uploaded file that contains validation data.\n\nIf you provide this file, the data is used to generate validation metrics periodically during fine-tuning. These metrics can be viewed in the fine-tuning results file. The same data should not be present in both train and validation files.\n\nYour dataset must be formatted as a JSONL file. You must upload your file with the purpose `fine-tune`.\n\nSee the [fine-tuning guide](https://platform.openai.com/docs/guides/fine-tuning) for more details.\n\n### Returns\n\nNo hyperparametersHyperparametersValidation file\n\n```\n1\n2\n3\n4\n5\n6\n7\ncurl https://api.openai.com/v1/fine_tuning/jobs \\\n  -H \"Content-Type: application/json\" \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\" \\\n  -d '{\n    \"training_file\": \"file-abc123\",\n    \"model\": \"gpt-3.5-turbo\"\n  }'\n```\n\n```\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n{\n  \"object\": \"fine_tuning.job\",\n  \"id\": \"ftjob-abc123\",\n  \"model\": \"gpt-3.5-turbo-0613\",\n  \"created_at\": 1614807352,\n  \"fine_tuned_model\": null,\n  \"organization_id\": \"org-123\",\n  \"result_files\": [],\n  \"status\": \"queued\",\n  \"validation_file\": null,\n  \"training_file\": \"file-abc123\",\n}\n```\n\n[](https://platform.openai.com/docs/api-reference/fine-tuning/list)\n\n## [List fine-tuning jobs](https://platform.openai.com/docs/api-reference/fine-tuning/list)\n\nget\u00a0https://api.openai.com/v1/fine\\_tuning/jobs\n\nList your organization's fine-tuning jobs\n\n### Query parameters\n\nIdentifier for the last job from the previous pagination request.\n\nNumber of fine-tuning jobs to retrieve.\n\n### Returns\n\n```\n1\n2\ncurl https://api.openai.com/v1/fine_tuning/jobs?limit=2 \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\"\n```\n\n```\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n{\n  \"object\": \"list\",\n  \"data\": [\n    {\n      \"object\": \"fine_tuning.job.event\",\n      \"id\": \"ft-event-TjX0lMfOniCZX64t9PUQT5hn\",\n      \"created_at\": 1689813489,\n      \"level\": \"warn\",\n      \"message\": \"Fine tuning process stopping due to job cancellation\",\n      \"data\": null,\n      \"type\": \"message\"\n    },\n    { ... },\n    { ... }\n  ], \"has_more\": true\n}\n```\n\n[](https://platform.openai.com/docs/api-reference/fine-tuning/retrieve)\n\n## [Retrieve fine-tuning job](https://platform.openai.com/docs/api-reference/fine-tuning/retrieve)\n\nget\u00a0https://api.openai.com/v1/fine\\_tuning/jobs/{fine\\_tuning\\_job\\_id}\n\n### Path parameters\n\nThe ID of the fine-tuning job.\n\n### Returns\n\n```\n1\n2\ncurl https://api.openai.com/v1/fine_tuning/jobs/ft-AF1WoRqd3aJAHsqc9NY7iL8F \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\"\n```\n\n```\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n{\n  \"object\": \"fine_tuning.job\",\n  \"id\": \"ftjob-abc123\",\n  \"model\": \"davinci-002\",\n  \"created_at\": 1692661014,\n  \"finished_at\": 1692661190,\n  \"fine_tuned_model\": \"ft:davinci-002:my-org:custom_suffix:7q8mpxmy\",\n  \"organization_id\": \"org-123\",\n  \"result_files\": [\n      \"file-abc123\"\n  ],\n  \"status\": \"succeeded\",\n  \"validation_file\": null,\n  \"training_file\": \"file-abc123\",\n  \"hyperparameters\": {\n      \"n_epochs\": 4,\n  },\n  \"trained_tokens\": 5768\n}\n```\n\n[](https://platform.openai.com/docs/api-reference/fine-tuning/cancel)\n\n## [Cancel fine-tuning](https://platform.openai.com/docs/api-reference/fine-tuning/cancel)\n\npost\u00a0https://api.openai.com/v1/fine\\_tuning/jobs/{fine\\_tuning\\_job\\_id}/cancel\n\nImmediately cancel a fine-tune job.\n\n### Path parameters\n\nThe ID of the fine-tuning job to cancel.\n\n### Returns\n\n```\n1\n2\ncurl -X POST https://api.openai.com/v1/fine_tuning/jobs/ftjob-abc123/cancel \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\"\n```\n\n```\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n{\n  \"object\": \"fine_tuning.job\",\n  \"id\": \"ftjob-abc123\",\n  \"model\": \"gpt-3.5-turbo-0613\",\n  \"created_at\": 1689376978,\n  \"fine_tuned_model\": null,\n  \"organization_id\": \"org-123\",\n  \"result_files\": [],\n  \"hyperparameters\": {\n    \"n_epochs\":  \"auto\"\n  },\n  \"status\": \"cancelled\",\n  \"validation_file\": \"file-abc123\",\n  \"training_file\": \"file-abc123\"\n}\n```\n\n```\n1\n2\n3\n4\n5\n6\n7\n{\n  \"object\": \"event\",\n  \"id\": \"ftevent-abc123\"\n  \"created_at\": 1677610602,\n  \"level\": \"info\",\n  \"message\": \"Created fine-tuning job\"\n}\n```\n\n[](https://platform.openai.com/docs/api-reference/fine-tuning/list-events)\n\n## [List fine-tuning events](https://platform.openai.com/docs/api-reference/fine-tuning/list-events)\n\nget\u00a0https://api.openai.com/v1/fine\\_tuning/jobs/{fine\\_tuning\\_job\\_id}/events\n\nGet status updates for a fine-tuning job.\n\n### Path parameters\n\nThe ID of the fine-tuning job to get events for.\n\n### Query parameters\n\nIdentifier for the last event from the previous pagination request.\n\nNumber of events to retrieve.\n\n### Returns\n\nA list of fine-tuning event objects.\n\n```\n1\n2\ncurl https://api.openai.com/v1/fine_tuning/jobs/ftjob-abc123/events \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\"\n```\n\n```\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n{\n  \"object\": \"list\",\n  \"data\": [\n    {\n      \"object\": \"fine_tuning.job.event\",\n      \"id\": \"ft-event-ddTJfwuMVpfLXseO0Am0Gqjm\",\n      \"created_at\": 1692407401,\n      \"level\": \"info\",\n      \"message\": \"Fine tuning job successfully completed\",\n      \"data\": null,\n      \"type\": \"message\"\n    },\n    {\n      \"object\": \"fine_tuning.job.event\",\n      \"id\": \"ft-event-tyiGuB72evQncpH87xe505Sv\",\n      \"created_at\": 1692407400,\n      \"level\": \"info\",\n      \"message\": \"New fine-tuned model created: ft:gpt-3.5-turbo:openai::7p4lURel\",\n      \"data\": null,\n      \"type\": \"message\"\n    }\n  ],\n  \"has_more\": true\n}\n```\n\n[](https://platform.openai.com/docs/api-reference/files)\n\n## [Files](https://platform.openai.com/docs/api-reference/files)\n\nFiles are used to upload documents that can be used with features like [fine-tuning](https://platform.openai.com/docs/api-reference/fine-tuning).\n\n[](https://platform.openai.com/docs/api-reference/files/object)\n\n## [The file object](https://platform.openai.com/docs/api-reference/files/object)\n\nThe `File` object represents a document that has been uploaded to OpenAI.\n\nThe file identifier, which can be referenced in the API endpoints.\n\nThe size of the file in bytes.\n\nThe Unix timestamp (in seconds) for when the file was created.\n\nThe object type, which is always \"file\".\n\nThe intended purpose of the file. Currently, only \"fine-tune\" is supported.\n\nThe current status of the file, which can be either `uploaded`, `processed`, `pending`, `error`, `deleting` or `deleted`.\n\nAdditional details about the status of the file. If the file is in the `error` state, this will include a message describing the error.\n\n```\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n{\n  \"id\": \"file-abc123\",\n  \"object\": \"file\",\n  \"bytes\": 120000,\n  \"created_at\": 1677610602,\n  \"filename\": \"my_file.jsonl\",\n  \"purpose\": \"fine-tune\",\n  \"status\": \"uploaded\",\n  \"status_details\": null\n}\n```\n\n[](https://platform.openai.com/docs/api-reference/files/list)\n\n## [List files](https://platform.openai.com/docs/api-reference/files/list)\n\nget\u00a0https://api.openai.com/v1/files\n\nReturns a list of files that belong to the user's organization.\n\n### Returns\n\n```\n1\n2\ncurl https://api.openai.com/v1/files \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\"\n```\n\n```\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n{\n  \"data\": [\n    {\n      \"id\": \"file-abc123\",\n      \"object\": \"file\",\n      \"bytes\": 175,\n      \"created_at\": 1613677385,\n      \"filename\": \"train.jsonl\",\n      \"purpose\": \"search\"\n    },\n    {\n      \"id\": \"file-abc123\",\n      \"object\": \"file\",\n      \"bytes\": 140,\n      \"created_at\": 1613779121,\n      \"filename\": \"puppy.jsonl\",\n      \"purpose\": \"search\"\n    }\n  ],\n  \"object\": \"list\"\n}\n```\n\n[](https://platform.openai.com/docs/api-reference/files/create)\n\n## [Upload file](https://platform.openai.com/docs/api-reference/files/create)\n\npost\u00a0https://api.openai.com/v1/files\n\nUpload a file that can be used across various endpoints/features. Currently, the size of all the files uploaded by one organization can be up to 1 GB. Please [contact us](https://help.openai.com/) if you need to increase the storage limit.\n\n### Request body\n\nThe file object (not file name) to be uploaded.\n\nIf the `purpose` is set to \"fine-tune\", the file will be used for fine-tuning.\n\nThe intended purpose of the uploaded file.\n\nUse \"fine-tune\" for [fine-tuning](https://platform.openai.com/docs/api-reference/fine-tuning). This allows us to validate the format of the uploaded file is correct for fine-tuning.\n\n### Returns\n\nThe uploaded [file](https://platform.openai.com/docs/api-reference/files/object) object.\n\n```\n1\n2\n3\n4\ncurl https://api.openai.com/v1/files \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\" \\\n  -F purpose=\"fine-tune\" \\\n  -F file=\"@mydata.jsonl\"\n```\n\n```\n1\n2\n3\n4\n5\n6\n7\n8\n9\n{\n  \"id\": \"file-abc123\",\n  \"object\": \"file\",\n  \"bytes\": 140,\n  \"created_at\": 1613779121,\n  \"filename\": \"mydata.jsonl\",\n  \"purpose\": \"fine-tune\",\n  \"status\": \"uploaded\" | \"processed\" | \"pending\" | \"error\"\n}\n```\n\n[](https://platform.openai.com/docs/api-reference/files/delete)\n\n## [Delete file](https://platform.openai.com/docs/api-reference/files/delete)\n\ndelete\u00a0https://api.openai.com/v1/files/{file\\_id}\n\nDelete a file.\n\n### Path parameters\n\nThe ID of the file to use for this request.\n\n### Returns\n\n```\n1\n2\n3\ncurl https://api.openai.com/v1/files/file-abc123 \\\n  -X DELETE \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\"\n```\n\n```\n1\n2\n3\n4\n5\n{\n  \"id\": \"file-abc123\",\n  \"object\": \"file\",\n  \"deleted\": true\n}\n```\n\n[](https://platform.openai.com/docs/api-reference/files/retrieve)\n\n## [Retrieve file](https://platform.openai.com/docs/api-reference/files/retrieve)\n\nget\u00a0https://api.openai.com/v1/files/{file\\_id}\n\nReturns information about a specific file.\n\n### Path parameters\n\nThe ID of the file to use for this request.\n\n### Returns\n\nThe [file](https://platform.openai.com/docs/api-reference/files/object) object matching the specified ID.\n\n```\n1\n2\ncurl https://api.openai.com/v1/files/file-abc123 \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\"\n```\n\n```\n1\n2\n3\n4\n5\n6\n7\n8\n{\n  \"id\": \"file-abc123\",\n  \"object\": \"file\",\n  \"bytes\": 140,\n  \"created_at\": 1613779657,\n  \"filename\": \"mydata.jsonl\",\n  \"purpose\": \"fine-tune\"\n}\n```\n\n[](https://platform.openai.com/docs/api-reference/files/retrieve-contents)\n\n## [Retrieve file content](https://platform.openai.com/docs/api-reference/files/retrieve-contents)\n\nget\u00a0https://api.openai.com/v1/files/{file\\_id}/content\n\nReturns the contents of the specified file.\n\n### Path parameters\n\nThe ID of the file to use for this request.\n\n### Returns\n\n```\n1\n2\ncurl https://api.openai.com/v1/files/file-abc123/content \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\" > file.jsonl\n```\n\n[](https://platform.openai.com/docs/api-reference/images)\n\n## [Images](https://platform.openai.com/docs/api-reference/images)\n\nGiven a prompt and/or an input image, the model will generate a new image.\n\nRelated guide: [Image generation](https://platform.openai.com/docs/guides/images)\n\n[](https://platform.openai.com/docs/api-reference/images/object)\n\n## [The image object](https://platform.openai.com/docs/api-reference/images/object)\n\nRepresents the url or the content of an image generated by the OpenAI API.\n\nThe base64-encoded JSON of the generated image, if `response_format` is `b64_json`.\n\nThe URL of the generated image, if `response_format` is `url` (default).\n\n[](https://platform.openai.com/docs/api-reference/images/create)\n\n## [Create image](https://platform.openai.com/docs/api-reference/images/create)\n\npost\u00a0https://api.openai.com/v1/images/generations\n\nCreates an image given a prompt.\n\n### Request body\n\nA text description of the desired image(s). The maximum length is 1000 characters.\n\nThe number of images to generate. Must be between 1 and 10.\n\nThe format in which the generated images are returned. Must be one of `url` or `b64_json`.\n\nThe size of the generated images. Must be one of `256x256`, `512x512`, or `1024x1024`.\n\nA unique identifier representing your end-user, which can help OpenAI to monitor and detect abuse. [Learn more](https://platform.openai.com/docs/guides/safety-best-practices/end-user-ids).\n\n### Returns\n\nReturns a list of [image](https://platform.openai.com/docs/api-reference/images/object) objects.\n\n```\n1\n2\n3\n4\n5\n6\n7\n8\ncurl https://api.openai.com/v1/images/generations \\\n  -H \"Content-Type: application/json\" \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\" \\\n  -d '{\n    \"prompt\": \"A cute baby sea otter\",\n    \"n\": 2,\n    \"size\": \"1024x1024\"\n  }'\n```\n\n```\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n{\n  \"created\": 1589478378,\n  \"data\": [\n    {\n      \"url\": \"https://...\"\n    },\n    {\n      \"url\": \"https://...\"\n    }\n  ]\n}\n```\n\n[](https://platform.openai.com/docs/api-reference/images/createEdit)\n\n## [Create image edit](https://platform.openai.com/docs/api-reference/images/createEdit)\n\npost\u00a0https://api.openai.com/v1/images/edits\n\nCreates an edited or extended image given an original image and a prompt.\n\n### Request body\n\nThe image to edit. Must be a valid PNG file, less than 4MB, and square. If mask is not provided, image must have transparency, which will be used as the mask.\n\nA text description of the desired image(s). The maximum length is 1000 characters.\n\nAn additional image whose fully transparent areas (e.g. where alpha is zero) indicate where `image` should be edited. Must be a valid PNG file, less than 4MB, and have the same dimensions as `image`.\n\nThe number of images to generate. Must be between 1 and 10.\n\nThe size of the generated images. Must be one of `256x256`, `512x512`, or `1024x1024`.\n\nThe format in which the generated images are returned. Must be one of `url` or `b64_json`.\n\nA unique identifier representing your end-user, which can help OpenAI to monitor and detect abuse. [Learn more](https://platform.openai.com/docs/guides/safety-best-practices/end-user-ids).\n\n### Returns\n\nReturns a list of [image](https://platform.openai.com/docs/api-reference/images/object) objects.\n\n```\n1\n2\n3\n4\n5\n6\n7\ncurl https://api.openai.com/v1/images/edits \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\" \\\n  -F image=\"@otter.png\" \\\n  -F mask=\"@mask.png\" \\\n  -F prompt=\"A cute baby sea otter wearing a beret\" \\\n  -F n=2 \\\n  -F size=\"1024x1024\"\n```\n\n```\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n{\n  \"created\": 1589478378,\n  \"data\": [\n    {\n      \"url\": \"https://...\"\n    },\n    {\n      \"url\": \"https://...\"\n    }\n  ]\n}\n```\n\n[](https://platform.openai.com/docs/api-reference/images/createVariation)\n\n## [Create image variation](https://platform.openai.com/docs/api-reference/images/createVariation)\n\npost\u00a0https://api.openai.com/v1/images/variations\n\nCreates a variation of a given image.\n\n### Request body\n\nThe image to use as the basis for the variation(s). Must be a valid PNG file, less than 4MB, and square.\n\nThe number of images to generate. Must be between 1 and 10.\n\nThe format in which the generated images are returned. Must be one of `url` or `b64_json`.\n\nThe size of the generated images. Must be one of `256x256`, `512x512`, or `1024x1024`.\n\nA unique identifier representing your end-user, which can help OpenAI to monitor and detect abuse. [Learn more](https://platform.openai.com/docs/guides/safety-best-practices/end-user-ids).\n\n### Returns\n\nReturns a list of [image](https://platform.openai.com/docs/api-reference/images/object) objects.\n\n```\n1\n2\n3\n4\n5\ncurl https://api.openai.com/v1/images/variations \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\" \\\n  -F image=\"@otter.png\" \\\n  -F n=2 \\\n  -F size=\"1024x1024\"\n```\n\n```\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n{\n  \"created\": 1589478378,\n  \"data\": [\n    {\n      \"url\": \"https://...\"\n    },\n    {\n      \"url\": \"https://...\"\n    }\n  ]\n}\n```\n\n[](https://platform.openai.com/docs/api-reference/models)\n\n## [Models](https://platform.openai.com/docs/api-reference/models)\n\nList and describe the various models available in the API. You can refer to the [Models](https://platform.openai.com/docs/models) documentation to understand what models are available and the differences between them.\n\n[](https://platform.openai.com/docs/api-reference/models/object)\n\n## [The model object](https://platform.openai.com/docs/api-reference/models/object)\n\nDescribes an OpenAI model offering that can be used with the API.\n\nThe model identifier, which can be referenced in the API endpoints.\n\nThe Unix timestamp (in seconds) when the model was created.\n\nThe object type, which is always \"model\".\n\nThe organization that owns the model.\n\n```\n1\n2\n3\n4\n5\n6\n{\n  \"id\": \"davinci\",\n  \"object\": \"model\",\n  \"created\": 1686935002,\n  \"owned_by\": \"openai\"\n}\n```\n\n[](https://platform.openai.com/docs/api-reference/models/list)\n\n## [List models](https://platform.openai.com/docs/api-reference/models/list)\n\nget\u00a0https://api.openai.com/v1/models\n\nLists the currently available models, and provides basic information about each one such as the owner and availability.\n\n### Returns\n\n```\n1\n2\ncurl https://api.openai.com/v1/models \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\"\n```\n\n```\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n{\n  \"object\": \"list\",\n  \"data\": [\n    {\n      \"id\": \"model-id-0\",\n      \"object\": \"model\",\n      \"created\": 1686935002,\n      \"owned_by\": \"organization-owner\"\n    },\n    {\n      \"id\": \"model-id-1\",\n      \"object\": \"model\",\n      \"created\": 1686935002,\n      \"owned_by\": \"organization-owner\",\n    },\n    {\n      \"id\": \"model-id-2\",\n      \"object\": \"model\",\n      \"created\": 1686935002,\n      \"owned_by\": \"openai\"\n    },\n  ],\n  \"object\": \"list\"\n}\n```\n\n[](https://platform.openai.com/docs/api-reference/models/retrieve)\n\n## [Retrieve model](https://platform.openai.com/docs/api-reference/models/retrieve)\n\nget\u00a0https://api.openai.com/v1/models/{model}\n\nRetrieves a model instance, providing basic information about the model such as the owner and permissioning.\n\n### Path parameters\n\nThe ID of the model to use for this request\n\n### Returns\n\nThe [model](https://platform.openai.com/docs/api-reference/models/object) object matching the specified ID.\n\n```\n1\n2\ncurl https://api.openai.com/v1/models/gpt-3.5-turbo-instruct \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\"\n```\n\n```\n1\n2\n3\n4\n5\n6\n{\n  \"id\": \"gpt-3.5-turbo-instruct\",\n  \"object\": \"model\",\n  \"created\": 1686935002,\n  \"owned_by\": \"openai\"\n}\n```\n\n[](https://platform.openai.com/docs/api-reference/models/delete)\n\n## [Delete fine-tune model](https://platform.openai.com/docs/api-reference/models/delete)\n\ndelete\u00a0https://api.openai.com/v1/models/{model}\n\nDelete a fine-tuned model. You must have the Owner role in your organization to delete a model.\n\n### Path parameters\n\n### Returns\n\n```\n1\n2\n3\ncurl https://api.openai.com/v1/models/ft:gpt-3.5-turbo:acemeco:suffix:abc123 \\\n  -X DELETE \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\"\n```\n\n```\n1\n2\n3\n4\n5\n{\n  \"id\": \"ft:gpt-3.5-turbo:acemeco:suffix:abc123\",\n  \"object\": \"model\",\n  \"deleted\": true\n}\n```\n\n[](https://platform.openai.com/docs/api-reference/moderations)\n\n## [Moderations](https://platform.openai.com/docs/api-reference/moderations)\n\nGiven a input text, outputs if the model classifies it as violating OpenAI's content policy.\n\nRelated guide: [Moderations](https://platform.openai.com/docs/guides/moderation)\n\n[](https://platform.openai.com/docs/api-reference/moderations/object)\n\n## [The moderation object](https://platform.openai.com/docs/api-reference/moderations/object)\n\nRepresents policy compliance report by OpenAI's content moderation model against a given input.\n\nThe unique identifier for the moderation request.\n\nThe model used to generate the moderation results.\n\nA list of moderation objects.\n\n```\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n{\n  \"id\": \"modr-XXXXX\",\n  \"model\": \"text-moderation-005\",\n  \"results\": [\n    {\n      \"flagged\": true,\n      \"categories\": {\n        \"sexual\": false,\n        \"hate\": false,\n        \"harassment\": false,\n        \"self-harm\": false,\n        \"sexual/minors\": false,\n        \"hate/threatening\": false,\n        \"violence/graphic\": false,\n        \"self-harm/intent\": false,\n        \"self-harm/instructions\": false,\n        \"harassment/threatening\": true,\n        \"violence\": true,\n      },\n      \"category_scores\": {\n        \"sexual\": 1.2282071e-06,\n        \"hate\": 0.010696256,\n        \"harassment\": 0.29842457,\n        \"self-harm\": 1.5236925e-08,\n        \"sexual/minors\": 5.7246268e-08,\n        \"hate/threatening\": 0.0060676364,\n        \"violence/graphic\": 4.435014e-06,\n        \"self-harm/intent\": 8.098441e-10,\n        \"self-harm/instructions\": 2.8498655e-11,\n        \"harassment/threatening\": 0.63055265,\n        \"violence\": 0.99011886,\n      }\n    }\n  ]\n}\n```\n\n[](https://platform.openai.com/docs/api-reference/moderations/create)\n\n## [Create moderation](https://platform.openai.com/docs/api-reference/moderations/create)\n\npost\u00a0https://api.openai.com/v1/moderations\n\nClassifies if text violates OpenAI's Content Policy\n\n### Request body\n\nThe input text to classify\n\nTwo content moderations models are available: `text-moderation-stable` and `text-moderation-latest`.\n\nThe default is `text-moderation-latest` which will be automatically upgraded over time. This ensures you are always using our most accurate model. If you use `text-moderation-stable`, we will provide advanced notice before updating the model. Accuracy of `text-moderation-stable` may be slightly lower than for `text-moderation-latest`.\n\n### Returns\n\n```\n1\n2\n3\n4\n5\n6\ncurl https://api.openai.com/v1/moderations \\\n  -H \"Content-Type: application/json\" \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\" \\\n  -d '{\n    \"input\": \"I want to kill them.\"\n  }'\n```\n\n```\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n{\n  \"id\": \"modr-XXXXX\",\n  \"model\": \"text-moderation-005\",\n  \"results\": [\n    {\n      \"flagged\": true,\n      \"categories\": {\n        \"sexual\": false,\n        \"hate\": false,\n        \"harassment\": false,\n        \"self-harm\": false,\n        \"sexual/minors\": false,\n        \"hate/threatening\": false,\n        \"violence/graphic\": false,\n        \"self-harm/intent\": false,\n        \"self-harm/instructions\": false,\n        \"harassment/threatening\": true,\n        \"violence\": true,\n      },\n      \"category_scores\": {\n        \"sexual\": 1.2282071e-06,\n        \"hate\": 0.010696256,\n        \"harassment\": 0.29842457,\n        \"self-harm\": 1.5236925e-08,\n        \"sexual/minors\": 5.7246268e-08,\n        \"hate/threatening\": 0.0060676364,\n        \"violence/graphic\": 4.435014e-06,\n        \"self-harm/intent\": 8.098441e-10,\n        \"self-harm/instructions\": 2.8498655e-11,\n        \"harassment/threatening\": 0.63055265,\n        \"violence\": 0.99011886,\n      }\n    }\n  ]\n}\n```\n\nManage legacy fine-tuning jobs to tailor a model to your specific training data.\n\nWe recommend transitioning to the updating [fine-tuning API](https://platform.openai.com/docs/guides/fine-tuning)\n\nThe `FineTune` object represents a legacy fine-tune job that has been created through the API.\n\nThe object identifier, which can be referenced in the API endpoints.\n\nThe Unix timestamp (in seconds) for when the fine-tuning job was created.\n\nThe list of events that have been observed in the lifecycle of the FineTune job.\n\nThe name of the fine-tuned model that is being created.\n\nThe hyperparameters used for the fine-tuning job. See the [fine-tuning guide](https://platform.openai.com/docs/guides/legacy-fine-tuning/hyperparameters) for more details.\n\nThe base model that is being fine-tuned.\n\nThe object type, which is always \"fine-tune\".\n\nThe organization that owns the fine-tuning job.\n\nThe compiled results files for the fine-tuning job.\n\nThe current status of the fine-tuning job, which can be either `created`, `running`, `succeeded`, `failed`, or `cancelled`.\n\nThe list of files used for training.\n\nThe Unix timestamp (in seconds) for when the fine-tuning job was last updated.\n\nThe list of files used for validation.\n\n```\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n36\n37\n38\n39\n40\n41\n42\n43\n44\n45\n46\n47\n48\n49\n50\n51\n52\n53\n54\n55\n56\n57\n58\n59\n60\n61\n62\n63\n64\n65\n66\n67\n68\n69\n{\n  \"id\": \"ft-AF1WoRqd3aJAHsqc9NY7iL8F\",\n  \"object\": \"fine-tune\",\n  \"model\": \"curie\",\n  \"created_at\": 1614807352,\n  \"events\": [\n    {\n      \"object\": \"fine-tune-event\",\n      \"created_at\": 1614807352,\n      \"level\": \"info\",\n      \"message\": \"Job enqueued. Waiting for jobs ahead to complete. Queue number: 0.\"\n    },\n    {\n      \"object\": \"fine-tune-event\",\n      \"created_at\": 1614807356,\n      \"level\": \"info\",\n      \"message\": \"Job started.\"\n    },\n    {\n      \"object\": \"fine-tune-event\",\n      \"created_at\": 1614807861,\n      \"level\": \"info\",\n      \"message\": \"Uploaded snapshot: curie:ft-acmeco-2021-03-03-21-44-20.\"\n    },\n    {\n      \"object\": \"fine-tune-event\",\n      \"created_at\": 1614807864,\n      \"level\": \"info\",\n      \"message\": \"Uploaded result files: file-abc123.\"\n    },\n    {\n      \"object\": \"fine-tune-event\",\n      \"created_at\": 1614807864,\n      \"level\": \"info\",\n      \"message\": \"Job succeeded.\"\n    }\n  ],\n  \"fine_tuned_model\": \"curie:ft-acmeco-2021-03-03-21-44-20\",\n  \"hyperparams\": {\n    \"batch_size\": 4,\n    \"learning_rate_multiplier\": 0.1,\n    \"n_epochs\": 4,\n    \"prompt_loss_weight\": 0.1,\n  },\n  \"organization_id\": \"org-123\",\n  \"result_files\": [\n    {\n      \"id\": \"file-abc123\",\n      \"object\": \"file\",\n      \"bytes\": 81509,\n      \"created_at\": 1614807863,\n      \"filename\": \"compiled_results.csv\",\n      \"purpose\": \"fine-tune-results\"\n    }\n  ],\n  \"status\": \"succeeded\",\n  \"validation_files\": [],\n  \"training_files\": [\n    {\n      \"id\": \"file-abc123\",\n      \"object\": \"file\",\n      \"bytes\": 1547276,\n      \"created_at\": 1610062281,\n      \"filename\": \"my-data-train.jsonl\",\n      \"purpose\": \"fine-tune-train\"\n    }\n  ],\n  \"updated_at\": 1614807865,\n}\n```\n\npost\u00a0https://api.openai.com/v1/fine-tunes\n\nCreates a job that fine-tunes a specified model from a given dataset.\n\nResponse includes details of the enqueued job including job status and the name of the fine-tuned models once complete.\n\n[Learn more about fine-tuning](https://platform.openai.com/docs/guides/legacy-fine-tuning)\n\n### Request body\n\nThe ID of an uploaded file that contains training data.\n\nSee [upload file](https://platform.openai.com/docs/api-reference/files/upload) for how to upload a file.\n\nYour dataset must be formatted as a JSONL file, where each training example is a JSON object with the keys \"prompt\" and \"completion\". Additionally, you must upload your file with the purpose `fine-tune`.\n\nSee the [fine-tuning guide](https://platform.openai.com/docs/guides/legacy-fine-tuning/creating-training-data) for more details.\n\nThe batch size to use for training. The batch size is the number of training examples used to train a single forward and backward pass.\n\nBy default, the batch size will be dynamically configured to be ~0.2% of the number of examples in the training set, capped at 256 - in general, we've found that larger batch sizes tend to work better for larger datasets.\n\nIf this is provided, we calculate F-beta scores at the specified beta values. The F-beta score is a generalization of F-1 score. This is only used for binary classification.\n\nWith a beta of 1 (i.e. the F-1 score), precision and recall are given the same weight. A larger beta score puts more weight on recall and less on precision. A smaller beta score puts more weight on precision and less on recall.\n\nThe number of classes in a classification task.\n\nThis parameter is required for multiclass classification.\n\nThe positive class in binary classification.\n\nThis parameter is needed to generate precision, recall, and F1 metrics when doing binary classification.\n\nIf set, we calculate classification-specific metrics such as accuracy and F-1 score using the validation set at the end of every epoch. These metrics can be viewed in the [results file](https://platform.openai.com/docs/guides/legacy-fine-tuning/analyzing-your-fine-tuned-model).\n\nIn order to compute classification metrics, you must provide a `validation_file`. Additionally, you must specify `classification_n_classes` for multiclass classification or `classification_positive_class` for binary classification.\n\nThe hyperparameters used for the fine-tuning job.\n\nThe learning rate multiplier to use for training. The fine-tuning learning rate is the original learning rate used for pretraining multiplied by this value.\n\nBy default, the learning rate multiplier is the 0.05, 0.1, or 0.2 depending on final `batch_size` (larger learning rates tend to perform better with larger batch sizes). We recommend experimenting with values in the range 0.02 to 0.2 to see what produces the best results.\n\nThe name of the base model to fine-tune. You can select one of \"ada\", \"babbage\", \"curie\", \"davinci\", or a fine-tuned model created after 2022-04-21 and before 2023-08-22. To learn more about these models, see the [Models](https://platform.openai.com/docs/models) documentation.\n\nThe weight to use for loss on the prompt tokens. This controls how much the model tries to learn to generate the prompt (as compared to the completion which always has a weight of 1.0), and can add a stabilizing effect to training when completions are short.\n\nIf prompts are extremely long (relative to completions), it may make sense to reduce this weight so as to avoid over-prioritizing learning the prompt.\n\nA string of up to 40 characters that will be added to your fine-tuned model name.\n\nFor example, a `suffix` of \"custom-model-name\" would produce a model name like `ada:ft-your-org:custom-model-name-2022-02-15-04-21-04`.\n\nThe ID of an uploaded file that contains validation data.\n\nIf you provide this file, the data is used to generate validation metrics periodically during fine-tuning. These metrics can be viewed in the [fine-tuning results file](https://platform.openai.com/docs/guides/legacy-fine-tuning/analyzing-your-fine-tuned-model). Your train and validation data should be mutually exclusive.\n\nYour dataset must be formatted as a JSONL file, where each validation example is a JSON object with the keys \"prompt\" and \"completion\". Additionally, you must upload your file with the purpose `fine-tune`.\n\nSee the [fine-tuning guide](https://platform.openai.com/docs/guides/legacy-fine-tuning/creating-training-data) for more details.\n\n### Returns\n\n```\n1\n2\n3\n4\n5\n6\ncurl https://api.openai.com/v1/fine-tunes \\\n  -H \"Content-Type: application/json\" \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\" \\\n  -d '{\n    \"training_file\": \"file-abc123\"\n  }'\n```\n\n```\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n36\n{\n  \"id\": \"ft-AF1WoRqd3aJAHsqc9NY7iL8F\",\n  \"object\": \"fine-tune\",\n  \"model\": \"curie\",\n  \"created_at\": 1614807352,\n  \"events\": [\n    {\n      \"object\": \"fine-tune-event\",\n      \"created_at\": 1614807352,\n      \"level\": \"info\",\n      \"message\": \"Job enqueued. Waiting for jobs ahead to complete. Queue number: 0.\"\n    }\n  ],\n  \"fine_tuned_model\": null,\n  \"hyperparams\": {\n    \"batch_size\": 4,\n    \"learning_rate_multiplier\": 0.1,\n    \"n_epochs\": 4,\n    \"prompt_loss_weight\": 0.1,\n  },\n  \"organization_id\": \"org-123\",\n  \"result_files\": [],\n  \"status\": \"pending\",\n  \"validation_files\": [],\n  \"training_files\": [\n    {\n      \"id\": \"file-abc123\",\n      \"object\": \"file\",\n      \"bytes\": 1547276,\n      \"created_at\": 1610062281,\n      \"filename\": \"my-data-train.jsonl\",\n      \"purpose\": \"fine-tune-train\"\n    }\n  ],\n  \"updated_at\": 1614807352,\n}\n```\n\nget\u00a0https://api.openai.com/v1/fine-tunes\n\nList your organization's fine-tuning jobs\n\n### Returns\n\n```\n1\n2\ncurl https://api.openai.com/v1/fine-tunes \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\"\n```\n\n```\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n{\n  \"object\": \"list\",\n  \"data\": [\n    {\n      \"id\": \"ft-AF1WoRqd3aJAHsqc9NY7iL8F\",\n      \"object\": \"fine-tune\",\n      \"model\": \"curie\",\n      \"created_at\": 1614807352,\n      \"fine_tuned_model\": null,\n      \"hyperparams\": { ... },\n      \"organization_id\": \"org-123\",\n      \"result_files\": [],\n      \"status\": \"pending\",\n      \"validation_files\": [],\n      \"training_files\": [ { ... } ],\n      \"updated_at\": 1614807352,\n    },\n    { ... },\n    { ... }\n  ]\n}\n```\n\nget\u00a0https://api.openai.com/v1/fine-tunes/{fine\\_tune\\_id}\n\n### Path parameters\n\nThe ID of the fine-tune job\n\n### Returns\n\n```\n1\n2\ncurl https://api.openai.com/v1/fine-tunes/ft-AF1WoRqd3aJAHsqc9NY7iL8F \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\"\n```\n\n```\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n36\n37\n38\n39\n40\n41\n42\n43\n44\n45\n46\n47\n48\n49\n50\n51\n52\n53\n54\n55\n56\n57\n58\n59\n60\n61\n62\n63\n64\n65\n66\n67\n68\n69\n{\n  \"id\": \"ft-AF1WoRqd3aJAHsqc9NY7iL8F\",\n  \"object\": \"fine-tune\",\n  \"model\": \"curie\",\n  \"created_at\": 1614807352,\n  \"events\": [\n    {\n      \"object\": \"fine-tune-event\",\n      \"created_at\": 1614807352,\n      \"level\": \"info\",\n      \"message\": \"Job enqueued. Waiting for jobs ahead to complete. Queue number: 0.\"\n    },\n    {\n      \"object\": \"fine-tune-event\",\n      \"created_at\": 1614807356,\n      \"level\": \"info\",\n      \"message\": \"Job started.\"\n    },\n    {\n      \"object\": \"fine-tune-event\",\n      \"created_at\": 1614807861,\n      \"level\": \"info\",\n      \"message\": \"Uploaded snapshot: curie:ft-acmeco-2021-03-03-21-44-20.\"\n    },\n    {\n      \"object\": \"fine-tune-event\",\n      \"created_at\": 1614807864,\n      \"level\": \"info\",\n      \"message\": \"Uploaded result files: file-abc123.\"\n    },\n    {\n      \"object\": \"fine-tune-event\",\n      \"created_at\": 1614807864,\n      \"level\": \"info\",\n      \"message\": \"Job succeeded.\"\n    }\n  ],\n  \"fine_tuned_model\": \"curie:ft-acmeco-2021-03-03-21-44-20\",\n  \"hyperparams\": {\n    \"batch_size\": 4,\n    \"learning_rate_multiplier\": 0.1,\n    \"n_epochs\": 4,\n    \"prompt_loss_weight\": 0.1,\n  },\n  \"organization_id\": \"org-123\",\n  \"result_files\": [\n    {\n      \"id\": \"file-abc123\",\n      \"object\": \"file\",\n      \"bytes\": 81509,\n      \"created_at\": 1614807863,\n      \"filename\": \"compiled_results.csv\",\n      \"purpose\": \"fine-tune-results\"\n    }\n  ],\n  \"status\": \"succeeded\",\n  \"validation_files\": [],\n  \"training_files\": [\n    {\n      \"id\": \"file-abc123\",\n      \"object\": \"file\",\n      \"bytes\": 1547276,\n      \"created_at\": 1610062281,\n      \"filename\": \"my-data-train.jsonl\",\n      \"purpose\": \"fine-tune-train\"\n    }\n  ],\n  \"updated_at\": 1614807865,\n}\n```\n\npost\u00a0https://api.openai.com/v1/fine-tunes/{fine\\_tune\\_id}/cancel\n\nImmediately cancel a fine-tune job.\n\n### Path parameters\n\nThe ID of the fine-tune job to cancel\n\n### Returns\n\n```\n1\n2\ncurl https://api.openai.com/v1/fine-tunes/ft-AF1WoRqd3aJAHsqc9NY7iL8F/cancel \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\"\n```\n\n```\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n{\n  \"id\": \"ft-xhrpBbvVUzYGo8oUO1FY4nI7\",\n  \"object\": \"fine-tune\",\n  \"model\": \"curie\",\n  \"created_at\": 1614807770,\n  \"events\": [ { ... } ],\n  \"fine_tuned_model\": null,\n  \"hyperparams\": { ... },\n  \"organization_id\": \"org-123\",\n  \"result_files\": [],\n  \"status\": \"cancelled\",\n  \"validation_files\": [],\n  \"training_files\": [\n    {\n      \"id\": \"file-abc123\",\n      \"object\": \"file\",\n      \"bytes\": 1547276,\n      \"created_at\": 1610062281,\n      \"filename\": \"my-data-train.jsonl\",\n      \"purpose\": \"fine-tune-train\"\n    }\n  ],\n  \"updated_at\": 1614807789,\n}\n```\n\n```\n1\n2\n3\n4\n5\n6\n{\n  \"object\": \"event\",\n  \"created_at\": 1677610602,\n  \"level\": \"info\",\n  \"message\": \"Created fine-tune job\"\n}\n```\n\nget\u00a0https://api.openai.com/v1/fine-tunes/{fine\\_tune\\_id}/events\n\nGet fine-grained status updates for a fine-tune job.\n\n### Path parameters\n\nThe ID of the fine-tune job to get events for.\n\n### Query parameters\n\nWhether to stream events for the fine-tune job. If set to true, events will be sent as data-only [server-sent events](https://developer.mozilla.org/en-US/docs/Web/API/Server-sent_events/Using_server-sent_events#Event_stream_format) as they become available. The stream will terminate with a `data: [DONE]` message when the job is finished (succeeded, cancelled, or failed).\n\nIf set to false, only events generated so far will be returned.\n\n### Returns\n\nA list of fine-tune event objects.\n\n```\n1\n2\ncurl https://api.openai.com/v1/fine-tunes/ft-AF1WoRqd3aJAHsqc9NY7iL8F/events \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\"\n```\n\n```\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n{\n  \"object\": \"list\",\n  \"data\": [\n    {\n      \"object\": \"fine-tune-event\",\n      \"created_at\": 1614807352,\n      \"level\": \"info\",\n      \"message\": \"Job enqueued. Waiting for jobs ahead to complete. Queue number: 0.\"\n    },\n    {\n      \"object\": \"fine-tune-event\",\n      \"created_at\": 1614807356,\n      \"level\": \"info\",\n      \"message\": \"Job started.\"\n    },\n    {\n      \"object\": \"fine-tune-event\",\n      \"created_at\": 1614807861,\n      \"level\": \"info\",\n      \"message\": \"Uploaded snapshot: curie:ft-acmeco-2021-03-03-21-44-20.\"\n    },\n    {\n      \"object\": \"fine-tune-event\",\n      \"created_at\": 1614807864,\n      \"level\": \"info\",\n      \"message\": \"Uploaded result files: file-abc123\"\n    },\n    {\n      \"object\": \"fine-tune-event\",\n      \"created_at\": 1614807864,\n      \"level\": \"info\",\n      \"message\": \"Job succeeded.\"\n    }\n  ]\n}\n```\n\nGiven a prompt and an instruction, the model will return an edited version of the prompt.\n\nA list of edit choices. Can be more than one if `n` is greater than 1.\n\nThe object type, which is always `edit`.\n\nThe Unix timestamp (in seconds) of when the edit was created.\n\nUsage statistics for the completion request.\n\n```\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n{\n  \"object\": \"edit\",\n  \"created\": 1589478378,\n  \"choices\": [\n    {\n      \"text\": \"What day of the week is it?\",\n      \"index\": 0,\n    }\n  ],\n  \"usage\": {\n    \"prompt_tokens\": 25,\n    \"completion_tokens\": 32,\n    \"total_tokens\": 57\n  }\n}\n```\n\npost\u00a0https://api.openai.com/v1/edits\n\nCreates a new edit for the provided input, instruction, and parameters.\n\n### Request body\n\nThe instruction that tells the model how to edit the prompt.\n\nID of the model to use. You can use the `text-davinci-edit-001` or `code-davinci-edit-001` model with this endpoint.\n\nThe input text to use as a starting point for the edit.\n\nHow many edits to generate for the input and instruction.\n\nWhat sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic.\n\nWe generally recommend altering this or `top_p` but not both.\n\nAn alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top\\_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered.\n\nWe generally recommend altering this or `temperature` but not both.\n\n### Returns\n\n```\n1\n2\n3\n4\n5\n6\n7\n8\ncurl https://api.openai.com/v1/edits \\\n  -H \"Content-Type: application/json\" \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\" \\\n  -d '{\n    \"model\": \"text-davinci-edit-001\",\n    \"input\": \"What day of the wek is it?\",\n    \"instruction\": \"Fix the spelling mistakes\"\n  }'\n```\n\n```\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n{\n  \"object\": \"edit\",\n  \"created\": 1589478378,\n  \"choices\": [\n    {\n      \"text\": \"What day of the week is it?\",\n      \"index\": 0,\n    }\n  ],\n  \"usage\": {\n    \"prompt_tokens\": 25,\n    \"completion_tokens\": 32,\n    \"total_tokens\": 57\n  }\n}\n```"
}