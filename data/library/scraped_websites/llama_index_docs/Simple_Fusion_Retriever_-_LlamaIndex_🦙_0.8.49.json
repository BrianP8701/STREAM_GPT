{
    "metadata": {
        "type": "web",
        "url": "https://docs.llamaindex.ai/en/stable/examples/retrievers/simple_fusion.html",
        "title": "Simple Fusion Retriever - LlamaIndex \ud83e\udd99 0.8.49",
        "description": null
    },
    "text": "[Back to top](#)\n\nToggle table of contents sidebar\n\n## Simple Fusion Retriever[\uf0c1](#simple-fusion-retriever \"Permalink to this heading\")\n\nIn this example, we walk through how you can combine retireval results from multiple queries and multiple indexes.\n\nThe retrieved nodes will be returned as the top-k across all queries and indexes, as well as handling de-duplication of any nodes.\n\nimport os\nimport openai\n\nos.environ\\[\"OPENAI\\_API\\_KEY\"\\] \\= \"sk-...\"\nopenai.api\\_key \\= os.environ\\[\"OPENAI\\_API\\_KEY\"\\]\n\n## Setup[\uf0c1](#setup \"Permalink to this heading\")\n\nFor this notebook, we will use two very similar pages of our documentation, each stored in a separaete index.\n\nfrom llama\\_index import SimpleDirectoryReader\n\ndocuments\\_1 \\= SimpleDirectoryReader(\n    input\\_files\\=\\[\"../../community/integrations/vector\\_stores.md\"\\]\n).load\\_data()\ndocuments\\_2 \\= SimpleDirectoryReader(\n    input\\_files\\=\\[\"../../core\\_modules/data\\_modules/storage/vector\\_stores.md\"\\]\n).load\\_data()\n\nfrom llama\\_index import VectorStoreIndex\n\nindex\\_1 \\= VectorStoreIndex.from\\_documents(documents\\_1)\nindex\\_2 \\= VectorStoreIndex.from\\_documents(documents\\_2)\n\n## Fuse the Indexes![\uf0c1](#fuse-the-indexes \"Permalink to this heading\")\n\nIn this step, we fuse our indexes into a single retriever. This retriever will also generate augment our query by generating extra queries related to the original question, and aggregate the results.\n\nThis setup will query 4 times, once with your original query, and generate 3 more queries.\n\nBy default, it uses the following prompt to generate extra queries:\n\nQUERY\\_GEN\\_PROMPT \\= (\n    \"You are a helpful assistant that generates multiple search queries based on a \"\n    \"single input query. Generate {num\\_queries} search queries, one on each line, \"\n    \"related to the following input query:\\\\n\"\n    \"Query: {query}\\\\n\"\n    \"Queries:\\\\n\"\n)\n\nfrom llama\\_index.retrievers import QueryFusionRetriever\n\nretriever \\= QueryFusionRetriever(\n    \\[index\\_1.as\\_retriever(), index\\_2.as\\_retriever()\\],\n    similarity\\_top\\_k\\=2,\n    num\\_queries\\=4,  \\# set this to 1 to disable query generation\n    use\\_async\\=True,\n    verbose\\=True,\n    \\# query\\_gen\\_prompt=\"...\",  # we could override the query generation prompt here\n)\n\n\\# apply nested async to run in a notebook\nimport nest\\_asyncio\n\nnest\\_asyncio.apply()\n\nnodes\\_with\\_scores \\= retriever.retrieve(\"How do I setup a chroma vector store?\")\n\nGenerated queries:\n1. What are the steps to set up a chroma vector store?\n2. Best practices for setting up a chroma vector store\n3. Troubleshooting common issues when setting up a chroma vector store\n\nfor node in nodes\\_with\\_scores:\n    print(f\"Score: {node.score:.2f} - {node.text\\[:100\\]}...\")\n\nScore: 0.81 - construct vector store\nneo4j\\_vector = Neo4jVectorStore(\n    username=\"neo4j\",\n    password=\"pleasele...\nScore: 0.80 - construct vector store\nvector\\_store = ChromaVectorStore(\n    chroma\\_collection=chroma\\_collection,\n)\n...\n\n## Use in a Query Engine![\uf0c1](#use-in-a-query-engine \"Permalink to this heading\")\n\nNow, we can plug our retriever into a query engine to synthesize natural language responses.\n\nfrom llama\\_index.query\\_engine import RetrieverQueryEngine\n\nquery\\_engine \\= RetrieverQueryEngine.from\\_args(retriever)\n\nresponse \\= query\\_engine.query(\n    \"How do I setup a chroma vector store? Can you give an example?\"\n)\n\nGenerated queries:\n1. How to set up a chroma vector store?\n2. Step-by-step guide for creating a chroma vector store.\n3. Examples of chroma vector store setups and configurations.\n\nfrom llama\\_index.response.notebook\\_utils import display\\_response\n\ndisplay\\_response(response)\n\n**`Final Response:`** To set up a Chroma Vector Store, you can use the `ChromaVectorStore` class from the `llama_index.vector_stores` module. Here is an example of how to set it up:\n\nfrom llama\\_index.vector\\_stores import ChromaVectorStore\n\n\\# Assuming you have a chroma\\_collection variable\nvector\\_store \\= ChromaVectorStore(\n    chroma\\_collection\\=chroma\\_collection,\n)\n\nThis code creates an instance of the `ChromaVectorStore` class, passing in the `chroma_collection` as a parameter."
}