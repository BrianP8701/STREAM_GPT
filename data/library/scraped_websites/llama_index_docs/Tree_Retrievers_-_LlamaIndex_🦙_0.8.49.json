{
    "metadata": {
        "type": "web",
        "url": "https://docs.llamaindex.ai/en/stable/api_reference/query/retrievers/tree.html",
        "title": "Tree Retrievers - LlamaIndex \ud83e\udd99 0.8.49",
        "description": null
    },
    "text": "[Back to top](#)\n\nToggle table of contents sidebar\n\n## Tree Retrievers[\uf0c1](#module-llama_index.indices.tree.all_leaf_retriever \"Permalink to this heading\")\n\nSummarize query.\n\n_class_ llama\\_index.indices.tree.all\\_leaf\\_retriever.TreeAllLeafRetriever(_index: [TreeIndex](https://docs.llamaindex.ai/en/stable/api_reference/indices/tree.html#llama_index.indices.tree.TreeIndex \"llama_index.indices.tree.base.TreeIndex\")_, _\\*\\*kwargs: Any_)[\uf0c1](#llama_index.indices.tree.all_leaf_retriever.TreeAllLeafRetriever \"Permalink to this definition\")\n\nGPT all leaf retriever.\n\nThis class builds a query-specific tree from leaf nodes to return a response. Using this query mode means that the tree index doesn\u2019t need to be built when initialized, since we rebuild the tree for each query.\n\nParameters\n\n**text\\_qa\\_template** (_Optional__\\[_[_BasePromptTemplate_](https://docs.llamaindex.ai/en/stable/api_reference/prompts.html#llama_index.prompts.base.BasePromptTemplate \"llama_index.prompts.base.BasePromptTemplate\")_\\]_) \u2013 Question-Answer Prompt (see [Prompt Templates](https://docs.llamaindex.ai/en/stable/api_reference/prompts.html#prompt-templates)).\n\nget\\_service\\_context() \u2192 Optional\\[[ServiceContext](https://docs.llamaindex.ai/en/stable/api_reference/service_context.html#llama_index.indices.service_context.ServiceContext \"llama_index.indices.service_context.ServiceContext\")\\][\uf0c1](#llama_index.indices.tree.all_leaf_retriever.TreeAllLeafRetriever.get_service_context \"Permalink to this definition\")\n\nAttempts to resolve a service context. Short-circuits at self.service\\_context, self.\\_service\\_context, or self.\\_index.service\\_context.\n\nretrieve(_str\\_or\\_query\\_bundle: Union\\[str, [QueryBundle](https://docs.llamaindex.ai/en/stable/api_reference/query/query_bundle.html#llama_index.indices.query.schema.QueryBundle \"llama_index.indices.query.schema.QueryBundle\")\\]_) \u2192 List\\[[NodeWithScore](https://docs.llamaindex.ai/en/stable/api_reference/node.html#llama_index.schema.NodeWithScore \"llama_index.schema.NodeWithScore\")\\][\uf0c1](#llama_index.indices.tree.all_leaf_retriever.TreeAllLeafRetriever.retrieve \"Permalink to this definition\")\n\nRetrieve nodes given query.\n\nParameters\n\n**str\\_or\\_query\\_bundle** (_QueryType_) \u2013 Either a query string or a QueryBundle object.\n\nLeaf query mechanism.\n\n_class_ llama\\_index.indices.tree.select\\_leaf\\_retriever.TreeSelectLeafRetriever(_index: [TreeIndex](https://docs.llamaindex.ai/en/stable/api_reference/indices/tree.html#llama_index.indices.tree.TreeIndex \"llama_index.indices.tree.base.TreeIndex\")_, _query\\_template: Optional\\[[BasePromptTemplate](https://docs.llamaindex.ai/en/stable/api_reference/prompts.html#llama_index.prompts.base.BasePromptTemplate \"llama_index.prompts.base.BasePromptTemplate\")\\] \\= None_, _text\\_qa\\_template: Optional\\[[BasePromptTemplate](https://docs.llamaindex.ai/en/stable/api_reference/prompts.html#llama_index.prompts.base.BasePromptTemplate \"llama_index.prompts.base.BasePromptTemplate\")\\] \\= None_, _refine\\_template: Optional\\[[BasePromptTemplate](https://docs.llamaindex.ai/en/stable/api_reference/prompts.html#llama_index.prompts.base.BasePromptTemplate \"llama_index.prompts.base.BasePromptTemplate\")\\] \\= None_, _query\\_template\\_multiple: Optional\\[[BasePromptTemplate](https://docs.llamaindex.ai/en/stable/api_reference/prompts.html#llama_index.prompts.base.BasePromptTemplate \"llama_index.prompts.base.BasePromptTemplate\")\\] \\= None_, _child\\_branch\\_factor: int \\= 1_, _verbose: bool \\= False_, _\\*\\*kwargs: Any_)[\uf0c1](#llama_index.indices.tree.select_leaf_retriever.TreeSelectLeafRetriever \"Permalink to this definition\")\n\nTree select leaf retriever.\n\nThis class traverses the index graph and searches for a leaf node that can best answer the query.\n\nParameters\n\n*   **query\\_template** (_Optional__\\[_[_BasePromptTemplate_](https://docs.llamaindex.ai/en/stable/api_reference/prompts.html#llama_index.prompts.base.BasePromptTemplate \"llama_index.prompts.base.BasePromptTemplate\")_\\]_) \u2013 Tree Select Query Prompt (see [Prompt Templates](https://docs.llamaindex.ai/en/stable/api_reference/prompts.html#prompt-templates)).\n    \n*   **query\\_template\\_multiple** (_Optional__\\[_[_BasePromptTemplate_](https://docs.llamaindex.ai/en/stable/api_reference/prompts.html#llama_index.prompts.base.BasePromptTemplate \"llama_index.prompts.base.BasePromptTemplate\")_\\]_) \u2013 Tree Select Query Prompt (Multiple) (see [Prompt Templates](https://docs.llamaindex.ai/en/stable/api_reference/prompts.html#prompt-templates)).\n    \n*   **child\\_branch\\_factor** (_int_) \u2013 Number of child nodes to consider at each level. If child\\_branch\\_factor is 1, then the query will only choose one child node to traverse for any given parent node. If child\\_branch\\_factor is 2, then the query will choose two child nodes.\n    \n\nget\\_service\\_context() \u2192 Optional\\[[ServiceContext](https://docs.llamaindex.ai/en/stable/api_reference/service_context.html#llama_index.indices.service_context.ServiceContext \"llama_index.indices.service_context.ServiceContext\")\\][\uf0c1](#llama_index.indices.tree.select_leaf_retriever.TreeSelectLeafRetriever.get_service_context \"Permalink to this definition\")\n\nAttempts to resolve a service context. Short-circuits at self.service\\_context, self.\\_service\\_context, or self.\\_index.service\\_context.\n\nretrieve(_str\\_or\\_query\\_bundle: Union\\[str, [QueryBundle](https://docs.llamaindex.ai/en/stable/api_reference/query/query_bundle.html#llama_index.indices.query.schema.QueryBundle \"llama_index.indices.query.schema.QueryBundle\")\\]_) \u2192 List\\[[NodeWithScore](https://docs.llamaindex.ai/en/stable/api_reference/node.html#llama_index.schema.NodeWithScore \"llama_index.schema.NodeWithScore\")\\][\uf0c1](#llama_index.indices.tree.select_leaf_retriever.TreeSelectLeafRetriever.retrieve \"Permalink to this definition\")\n\nRetrieve nodes given query.\n\nParameters\n\n**str\\_or\\_query\\_bundle** (_QueryType_) \u2013 Either a query string or a QueryBundle object.\n\nllama\\_index.indices.tree.select\\_leaf\\_retriever.get\\_text\\_from\\_node(_node: [BaseNode](https://docs.llamaindex.ai/en/stable/api_reference/node.html#llama_index.schema.BaseNode \"llama_index.schema.BaseNode\")_, _level: Optional\\[int\\] \\= None_, _verbose: bool \\= False_) \u2192 str[\uf0c1](#llama_index.indices.tree.select_leaf_retriever.get_text_from_node \"Permalink to this definition\")\n\nGet text from node.\n\nQuery Tree using embedding similarity between query and node text.\n\n_class_ llama\\_index.indices.tree.select\\_leaf\\_embedding\\_retriever.TreeSelectLeafEmbeddingRetriever(_index: [TreeIndex](https://docs.llamaindex.ai/en/stable/api_reference/indices/tree.html#llama_index.indices.tree.TreeIndex \"llama_index.indices.tree.base.TreeIndex\")_, _query\\_template: Optional\\[[BasePromptTemplate](https://docs.llamaindex.ai/en/stable/api_reference/prompts.html#llama_index.prompts.base.BasePromptTemplate \"llama_index.prompts.base.BasePromptTemplate\")\\] \\= None_, _text\\_qa\\_template: Optional\\[[BasePromptTemplate](https://docs.llamaindex.ai/en/stable/api_reference/prompts.html#llama_index.prompts.base.BasePromptTemplate \"llama_index.prompts.base.BasePromptTemplate\")\\] \\= None_, _refine\\_template: Optional\\[[BasePromptTemplate](https://docs.llamaindex.ai/en/stable/api_reference/prompts.html#llama_index.prompts.base.BasePromptTemplate \"llama_index.prompts.base.BasePromptTemplate\")\\] \\= None_, _query\\_template\\_multiple: Optional\\[[BasePromptTemplate](https://docs.llamaindex.ai/en/stable/api_reference/prompts.html#llama_index.prompts.base.BasePromptTemplate \"llama_index.prompts.base.BasePromptTemplate\")\\] \\= None_, _child\\_branch\\_factor: int \\= 1_, _verbose: bool \\= False_, _\\*\\*kwargs: Any_)[\uf0c1](#llama_index.indices.tree.select_leaf_embedding_retriever.TreeSelectLeafEmbeddingRetriever \"Permalink to this definition\")\n\nTree select leaf embedding retriever.\n\nThis class traverses the index graph using the embedding similarity between the query and the node text.\n\nParameters\n\n*   **query\\_template** (_Optional__\\[_[_BasePromptTemplate_](https://docs.llamaindex.ai/en/stable/api_reference/prompts.html#llama_index.prompts.base.BasePromptTemplate \"llama_index.prompts.base.BasePromptTemplate\")_\\]_) \u2013 Tree Select Query Prompt (see [Prompt Templates](https://docs.llamaindex.ai/en/stable/api_reference/prompts.html#prompt-templates)).\n    \n*   **query\\_template\\_multiple** (_Optional__\\[_[_BasePromptTemplate_](https://docs.llamaindex.ai/en/stable/api_reference/prompts.html#llama_index.prompts.base.BasePromptTemplate \"llama_index.prompts.base.BasePromptTemplate\")_\\]_) \u2013 Tree Select Query Prompt (Multiple) (see [Prompt Templates](https://docs.llamaindex.ai/en/stable/api_reference/prompts.html#prompt-templates)).\n    \n*   **text\\_qa\\_template** (_Optional__\\[_[_BasePromptTemplate_](https://docs.llamaindex.ai/en/stable/api_reference/prompts.html#llama_index.prompts.base.BasePromptTemplate \"llama_index.prompts.base.BasePromptTemplate\")_\\]_) \u2013 Question-Answer Prompt (see [Prompt Templates](https://docs.llamaindex.ai/en/stable/api_reference/prompts.html#prompt-templates)).\n    \n*   **refine\\_template** (_Optional__\\[_[_BasePromptTemplate_](https://docs.llamaindex.ai/en/stable/api_reference/prompts.html#llama_index.prompts.base.BasePromptTemplate \"llama_index.prompts.base.BasePromptTemplate\")_\\]_) \u2013 Refinement Prompt (see [Prompt Templates](https://docs.llamaindex.ai/en/stable/api_reference/prompts.html#prompt-templates)).\n    \n*   **child\\_branch\\_factor** (_int_) \u2013 Number of child nodes to consider at each level. If child\\_branch\\_factor is 1, then the query will only choose one child node to traverse for any given parent node. If child\\_branch\\_factor is 2, then the query will choose two child nodes.\n    \n*   **embed\\_model** (_Optional__\\[__BaseEmbedding__\\]_) \u2013 Embedding model to use for embedding similarity.\n    \n\nget\\_service\\_context() \u2192 Optional\\[[ServiceContext](https://docs.llamaindex.ai/en/stable/api_reference/service_context.html#llama_index.indices.service_context.ServiceContext \"llama_index.indices.service_context.ServiceContext\")\\][\uf0c1](#llama_index.indices.tree.select_leaf_embedding_retriever.TreeSelectLeafEmbeddingRetriever.get_service_context \"Permalink to this definition\")\n\nAttempts to resolve a service context. Short-circuits at self.service\\_context, self.\\_service\\_context, or self.\\_index.service\\_context.\n\nretrieve(_str\\_or\\_query\\_bundle: Union\\[str, [QueryBundle](https://docs.llamaindex.ai/en/stable/api_reference/query/query_bundle.html#llama_index.indices.query.schema.QueryBundle \"llama_index.indices.query.schema.QueryBundle\")\\]_) \u2192 List\\[[NodeWithScore](https://docs.llamaindex.ai/en/stable/api_reference/node.html#llama_index.schema.NodeWithScore \"llama_index.schema.NodeWithScore\")\\][\uf0c1](#llama_index.indices.tree.select_leaf_embedding_retriever.TreeSelectLeafEmbeddingRetriever.retrieve \"Permalink to this definition\")\n\nRetrieve nodes given query.\n\nParameters\n\n**str\\_or\\_query\\_bundle** (_QueryType_) \u2013 Either a query string or a QueryBundle object."
}