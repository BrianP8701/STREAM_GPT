{
    "metadata": {
        "type": "web",
        "url": "https://docs.llamaindex.ai/en/stable/examples/vector_stores/Elasticsearch_demo.html",
        "title": "Elasticsearch - LlamaIndex \ud83e\udd99 0.8.49",
        "description": null
    },
    "text": "[Back to top](#)\n\nToggle table of contents sidebar\n\n## Elasticsearch[\uf0c1](#elasticsearch \"Permalink to this heading\")\n\n> [Elasticsearch](http://www.github.com/elastic/elasticsearch) is a search database, that supports full text and vector searches.\n\n## Basic Example[\uf0c1](#basic-example \"Permalink to this heading\")\n\nIn this basic example, we take the a Paul Graham essay, split it into chunks, embed it using an open-source embedding model, load it into Elasticsearch, and then query it.\n\n\\# !pip install llama-index elasticsearch --quiet\n\\# !pip install sentence-transformers\n\\# !pip install pydantic==1.10.11\n\n\\# import\nfrom llama\\_index import VectorStoreIndex, SimpleDirectoryReader, ServiceContext\nfrom llama\\_index.vector\\_stores import ElasticsearchStore\nfrom llama\\_index.storage.storage\\_context import StorageContext\nfrom IPython.display import Markdown, display\n\n\\# set up OpenAI\nimport os\nimport getpass\n\nos.environ\\[\"OPENAI\\_API\\_KEY\"\\] \\= getpass.getpass(\"OpenAI API Key:\")\nimport openai\n\nopenai.api\\_key \\= os.environ\\[\"OPENAI\\_API\\_KEY\"\\]\n\n\\# define embedding function\nembed\\_model \\= \"local/BAAI/bge-small-en-v1.5\"\n\n\\# load documents\ndocuments \\= SimpleDirectoryReader(\n    \"../../../examples/paul\\_graham\\_essay/data\"\n).load\\_data()\n\nvector\\_store \\= ElasticsearchStore(\n    index\\_name\\=\"paul\\_graham\\_essay\", es\\_url\\=\"http://localhost:9200\"\n)\nstorage\\_context \\= StorageContext.from\\_defaults(vector\\_store\\=vector\\_store)\nservice\\_context \\= ServiceContext.from\\_defaults(embed\\_model\\=embed\\_model)\nindex \\= VectorStoreIndex.from\\_documents(\n    documents, storage\\_context\\=storage\\_context, service\\_context\\=service\\_context\n)\n\n\\# Query Data\nquery\\_engine \\= index.as\\_query\\_engine()\nresponse \\= query\\_engine.query(\"What did the author do growing up?\")\ndisplay(Markdown(f\"<b>{response}</b>\"))\n\n**The author worked on writing and programming outside of school. They wrote short stories and tried writing programs on an IBM 1401 computer. They also built a microcomputer kit and started programming on it, writing simple games and a word processor.**"
}