{
    "metadata": {
        "type": "repo",
        "path": "src/helpers/preprocessing.py"
    },
    "text": "'''\n    This file contains functions for preprocessing images.\n    These are the functions meant to be used:\n\n        - gmms_preprocess_image: This function preprocesses an image using a Gaussian Mixture Model with extra sensitivity for material.\n        - gmm_preprocess_image: This function preprocesses an image using a Gaussian Mixture Model.\n        - resize_image: This function simply rescales images to a square of size x size pixels. Meant to work with square images.\n        - pad_image: This function pads images to a square of size x size pixels. Meant to work with square images.\n        - simplify: This function simplifies the image by emphasizing edges and reducing noise through color simplification based on pixel color variation.\n        - preprocess_image: This function preprocesses an image by removing noise and emphasizing edges.\n        - augment_dataset: This function augments a dataset by applying random rotations and color jitter to images.\n        - convert_to_grayscale_recursive: This function converts all images in a folder to grayscale.\n        - gmm_parameters: This function fits a Gaussian Mixture Model to an image and returns the means and variances of each cluster.\n        - create_bar_chart: This function creates a bar chart with the pixel intensities on the x-axis and the counts on the y-axis.\n        - create_bar_chart_with_gmm: This function creates a bar chart with the pixel intensities on the x-axis and the counts on the y-axis. It also adds a red line at means and blue lines at means +/- standard deviations.\n'''\nfrom PIL import Image, ImageOps, ImageFilter\nimport numpy as np\nimport cv2\nfrom sklearn.mixture import GaussianMixture\n\n'''\nGaussian Mixture Model Preprocessing with Extra Sensitivty for Material\n\n    Params:\n        img_path: path to image\n        num_components: number of clusters to fit\n    \n    Returns:\n        data: A 2d numpy array. Simplified image split into num_components+1 homogneous \n        regions, with a focus on the recently extruded material\n'''\ndef gmms_preprocess_image(img, num_components):\n    img = np.dot(img[...,:3], [0.299, 0.587, 0.114])\n    original_shape = img.shape\n    img = flatten(img)\n    \n    # Get means and variances assuming 3 clusters\n    means, stdvs = gmm_parameters(img, 3)    \n\n    # Get information of the cluster with the highest mean\n    means = np.sort(means)\n    stdvs = np.sqrt(np.sort(stdvs))\n    max_mean = means[-1]\n    max_stdv = stdvs[-1] * 2\n    if(max_stdv > 40): max_stdv = 50\n    \n    # This is the range of intensities we believe make up the recently extruded material\n    material_range = (max_mean - max_stdv, max_mean + max_stdv)\n    material_indices = get_indices_within_range(img, material_range)\n    material_data = img[material_indices]\n    \n    # Split the material data into num_components clusters\n    material_means, material_stdvs = gmm_parameters(material_data, num_components)\n    material_means = np.sort(material_means)\n    material_stdvs = np.sqrt(np.sort(material_stdvs))\n    \n    # Combine information from first cluster, and the material clusters\n    total_means = np.insert(material_means, 0, means[0])\n    total_stdvs = np.insert(material_stdvs, 0, stdvs[0])\n        \n    # Given the means and standard deviations, split the range 0-255 into 4 intervals\n    ranges = get_ranges(total_means, total_stdvs)\n    \n    # Create a list of colors to use for each range\n    colors = []\n    for i in range(num_components+1):\n        colors.append((255/(num_components+1))*i)\n    \n    # Replace all values in the data that fall within the ranges with the corresponding color\n    for i in range(num_components+1):\n        img = replace_values_within_range(img, ranges[i], colors[i])\n    \n    img = unflatten(img, original_shape)\n    return img\n\n\n# Simply rescales images to a square of size x size pixels. Meant to work with square images.\ndef resize_image(input_path, output_path, size):\n    with Image.open(input_path) as img:\n        img_resized = img.resize((size, size))\n        img_resized.save(output_path)\n        \n        \n# Pads images to a square of size x size pixels. Meant to work with square images.\ndef pad_image(input_path, output_path, final_size):\n    with Image.open(input_path) as img:\n        width, height = img.size\n\n        new_width = final_size\n        new_height = final_size\n\n        left_padding = (new_width - width) // 2\n        top_padding = (new_height - height) // 2\n        right_padding = new_width - width - left_padding\n        bottom_padding = new_height - height - top_padding\n\n        img_with_border = ImageOps.expand(img, (left_padding, top_padding, right_padding, bottom_padding), fill='black')\n        img_with_border.save(output_path)\n\n\n# The method simplifies the image by emphasizing edges and reducing noise through color simplification based on pixel color variation.\ndef simplify(input_path: str):\n    img = cv2.imread(input_path)[:,:,0]\n    # Get standard deviation across all pixels in image\n    x = np.std(img)\n    \n    # Compute the 'range' threshold based on the standard deviation\n    threshold = 2.04023 * x - 4.78237\n    \n    if(x < 20): threshold = 5\n    threshold = 5\n    \n    # Find the maximum pixel intensity in the image\n    whitestPixel = 0\n    for i in range(len(img)):\n        for j in range(len(img[0])):\n            if(img[i][j] > whitestPixel): whitestPixel = img[i][j]\n            \n    # Set all pixels with intensities greater than 'whitestPixel - threshold' to 255\n        for j in range(len(img[0])):\n            if(img[i][j] > whitestPixel - threshold): img[i][j] = 255\n            \n    # Cutoff is the minimum pixel intensity we have already simplified\n    cutoff = 255 - threshold\n    \n    # Loop until all pixels have been categorized\n    while(True):    \n        whitestPixel = 0\n        \n        # Find the maximum pixel intensity that's less than 'cutoff'\n        for i in range(len(img)):\n            for j in range(len(img[0])):\n                if(img[i][j] < cutoff and img[i][j] > whitestPixel): whitestPixel = img[i][j]\n                \n        # Break the loop if no such pixel is found\n        if whitestPixel == 0: break\n        \n        # Set all pixels with intensities greater than 'whitestPixel - threshold' and less than 'cutoff' to 'whitestPixel'\n        for i in range(len(img)):\n            for j in range(len(img[0])):\n                if(img[i][j] > whitestPixel - threshold and img[i][j] < cutoff): img[i][j] = whitestPixel\n                \n        # Update cutoff\n        cutoff = whitestPixel - threshold\n    return img\n\n\n# Given an image path, removes noise and emphasizes edges. Returns the processed image as a numpy array.\ndef preprocess_image(img_path):\n    # Load image\n    img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)  # Load in grayscale\n\n    # Denoise\n    img = cv2.fastNlMeansDenoising(img, h=10, templateWindowSize=7, searchWindowSize=21)\n\n    # Convert to PIL Image for edge enhancement\n    img = Image.fromarray(img)\n\n    # Sharpen edges using Unsharp Mask\n    img = img.filter(ImageFilter.UnsharpMask(radius=8, percent=100))\n\n    return np.array(img)\n\n\n\n'''\nGaussian Mixture Model\n\n    Params: \n        img_path: path to image\n        num_components: number of clusters to fit\n        \n    Returns:\n        means: list of means for each cluster\n        variances: list of variances for each cluster\n'''\ndef gmm_parameters(data, num_components):\n    # Reshape data to fit the GMM input requirements (should be 2D)\n    data = data.reshape(-1, 1)\n\n    # Initialize Gaussian Mixture Model\n    gmm = GaussianMixture(n_components=num_components, random_state=0)\n\n    # Fit the GMM to the data\n    gmm.fit(data)\n\n    # Extract means and variances\n    means = gmm.means_.flatten()  # Flatten to convert to 1D\n    variances = gmm.covariances_.flatten()\n\n    # Return the parameters as a list\n    return list(means), list(variances)\n\n   \n# Return a list of indices in the array that fall within the provided range.\ndef get_indices_within_range(array, range):\n    lower, upper = range\n    indices = np.where((array >= lower) & (array <= upper))\n    return indices[0].tolist()\n\n# Replace all values in the array that fall within the provided range with the given number.\ndef replace_values_within_range(array, range, replacement_value):\n    lower, upper = range\n    array[(array >= lower) & (array <= upper)] = replacement_value\n    return array\n\n# Splits the range 0-255 into intervals based on the provided means and standard deviations.\ndef get_ranges(means, std_devs):\n    # Calculate the raw ranges\n    raw_ranges = list(zip(means - std_devs, means + std_devs))\n    \n    # Fix overlaps and extend to 0 and 255\n    ranges = []\n    for i, (low, high) in enumerate(raw_ranges):\n        # If this is the first range, extend the lower bound to 0\n        if i == 0:\n            low = 0\n        # Otherwise, adjust the lower bound to be the midpoint between this range's lower bound and the previous range's upper bound\n        else:\n            low = (low + ranges[-1][1]) / 2\n\n        # If this is the last range, extend the upper bound to 255\n        if i == len(raw_ranges) - 1:\n            high = 255\n        # Otherwise, adjust the upper bound to be the midpoint between this range's upper bound and the next range's lower bound\n        else:\n            high = (high + raw_ranges[i+1][0]) / 2\n        \n        ranges.append((low, high))\n    \n    return ranges\n    \n# Turns 2d matrix into 1d vector\ndef flatten(matrix):\n    # Use numpy's ravel function to flatten the matrix\n    return matrix.ravel()\n\n# Turns 1d vector into 2d matrix\ndef unflatten(vector, original_shape):\n    # Use numpy's reshape function to convert the vector back to the original matrix shape\n    return vector.reshape(original_shape)"
}