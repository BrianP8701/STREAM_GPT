{
    "metadata": {
        "type": "web",
        "url": "https://docs.llamaindex.ai/en/stable/api_reference/llms/replicate.html",
        "title": "Replicate - LlamaIndex \ud83e\udd99 0.8.49",
        "description": null
    },
    "text": "[Back to top](#)\n\nToggle table of contents sidebar\n\n## Replicate[\uf0c1](#replicate \"Permalink to this heading\")\n\n_pydantic model_ llama\\_index.llms.replicate.Replicate[\uf0c1](#llama_index.llms.replicate.Replicate \"Permalink to this definition\")\n\nShow JSON schema\n\n{\n   \"title\": \"Replicate\",\n   \"description\": \"Simple abstract base class for custom LLMs.\\\\n\\\\nSubclasses must implement the \\`\\_\\_init\\_\\_\\`, \\`complete\\`,\\\\n    \\`stream\\_complete\\`, and \\`metadata\\` methods.\",\n   \"type\": \"object\",\n   \"properties\": {\n      \"callback\\_manager\": {\n         \"title\": \"Callback Manager\"\n      },\n      \"model\": {\n         \"title\": \"Model\",\n         \"description\": \"The Replicate model to use.\",\n         \"type\": \"string\"\n      },\n      \"temperature\": {\n         \"title\": \"Temperature\",\n         \"description\": \"The temperature to use for sampling.\",\n         \"type\": \"number\"\n      },\n      \"context\\_window\": {\n         \"title\": \"Context Window\",\n         \"description\": \"The maximum number of context tokens for the model.\",\n         \"type\": \"integer\"\n      },\n      \"prompt\\_key\": {\n         \"title\": \"Prompt Key\",\n         \"description\": \"The key to use for the prompt in API calls.\",\n         \"type\": \"string\"\n      },\n      \"additional\\_kwargs\": {\n         \"title\": \"Additional Kwargs\",\n         \"description\": \"Additional kwargs for the Replicate API.\",\n         \"type\": \"object\"\n      }\n   },\n   \"required\": \\[\n      \"model\",\n      \"temperature\",\n      \"context\\_window\",\n      \"prompt\\_key\"\n   \\]\n}\n\nConfig\n\n*   **arbitrary\\_types\\_allowed**: _bool = True_\n    \n\nFields\n\n*   [`additional_kwargs (Dict[str, Any])`](#llama_index.llms.replicate.Replicate.additional_kwargs \"llama_index.llms.replicate.Replicate.additional_kwargs\")\n    \n*   [`context_window (int)`](#llama_index.llms.replicate.Replicate.context_window \"llama_index.llms.replicate.Replicate.context_window\")\n    \n*   [`model (str)`](#llama_index.llms.replicate.Replicate.model \"llama_index.llms.replicate.Replicate.model\")\n    \n*   [`prompt_key (str)`](#llama_index.llms.replicate.Replicate.prompt_key \"llama_index.llms.replicate.Replicate.prompt_key\")\n    \n*   [`temperature (float)`](#llama_index.llms.replicate.Replicate.temperature \"llama_index.llms.replicate.Replicate.temperature\")\n    \n\nValidators\n\n*   `_validate_callback_manager` \u00bb `callback_manager`\n    \n\n_field_ additional\\_kwargs_: Dict\\[str, Any\\]_ _\\[Optional\\]_[\uf0c1](#llama_index.llms.replicate.Replicate.additional_kwargs \"Permalink to this definition\")\n\nAdditional kwargs for the Replicate API.\n\n_field_ context\\_window_: int_ _\\[Required\\]_[\uf0c1](#llama_index.llms.replicate.Replicate.context_window \"Permalink to this definition\")\n\nThe maximum number of context tokens for the model.\n\n_field_ model_: str_ _\\[Required\\]_[\uf0c1](#llama_index.llms.replicate.Replicate.model \"Permalink to this definition\")\n\nThe Replicate model to use.\n\n_field_ prompt\\_key_: str_ _\\[Required\\]_[\uf0c1](#llama_index.llms.replicate.Replicate.prompt_key \"Permalink to this definition\")\n\nThe key to use for the prompt in API calls.\n\n_field_ temperature_: float_ _\\[Required\\]_[\uf0c1](#llama_index.llms.replicate.Replicate.temperature \"Permalink to this definition\")\n\nThe temperature to use for sampling.\n\nchat(_messages: Sequence\\[[ChatMessage](https://docs.llamaindex.ai/en/stable/api_reference/llms.html#llama_index.llms.base.ChatMessage \"llama_index.llms.base.ChatMessage\")\\]_, _\\*\\*kwargs: Any_) \u2192 Any[\uf0c1](#llama_index.llms.replicate.Replicate.chat \"Permalink to this definition\")\n\nChat endpoint for LLM.\n\n_classmethod_ class\\_name() \u2192 str[\uf0c1](#llama_index.llms.replicate.Replicate.class_name \"Permalink to this definition\")\n\nGet the class name, used as a unique ID in serialization.\n\nThis provides a key that makes serialization robust against actual class name changes.\n\ncomplete(_\\*args: Any_, _\\*\\*kwargs: Any_) \u2192 Any[\uf0c1](#llama_index.llms.replicate.Replicate.complete \"Permalink to this definition\")\n\nCompletion endpoint for LLM.\n\nstream\\_chat(_messages: Sequence\\[[ChatMessage](https://docs.llamaindex.ai/en/stable/api_reference/llms.html#llama_index.llms.base.ChatMessage \"llama_index.llms.base.ChatMessage\")\\]_, _\\*\\*kwargs: Any_) \u2192 Any[\uf0c1](#llama_index.llms.replicate.Replicate.stream_chat \"Permalink to this definition\")\n\nStreaming chat endpoint for LLM.\n\nstream\\_complete(_\\*args: Any_, _\\*\\*kwargs: Any_) \u2192 Any[\uf0c1](#llama_index.llms.replicate.Replicate.stream_complete \"Permalink to this definition\")\n\nStreaming completion endpoint for LLM.\n\n_property_ metadata_: [LLMMetadata](https://docs.llamaindex.ai/en/stable/api_reference/llms.html#llama_index.llms.base.LLMMetadata \"llama_index.llms.base.LLMMetadata\")_[\uf0c1](#llama_index.llms.replicate.Replicate.metadata \"Permalink to this definition\")\n\nLLM metadata."
}