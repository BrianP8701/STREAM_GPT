import global_vars as gv
import openai_helpers as oah
import helpers as h
import time
import prompts as p

x = h.extract_ideas("{\n  \"indexed_text\": [\n    {\"idea\": \"The computational solution of optimal control problems with time lag\"},\n    {\"idea\": \"Improving generalisation performance using double back-propagation\"},\n    {\"idea\": \"Adaptive subgradient methods for online learning and stochastic optimization\"},\n    {\"idea\": \"Doubly robust policy evaluation and learning\"},\n    {\"idea\": \"Incorporating second-order functional knowledge for better option pricing\"},\n    {\"idea\": \"Training generative neural networks via maximum mean discrepancy optimization\"},\n    {\"idea\": \"Hierarchical recurrent neural networks for long-term dependencies\"},\n    {\"idea\": \"A multi-view deep learning approach for cross domain user modeling in recommendation systems\"},\n    {\"idea\": \"Learning and development in neural networks: The importance of starting small\"},\n    {\"idea\": \"The difficulty of training deep architectures and the effect of unsupervised pre-training\"},\n    {\"idea\": \"Massively parallel architectures for AI: NETL, thistle, and Boltzmann machines\"},\n    {\"idea\": \"From captions to visual concepts and back\"},\n    {\"idea\": \"Large-scale FPGA-based convolutional networks\"},\n    {\"idea\": \"Learning hierarchical features for scene labeling\"},\n    {\"idea\": \"One-shot learning of object categories\"},\n    {\"idea\": \"Learning visual feature spaces for robotic manipulation with deep spatial autoencoders\"},\n    {\"idea\": \"The use of multiple measurements in taxonomic problems\"},\n    {\"idea\": \"Adaptive network for optimal linear feature extraction\"},\n    {\"idea\": \"Slowness and sparseness lead to place, head-direction, and spatial-view cells\"},\n    {\"idea\": \"Invariant object recognition with slow feature analysis\"},\n    {\"idea\": \"On the efficient classification of data structures by neural networks\"},\n    {\"idea\": \"A general framework for adaptive processing of data structures\"},\n    {\"idea\": \"Experiments with a new boosting algorithm\"},\n    {\"idea\": \"Game theory, on-line prediction and boosting\"},\n    {\"idea\": \"Graphical models for machine learning and digital communication\"},\n    {\"idea\": \"Does the wake-sleep algorithm learn good density estimators?\"},\n    {\"idea\": \"Uber matrizen aus positiven elementen\"},\n    {\"idea\": \"Cognitron: A self-organizing multilayered neural network\"},\n    {\"idea\": \"Neocognitron: A self-organizing neural network model for a mechanism of pattern recognition unaffected by shift in position\"},\n    {\"idea\": \"Bayesian convolutional neural networks with Bernoulli approximate variational inference\"},\n    {\"idea\": \"Memoires associatives distribuees\"},\n    {\"idea\": \"Combining two and three-way embeddings models for link prediction in knowledge bases\"},\n    {\"idea\": \"Darpa timit acoustic-phonetic continous speech corpus cd-rom\"},\n    {\"idea\": \"The metric system of identification of criminals, as used in Great Britain and Ireland\"},\n    {\"idea\": \"Learning to forget: Continual prediction with LSTM\"},\n    {\"idea\": \"The EM algorithm for mixtures of factor analyzers\"},\n    {\"idea\": \"Multilingual language processing from bytes\"},\n    {\"idea\": \"Region-based convolutional networks for accurate object detection and segmentation\"},\n    {\"idea\": \"Programmed to learn? The ontogeny of mirror neurons\"},\n    {\"idea\": \"Understanding the difficulty of training deep feedforward neural networks\"},\n    {\"idea\": \"Deep sparse rectifier neural networks\"}\n  ]\n}")
print(x)