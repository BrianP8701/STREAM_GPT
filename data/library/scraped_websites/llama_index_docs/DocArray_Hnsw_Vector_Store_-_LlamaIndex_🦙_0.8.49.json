{
    "metadata": {
        "type": "web",
        "url": "https://docs.llamaindex.ai/en/stable/examples/vector_stores/DocArrayHnswIndexDemo.html",
        "title": "DocArray Hnsw Vector Store - LlamaIndex \ud83e\udd99 0.8.49",
        "description": null
    },
    "text": "[Back to top](#)\n\nToggle table of contents sidebar\n\n## DocArray Hnsw Vector Store[\uf0c1](#docarray-hnsw-vector-store \"Permalink to this heading\")\n\n[DocArrayHnswVectorStore](https://docs.docarray.org/user_guide/storing/index_hnswlib/) is a lightweight Document Index implementation provided by [DocArray](https://github.com/docarray/docarray) that runs fully locally and is best suited for small- to medium-sized datasets. It stores vectors on disk in hnswlib, and stores all other data in SQLite.\n\nimport os\nimport sys\nimport logging\nimport textwrap\n\nimport warnings\n\nwarnings.filterwarnings(\"ignore\")\n\n\\# stop h|uggingface warnings\nos.environ\\[\"TOKENIZERS\\_PARALLELISM\"\\] \\= \"false\"\n\n\\# Uncomment to see debug logs\n\\# logging.basicConfig(stream=sys.stdout, level=logging.INFO)\n\\# logging.getLogger().addHandler(logging.StreamHandler(stream=sys.stdout))\n\nfrom llama\\_index import GPTVectorStoreIndex, SimpleDirectoryReader, Document\nfrom llama\\_index.vector\\_stores import DocArrayHnswVectorStore\nfrom IPython.display import Markdown, display\n\nimport os\n\nos.environ\\[\"OPENAI\\_API\\_KEY\"\\] \\= \"<your openai key>\"\n\n\\# load documents\ndocuments \\= SimpleDirectoryReader(\"../data/paul\\_graham\").load\\_data()\nprint(\n    \"Document ID:\",\n    documents\\[0\\].doc\\_id,\n    \"Document Hash:\",\n    documents\\[0\\].doc\\_hash,\n)\n\nDocument ID: 07d9ca27-ded0-46fa-9165-7e621216fd47 Document Hash: 77ae91ab542f3abb308c4d7c77c9bc4c9ad0ccd63144802b7cbe7e1bb3a4094e\n\n## Initialization and indexing[\uf0c1](#initialization-and-indexing \"Permalink to this heading\")\n\nfrom llama\\_index.storage.storage\\_context import StorageContext\n\nvector\\_store \\= DocArrayHnswVectorStore(work\\_dir\\=\"hnsw\\_index\")\nstorage\\_context \\= StorageContext.from\\_defaults(vector\\_store\\=vector\\_store)\nindex \\= GPTVectorStoreIndex.from\\_documents(\n    documents, storage\\_context\\=storage\\_context\n)\n\n## Querying[\uf0c1](#querying \"Permalink to this heading\")\n\n\\# set Logging to DEBUG for more detailed outputs\nquery\\_engine \\= index.as\\_query\\_engine()\nresponse \\= query\\_engine.query(\"What did the author do growing up?\")\nprint(textwrap.fill(str(response), 100))\n\nToken indices sequence length is longer than the specified maximum sequence length for this model (1830 > 1024). Running this sequence through the model will result in indexing errors\n\n Growing up, the author wrote short stories, programmed on an IBM 1401, and nagged his father to buy\nhim a TRS-80 microcomputer. He wrote simple games, a program to predict how high his model rockets\nwould fly, and a word processor. He also studied philosophy in college, but switched to AI after\nbecoming bored with it. He then took art classes at Harvard and applied to art schools, eventually\nattending RISD.\n\nresponse \\= query\\_engine.query(\"What was a hard moment for the author?\")\nprint(textwrap.fill(str(response), 100))\n\n A hard moment for the author was when he realized that the AI programs of the time were a hoax and\nthat there was an unbridgeable gap between what they could do and actually understanding natural\nlanguage.\n\n## Querying with filters[\uf0c1](#querying-with-filters \"Permalink to this heading\")\n\nfrom llama\\_index.schema import TextNode\n\nnodes \\= \\[\n    TextNode(\n        text\\=\"The Shawshank Redemption\",\n        metadata\\={\n            \"author\": \"Stephen King\",\n            \"theme\": \"Friendship\",\n        },\n    ),\n    TextNode(\n        text\\=\"The Godfather\",\n        metadata\\={\n            \"director\": \"Francis Ford Coppola\",\n            \"theme\": \"Mafia\",\n        },\n    ),\n    TextNode(\n        text\\=\"Inception\",\n        metadata\\={\n            \"director\": \"Christopher Nolan\",\n        },\n    ),\n\\]\n\nfrom llama\\_index.storage.storage\\_context import StorageContext\n\nvector\\_store \\= DocArrayHnswVectorStore(work\\_dir\\=\"hnsw\\_filters\")\nstorage\\_context \\= StorageContext.from\\_defaults(vector\\_store\\=vector\\_store)\n\nindex \\= GPTVectorStoreIndex(nodes, storage\\_context\\=storage\\_context)\n\nfrom llama\\_index.vector\\_stores.types import ExactMatchFilter, MetadataFilters\n\nfilters \\= MetadataFilters(\n    filters\\=\\[ExactMatchFilter(key\\=\"theme\", value\\=\"Mafia\")\\]\n)\n\nretriever \\= index.as\\_retriever(filters\\=filters)\nretriever.retrieve(\"What is inception about?\")\n\n\\[NodeWithScore(node=Node(text='director: Francis Ford Coppola\\\\ntheme: Mafia\\\\n\\\\nThe Godfather', doc\\_id='d96456bf-ef6e-4c1b-bdb8-e90a37d881f3', embedding=None, doc\\_hash='b770e43e6a94854a22dc01421d3d9ef6a94931c2b8dbbadf4fdb6eb6fbe41010', extra\\_info=None, node\\_info=None, relationships={<DocumentRelationship.SOURCE: '1'>: 'None'}), score=0.4634347)\\]\n\n\\# remove created indices\nimport os, shutil\n\nhnsw\\_dirs \\= \\[\"hnsw\\_filters\", \"hnsw\\_index\"\\]\nfor dir in hnsw\\_dirs:\n    if os.path.exists(dir):\n        shutil.rmtree(dir)"
}