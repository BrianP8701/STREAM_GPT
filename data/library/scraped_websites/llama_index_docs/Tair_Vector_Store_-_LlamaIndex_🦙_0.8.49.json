{
    "metadata": {
        "type": "web",
        "url": "https://docs.llamaindex.ai/en/stable/examples/vector_stores/TairIndexDemo.html",
        "title": "Tair Vector Store - LlamaIndex \ud83e\udd99 0.8.49",
        "description": null
    },
    "text": "[Back to top](#)\n\nToggle table of contents sidebar\n\n## Tair Vector Store[\uf0c1](#tair-vector-store \"Permalink to this heading\")\n\nIn this notebook we are going to show a quick demo of using the TairVectorStore.\n\nimport os\nimport sys\nimport logging\nimport textwrap\n\nimport warnings\n\nwarnings.filterwarnings(\"ignore\")\n\n\\# stop huggingface warnings\nos.environ\\[\"TOKENIZERS\\_PARALLELISM\"\\] \\= \"false\"\n\n\\# Uncomment to see debug logs\n\\# logging.basicConfig(stream=sys.stdout, level=logging.INFO)\n\\# logging.getLogger().addHandler(logging.StreamHandler(stream=sys.stdout))\n\nfrom llama\\_index import GPTVectorStoreIndex, SimpleDirectoryReader, Document\nfrom llama\\_index.vector\\_stores import TairVectorStore\nfrom IPython.display import Markdown, display\n\n## Setup OpenAI[\uf0c1](#setup-openai \"Permalink to this heading\")\n\nLets first begin by adding the openai api key. This will allow us to access openai for embeddings and to use chatgpt.\n\nimport os\n\nos.environ\\[\"OPENAI\\_API\\_KEY\"\\] \\= \"sk-<your key here>\"\n\n## Read in a dataset[\uf0c1](#read-in-a-dataset \"Permalink to this heading\")\n\n\\# load documents\ndocuments \\= SimpleDirectoryReader(\"../data/paul\\_graham\").load\\_data()\nprint(\n    \"Document ID:\",\n    documents\\[0\\].doc\\_id,\n    \"Document Hash:\",\n    documents\\[0\\].doc\\_hash,\n)\n\n## Build index from documents[\uf0c1](#build-index-from-documents \"Permalink to this heading\")\n\nLet\u2019s build a vector index with `GPTVectorStoreIndex`, using `TairVectorStore` as its backend. Replace `tair_url` with the actual url of your Tair instance.\n\nfrom llama\\_index.storage.storage\\_context import StorageContext\n\ntair\\_url \\= \"redis://{username}:{password}@r-bp\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*.redis.rds.aliyuncs.com:{port}\"\n\nvector\\_store \\= TairVectorStore(\n    tair\\_url\\=tair\\_url, index\\_name\\=\"pg\\_essays\", overwrite\\=True\n)\nstorage\\_context \\= StorageContext.from\\_defaults(vector\\_store\\=vector\\_store)\nindex \\= GPTVectorStoreIndex.from\\_documents(\n    documents, storage\\_context\\=storage\\_context\n)\n\n## Query the data[\uf0c1](#query-the-data \"Permalink to this heading\")\n\nNow we can use the index as knowledge base and ask questions to it.\n\nquery\\_engine \\= index.as\\_query\\_engine()\nresponse \\= query\\_engine.query(\"What did the author learn?\")\nprint(textwrap.fill(str(response), 100))\n\nresponse \\= query\\_engine.query(\"What was a hard moment for the author?\")\nprint(textwrap.fill(str(response), 100))\n\n## Deleting documents[\uf0c1](#deleting-documents \"Permalink to this heading\")\n\nTo delete a document from the index, use `delete` method.\n\ndocument\\_id \\= documents\\[0\\].doc\\_id\ndocument\\_id\n\ninfo \\= vector\\_store.client.tvs\\_get\\_index(\"pg\\_essays\")\nprint(\"Number of documents\", int(info\\[\"data\\_count\"\\]))\n\nvector\\_store.delete(document\\_id)\n\ninfo \\= vector\\_store.client.tvs\\_get\\_index(\"pg\\_essays\")\nprint(\"Number of documents\", int(info\\[\"data\\_count\"\\]))\n\n## Deleting index[\uf0c1](#deleting-index \"Permalink to this heading\")\n\nDelete the entire index using `delete_index` method.\n\nvector\\_store.delete\\_index()\n\nprint(\"Check index existence:\", vector\\_store.client.\\_index\\_exists())"
}