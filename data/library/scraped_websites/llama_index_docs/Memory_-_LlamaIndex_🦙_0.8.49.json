{
    "metadata": {
        "type": "web",
        "url": "https://docs.llamaindex.ai/en/stable/api_reference/memory.html",
        "title": "Memory - LlamaIndex \ud83e\udd99 0.8.49",
        "description": null
    },
    "text": "[Back to top](#)\n\nToggle table of contents sidebar\n\n## Memory[\uf0c1](#module-llama_index.memory \"Permalink to this heading\")\n\n_pydantic model_ llama\\_index.memory.BaseMemory[\uf0c1](#llama_index.memory.BaseMemory \"Permalink to this definition\")\n\nBase class for all memory types.\n\nNOTE: The interface for memory is not yet finalized and is subject to change.\n\nShow JSON schema\n\n{\n   \"title\": \"BaseMemory\",\n   \"description\": \"Base class for all memory types.\\\\n\\\\nNOTE: The interface for memory is not yet finalized and is subject to change.\",\n   \"type\": \"object\",\n   \"properties\": {}\n}\n\n_classmethod_ construct(_\\_fields\\_set: Optional\\[SetStr\\] \\= None_, _\\*\\*values: Any_) \u2192 Model[\uf0c1](#llama_index.memory.BaseMemory.construct \"Permalink to this definition\")\n\nCreates a new model setting \\_\\_dict\\_\\_ and \\_\\_fields\\_set\\_\\_ from trusted or pre-validated data. Default values are respected, but no other validation is performed. Behaves as if Config.extra = \u2018allow\u2019 was set since it adds all passed values\n\ncopy(_\\*_, _include: Optional\\[Union\\[AbstractSetIntStr, MappingIntStrAny\\]\\] \\= None_, _exclude: Optional\\[Union\\[AbstractSetIntStr, MappingIntStrAny\\]\\] \\= None_, _update: Optional\\[DictStrAny\\] \\= None_, _deep: bool \\= False_) \u2192 Model[\uf0c1](#llama_index.memory.BaseMemory.copy \"Permalink to this definition\")\n\nDuplicate a model, optionally choose which fields to include, exclude and change.\n\nParameters\n\n*   **include** \u2013 fields to include in new model\n    \n*   **exclude** \u2013 fields to exclude from new model, as with values this takes precedence over include\n    \n*   **update** \u2013 values to change/add in the new model. Note: the data is not validated before creating the new model: you should trust this data\n    \n*   **deep** \u2013 set to True to make a deep copy of the model\n    \n\nReturns\n\nnew model instance\n\ndict(_\\*_, _include: Optional\\[Union\\[AbstractSetIntStr, MappingIntStrAny\\]\\] \\= None_, _exclude: Optional\\[Union\\[AbstractSetIntStr, MappingIntStrAny\\]\\] \\= None_, _by\\_alias: bool \\= False_, _skip\\_defaults: Optional\\[bool\\] \\= None_, _exclude\\_unset: bool \\= False_, _exclude\\_defaults: bool \\= False_, _exclude\\_none: bool \\= False_) \u2192 DictStrAny[\uf0c1](#llama_index.memory.BaseMemory.dict \"Permalink to this definition\")\n\nGenerate a dictionary representation of the model, optionally specifying which fields to include or exclude.\n\n_abstract classmethod_ from\\_defaults(_chat\\_history: Optional\\[List\\[[ChatMessage](https://docs.llamaindex.ai/en/stable/api_reference/llms.html#llama_index.llms.base.ChatMessage \"llama_index.llms.base.ChatMessage\")\\]\\] \\= None_, _llm: Optional\\[[LLM](https://docs.llamaindex.ai/en/stable/api_reference/llms.html#llama_index.llms.base.LLM \"llama_index.llms.base.LLM\")\\] \\= None_) \u2192 [BaseMemory](#llama_index.memory.BaseMemory \"llama_index.memory.types.BaseMemory\")[\uf0c1](#llama_index.memory.BaseMemory.from_defaults \"Permalink to this definition\")\n\nCreate a chat memory from defaults.\n\n_classmethod_ from\\_orm(_obj: Any_) \u2192 Model[\uf0c1](#llama_index.memory.BaseMemory.from_orm \"Permalink to this definition\")\n\n_abstract_ get() \u2192 List\\[[ChatMessage](https://docs.llamaindex.ai/en/stable/api_reference/llms.html#llama_index.llms.base.ChatMessage \"llama_index.llms.base.ChatMessage\")\\][\uf0c1](#llama_index.memory.BaseMemory.get \"Permalink to this definition\")\n\nGet chat history.\n\n_abstract_ get\\_all() \u2192 List\\[[ChatMessage](https://docs.llamaindex.ai/en/stable/api_reference/llms.html#llama_index.llms.base.ChatMessage \"llama_index.llms.base.ChatMessage\")\\][\uf0c1](#llama_index.memory.BaseMemory.get_all \"Permalink to this definition\")\n\nGet all chat history.\n\njson(_\\*_, _include: Optional\\[Union\\[AbstractSetIntStr, MappingIntStrAny\\]\\] \\= None_, _exclude: Optional\\[Union\\[AbstractSetIntStr, MappingIntStrAny\\]\\] \\= None_, _by\\_alias: bool \\= False_, _skip\\_defaults: Optional\\[bool\\] \\= None_, _exclude\\_unset: bool \\= False_, _exclude\\_defaults: bool \\= False_, _exclude\\_none: bool \\= False_, _encoder: Optional\\[Callable\\[\\[Any\\], Any\\]\\] \\= None_, _models\\_as\\_dict: bool \\= True_, _\\*\\*dumps\\_kwargs: Any_) \u2192 unicode[\uf0c1](#llama_index.memory.BaseMemory.json \"Permalink to this definition\")\n\nGenerate a JSON representation of the model, include and exclude arguments as per dict().\n\nencoder is an optional function to supply as default to json.dumps(), other arguments as per json.dumps().\n\n_classmethod_ parse\\_file(_path: Union\\[str, Path\\]_, _\\*_, _content\\_type: unicode \\= None_, _encoding: unicode \\= 'utf8'_, _proto: Protocol \\= None_, _allow\\_pickle: bool \\= False_) \u2192 Model[\uf0c1](#llama_index.memory.BaseMemory.parse_file \"Permalink to this definition\")\n\n_classmethod_ parse\\_obj(_obj: Any_) \u2192 Model[\uf0c1](#llama_index.memory.BaseMemory.parse_obj \"Permalink to this definition\")\n\n_classmethod_ parse\\_raw(_b: Union\\[str, bytes\\]_, _\\*_, _content\\_type: unicode \\= None_, _encoding: unicode \\= 'utf8'_, _proto: Protocol \\= None_, _allow\\_pickle: bool \\= False_) \u2192 Model[\uf0c1](#llama_index.memory.BaseMemory.parse_raw \"Permalink to this definition\")\n\n_abstract_ put(_message: [ChatMessage](https://docs.llamaindex.ai/en/stable/api_reference/llms.html#llama_index.llms.base.ChatMessage \"llama_index.llms.base.ChatMessage\")_) \u2192 None[\uf0c1](#llama_index.memory.BaseMemory.put \"Permalink to this definition\")\n\nPut chat history.\n\n_abstract_ reset() \u2192 None[\uf0c1](#llama_index.memory.BaseMemory.reset \"Permalink to this definition\")\n\nReset chat history.\n\n_classmethod_ schema(_by\\_alias: bool \\= True_, _ref\\_template: unicode \\= '#/definitions/{model}'_) \u2192 DictStrAny[\uf0c1](#llama_index.memory.BaseMemory.schema \"Permalink to this definition\")\n\n_classmethod_ schema\\_json(_\\*_, _by\\_alias: bool \\= True_, _ref\\_template: unicode \\= '#/definitions/{model}'_, _\\*\\*dumps\\_kwargs: Any_) \u2192 unicode[\uf0c1](#llama_index.memory.BaseMemory.schema_json \"Permalink to this definition\")\n\n_abstract_ set(_messages: List\\[[ChatMessage](https://docs.llamaindex.ai/en/stable/api_reference/llms.html#llama_index.llms.base.ChatMessage \"llama_index.llms.base.ChatMessage\")\\]_) \u2192 None[\uf0c1](#llama_index.memory.BaseMemory.set \"Permalink to this definition\")\n\nSet chat history.\n\n_classmethod_ update\\_forward\\_refs(_\\*\\*localns: Any_) \u2192 None[\uf0c1](#llama_index.memory.BaseMemory.update_forward_refs \"Permalink to this definition\")\n\nTry to update ForwardRefs on fields based on this Model, globalns and localns.\n\n_classmethod_ validate(_value: Any_) \u2192 Model[\uf0c1](#llama_index.memory.BaseMemory.validate \"Permalink to this definition\")\n\n_pydantic model_ llama\\_index.memory.ChatMemoryBuffer[\uf0c1](#llama_index.memory.ChatMemoryBuffer \"Permalink to this definition\")\n\nSimple buffer for storing chat history.\n\nShow JSON schema\n\n{\n   \"title\": \"ChatMemoryBuffer\",\n   \"description\": \"Simple buffer for storing chat history.\",\n   \"type\": \"object\",\n   \"properties\": {\n      \"token\\_limit\": {\n         \"title\": \"Token Limit\",\n         \"type\": \"integer\"\n      },\n      \"chat\\_history\": {\n         \"title\": \"Chat History\",\n         \"type\": \"array\",\n         \"items\": {\n            \"$ref\": \"#/definitions/ChatMessage\"\n         }\n      }\n   },\n   \"required\": \\[\n      \"token\\_limit\"\n   \\],\n   \"definitions\": {\n      \"MessageRole\": {\n         \"title\": \"MessageRole\",\n         \"description\": \"Message role.\",\n         \"enum\": \\[\n            \"system\",\n            \"user\",\n            \"assistant\",\n            \"function\"\n         \\],\n         \"type\": \"string\"\n      },\n      \"ChatMessage\": {\n         \"title\": \"ChatMessage\",\n         \"description\": \"Chat message.\",\n         \"type\": \"object\",\n         \"properties\": {\n            \"role\": {\n               \"default\": \"user\",\n               \"allOf\": \\[\n                  {\n                     \"$ref\": \"#/definitions/MessageRole\"\n                  }\n               \\]\n            },\n            \"content\": {\n               \"title\": \"Content\",\n               \"default\": \"\",\n               \"type\": \"string\"\n            },\n            \"additional\\_kwargs\": {\n               \"title\": \"Additional Kwargs\",\n               \"type\": \"object\"\n            }\n         }\n      }\n   }\n}\n\nFields\n\n*   `chat_history (List[llama_index.llms.base.ChatMessage])`\n    \n*   `token_limit (int)`\n    \n*   `tokenizer_fn (Callable[[str], List])`\n    \n\n_field_ chat\\_history_: List\\[[ChatMessage](https://docs.llamaindex.ai/en/stable/api_reference/llms.html#llama_index.llms.base.ChatMessage \"llama_index.llms.base.ChatMessage\")\\]_ _\\[Optional\\]_[\uf0c1](#llama_index.memory.ChatMemoryBuffer.chat_history \"Permalink to this definition\")\n\nValidated by\n\n*   `validate_memory`\n    \n\n_field_ token\\_limit_: int_ _\\[Required\\]_[\uf0c1](#llama_index.memory.ChatMemoryBuffer.token_limit \"Permalink to this definition\")\n\nValidated by\n\n*   `validate_memory`\n    \n\n_field_ tokenizer\\_fn_: Callable\\[\\[str\\], List\\]_ _\\[Optional\\]_[\uf0c1](#llama_index.memory.ChatMemoryBuffer.tokenizer_fn \"Permalink to this definition\")\n\nValidated by\n\n*   `validate_memory`\n    \n\n_classmethod_ construct(_\\_fields\\_set: Optional\\[SetStr\\] \\= None_, _\\*\\*values: Any_) \u2192 Model[\uf0c1](#llama_index.memory.ChatMemoryBuffer.construct \"Permalink to this definition\")\n\nCreates a new model setting \\_\\_dict\\_\\_ and \\_\\_fields\\_set\\_\\_ from trusted or pre-validated data. Default values are respected, but no other validation is performed. Behaves as if Config.extra = \u2018allow\u2019 was set since it adds all passed values\n\ncopy(_\\*_, _include: Optional\\[Union\\[AbstractSetIntStr, MappingIntStrAny\\]\\] \\= None_, _exclude: Optional\\[Union\\[AbstractSetIntStr, MappingIntStrAny\\]\\] \\= None_, _update: Optional\\[DictStrAny\\] \\= None_, _deep: bool \\= False_) \u2192 Model[\uf0c1](#llama_index.memory.ChatMemoryBuffer.copy \"Permalink to this definition\")\n\nDuplicate a model, optionally choose which fields to include, exclude and change.\n\nParameters\n\n*   **include** \u2013 fields to include in new model\n    \n*   **exclude** \u2013 fields to exclude from new model, as with values this takes precedence over include\n    \n*   **update** \u2013 values to change/add in the new model. Note: the data is not validated before creating the new model: you should trust this data\n    \n*   **deep** \u2013 set to True to make a deep copy of the model\n    \n\nReturns\n\nnew model instance\n\ndict(_\\*_, _include: Optional\\[Union\\[AbstractSetIntStr, MappingIntStrAny\\]\\] \\= None_, _exclude: Optional\\[Union\\[AbstractSetIntStr, MappingIntStrAny\\]\\] \\= None_, _by\\_alias: bool \\= False_, _skip\\_defaults: Optional\\[bool\\] \\= None_, _exclude\\_unset: bool \\= False_, _exclude\\_defaults: bool \\= False_, _exclude\\_none: bool \\= False_) \u2192 DictStrAny[\uf0c1](#llama_index.memory.ChatMemoryBuffer.dict \"Permalink to this definition\")\n\nGenerate a dictionary representation of the model, optionally specifying which fields to include or exclude.\n\n_classmethod_ from\\_defaults(_chat\\_history: Optional\\[List\\[[ChatMessage](https://docs.llamaindex.ai/en/stable/api_reference/llms.html#llama_index.llms.base.ChatMessage \"llama_index.llms.base.ChatMessage\")\\]\\] \\= None_, _llm: Optional\\[[LLM](https://docs.llamaindex.ai/en/stable/api_reference/llms.html#llama_index.llms.base.LLM \"llama_index.llms.base.LLM\")\\] \\= None_, _token\\_limit: Optional\\[int\\] \\= None_, _tokenizer\\_fn: Optional\\[Callable\\[\\[str\\], List\\]\\] \\= None_) \u2192 [ChatMemoryBuffer](#llama_index.memory.ChatMemoryBuffer \"llama_index.memory.chat_memory_buffer.ChatMemoryBuffer\")[\uf0c1](#llama_index.memory.ChatMemoryBuffer.from_defaults \"Permalink to this definition\")\n\nCreate a chat memory buffer from an LLM.\n\n_classmethod_ from\\_dict(_json\\_dict: dict_) \u2192 [ChatMemoryBuffer](#llama_index.memory.ChatMemoryBuffer \"llama_index.memory.chat_memory_buffer.ChatMemoryBuffer\")[\uf0c1](#llama_index.memory.ChatMemoryBuffer.from_dict \"Permalink to this definition\")\n\n_classmethod_ from\\_orm(_obj: Any_) \u2192 Model[\uf0c1](#llama_index.memory.ChatMemoryBuffer.from_orm \"Permalink to this definition\")\n\n_classmethod_ from\\_string(_json\\_str: str_) \u2192 [ChatMemoryBuffer](#llama_index.memory.ChatMemoryBuffer \"llama_index.memory.chat_memory_buffer.ChatMemoryBuffer\")[\uf0c1](#llama_index.memory.ChatMemoryBuffer.from_string \"Permalink to this definition\")\n\nget() \u2192 List\\[[ChatMessage](https://docs.llamaindex.ai/en/stable/api_reference/llms.html#llama_index.llms.base.ChatMessage \"llama_index.llms.base.ChatMessage\")\\][\uf0c1](#llama_index.memory.ChatMemoryBuffer.get \"Permalink to this definition\")\n\nGet chat history.\n\nget\\_all() \u2192 List\\[[ChatMessage](https://docs.llamaindex.ai/en/stable/api_reference/llms.html#llama_index.llms.base.ChatMessage \"llama_index.llms.base.ChatMessage\")\\][\uf0c1](#llama_index.memory.ChatMemoryBuffer.get_all \"Permalink to this definition\")\n\nGet all chat history.\n\njson(_\\*_, _include: Optional\\[Union\\[AbstractSetIntStr, MappingIntStrAny\\]\\] \\= None_, _exclude: Optional\\[Union\\[AbstractSetIntStr, MappingIntStrAny\\]\\] \\= None_, _by\\_alias: bool \\= False_, _skip\\_defaults: Optional\\[bool\\] \\= None_, _exclude\\_unset: bool \\= False_, _exclude\\_defaults: bool \\= False_, _exclude\\_none: bool \\= False_, _encoder: Optional\\[Callable\\[\\[Any\\], Any\\]\\] \\= None_, _models\\_as\\_dict: bool \\= True_, _\\*\\*dumps\\_kwargs: Any_) \u2192 unicode[\uf0c1](#llama_index.memory.ChatMemoryBuffer.json \"Permalink to this definition\")\n\nGenerate a JSON representation of the model, include and exclude arguments as per dict().\n\nencoder is an optional function to supply as default to json.dumps(), other arguments as per json.dumps().\n\n_classmethod_ parse\\_file(_path: Union\\[str, Path\\]_, _\\*_, _content\\_type: unicode \\= None_, _encoding: unicode \\= 'utf8'_, _proto: Protocol \\= None_, _allow\\_pickle: bool \\= False_) \u2192 Model[\uf0c1](#llama_index.memory.ChatMemoryBuffer.parse_file \"Permalink to this definition\")\n\n_classmethod_ parse\\_obj(_obj: Any_) \u2192 Model[\uf0c1](#llama_index.memory.ChatMemoryBuffer.parse_obj \"Permalink to this definition\")\n\n_classmethod_ parse\\_raw(_b: Union\\[str, bytes\\]_, _\\*_, _content\\_type: unicode \\= None_, _encoding: unicode \\= 'utf8'_, _proto: Protocol \\= None_, _allow\\_pickle: bool \\= False_) \u2192 Model[\uf0c1](#llama_index.memory.ChatMemoryBuffer.parse_raw \"Permalink to this definition\")\n\nput(_message: [ChatMessage](https://docs.llamaindex.ai/en/stable/api_reference/llms.html#llama_index.llms.base.ChatMessage \"llama_index.llms.base.ChatMessage\")_) \u2192 None[\uf0c1](#llama_index.memory.ChatMemoryBuffer.put \"Permalink to this definition\")\n\nPut chat history.\n\nreset() \u2192 None[\uf0c1](#llama_index.memory.ChatMemoryBuffer.reset \"Permalink to this definition\")\n\nReset chat history.\n\n_classmethod_ schema(_by\\_alias: bool \\= True_, _ref\\_template: unicode \\= '#/definitions/{model}'_) \u2192 DictStrAny[\uf0c1](#llama_index.memory.ChatMemoryBuffer.schema \"Permalink to this definition\")\n\n_classmethod_ schema\\_json(_\\*_, _by\\_alias: bool \\= True_, _ref\\_template: unicode \\= '#/definitions/{model}'_, _\\*\\*dumps\\_kwargs: Any_) \u2192 unicode[\uf0c1](#llama_index.memory.ChatMemoryBuffer.schema_json \"Permalink to this definition\")\n\nset(_messages: List\\[[ChatMessage](https://docs.llamaindex.ai/en/stable/api_reference/llms.html#llama_index.llms.base.ChatMessage \"llama_index.llms.base.ChatMessage\")\\]_) \u2192 None[\uf0c1](#llama_index.memory.ChatMemoryBuffer.set \"Permalink to this definition\")\n\nSet chat history.\n\nto\\_dict() \u2192 dict[\uf0c1](#llama_index.memory.ChatMemoryBuffer.to_dict \"Permalink to this definition\")\n\nConvert memory to dict.\n\nto\\_string() \u2192 str[\uf0c1](#llama_index.memory.ChatMemoryBuffer.to_string \"Permalink to this definition\")\n\nConvert memory to string.\n\n_classmethod_ update\\_forward\\_refs(_\\*\\*localns: Any_) \u2192 None[\uf0c1](#llama_index.memory.ChatMemoryBuffer.update_forward_refs \"Permalink to this definition\")\n\nTry to update ForwardRefs on fields based on this Model, globalns and localns.\n\n_classmethod_ validate(_value: Any_) \u2192 Model[\uf0c1](#llama_index.memory.ChatMemoryBuffer.validate \"Permalink to this definition\")\n\n_validator_ validate\\_memory\u00a0 _\u00bb_\u00a0 _all fields_[\uf0c1](#llama_index.memory.ChatMemoryBuffer.validate_memory \"Permalink to this definition\")"
}