{
    "metadata": {
        "type": "web",
        "url": "https://docs.llamaindex.ai/en/stable/core_modules/query_modules/response_synthesizers/modules.html",
        "title": "Module Guide - LlamaIndex \ud83e\udd99 0.8.49",
        "description": null
    },
    "text": "[Back to top](#)\n\nToggle table of contents sidebar\n\n## Module Guide[\uf0c1](#module-guide \"Permalink to this heading\")\n\nDetailed inputs/outputs for each response synthesizer are found below.\n\n## API Example[\uf0c1](#api-example \"Permalink to this heading\")\n\nThe following shows the setup for utilizing all kwargs.\n\n*   `response_mode` specifies which response synthesizer to use\n    \n*   `service_context` defines the LLM and related settings for synthesis\n    \n*   `text_qa_template` and `refine_template` are the prompts used at various stages\n    \n*   `use_async` is used for only the `tree_summarize` response mode right now, to asynchronously build the summary tree\n    \n*   `streaming` configures whether to return a streaming response object or not\n    \n*   `structured_answer_filtering` enables the active filtering of text chunks that are not relevant to a given question\n    \n\nIn the `synthesize`/`asyntheszie` functions, you can optionally provide additional source nodes, which will be added to the `response.source_nodes` list.\n\nfrom llama\\_index.schema import Node, NodeWithScore\nfrom llama\\_index import get\\_response\\_synthesizer\n\nresponse\\_synthesizer \\= get\\_response\\_synthesizer(\n  response\\_mode\\=\"refine\",\n  service\\_context\\=service\\_context,\n  text\\_qa\\_template\\=text\\_qa\\_template,\n  refine\\_template\\=refine\\_template,\n  use\\_async\\=False,\n  streaming\\=False\n)\n\n\\# synchronous\nresponse \\= response\\_synthesizer.synthesize(\n  \"query string\",\n  nodes\\=\\[NodeWithScore(node\\=Node(text\\=\"text\"), score\\=1.0), ..\\],\n  additional\\_source\\_nodes\\=\\[NodeWithScore(node\\=Node(text\\=\"text\"), score\\=1.0), ..\\],\n)\n\n\\# asynchronous\nresponse \\= await response\\_synthesizer.asynthesize(\n  \"query string\",\n  nodes\\=\\[NodeWithScore(node\\=Node(text\\=\"text\"), score\\=1.0), ..\\],\n  additional\\_source\\_nodes\\=\\[NodeWithScore(node\\=Node(text\\=\"text\"), score\\=1.0), ..\\],\n)\n\nYou can also directly return a string, using the lower-level `get_response` and `aget_response` functions\n\nresponse\\_str \\= response\\_synthesizer.get\\_response(\n  \"query string\",\n  text\\_chunks\\=\\[\"text1\", \"text2\", ...\\]\n)"
}