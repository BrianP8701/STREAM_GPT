{
    "metadata": {
        "type": "web",
        "url": "https://docs.llamaindex.ai/en/stable/end_to_end_tutorials/apps/fullstack_with_delphic.html",
        "title": "A Guide to Building a Full-Stack LlamaIndex Web App with Delphic - LlamaIndex \ud83e\udd99 0.8.49",
        "description": null
    },
    "text": "[Back to top](#)\n\nToggle table of contents sidebar\n\nThis guide seeks to walk you through using LlamaIndex with a production-ready web app starter template called [Delphic](https://github.com/JSv4/Delphic). All code examples here are available from the [Delphic](https://github.com/JSv4/Delphic) repo\n\n## What We\u2019re Building[\uf0c1](#what-we-re-building \"Permalink to this heading\")\n\nHere\u2019s a quick demo of the out-of-the-box functionality of Delphic:\n\nhttps://user-images.githubusercontent.com/5049984/233236432-aa4980b6-a510-42f3-887a-81485c9644e6.mp4\n\n## Architectural Overview[\uf0c1](#architectural-overview \"Permalink to this heading\")\n\nDelphic leverages the LlamaIndex python library to let users to create their own document collections they can then query in a responsive frontend.\n\nWe chose a stack that provides a responsive, robust mix of technologies that can (1) orchestrate complex python processing tasks while providing (2) a modern, responsive frontend and (3) a secure backend to build additional functionality upon.\n\nThe core libraries are:\n\n1.  [Django](https://www.djangoproject.com/)\n    \n2.  [Django Channels](https://channels.readthedocs.io/en/stable/)\n    \n3.  [Django Ninja](https://django-ninja.rest-framework.com/)\n    \n4.  [Redis](https://redis.io/)\n    \n5.  [Celery](https://docs.celeryq.dev/en/stable/getting-started/introduction.html)\n    \n6.  [LlamaIndex](https://gpt-index.readthedocs.io/en/latest/)\n    \n7.  [Langchain](https://python.langchain.com/en/latest/index.html)\n    \n8.  [React](https://github.com/facebook/react)\n    \n9.  Docker & Docker Compose\n    \n\nThanks to this modern stack built on the super stable Django web framework, the starter Delphic app boasts a streamlined developer experience, built-in authentication and user management, asynchronous vector store processing, and web-socket-based query connections for a responsive UI. In addition, our frontend is built with TypeScript and is based on MUI React for a responsive and modern user interface.\n\n## System Requirements[\uf0c1](#system-requirements \"Permalink to this heading\")\n\nCelery doesn\u2019t work on Windows. It may be deployable with Windows Subsystem for Linux, but configuring that is beyond the scope of this tutorial. For this reason, we recommend you only follow this tutorial if you\u2019re running Linux or OSX. You will need Docker and Docker Compose installed to deploy the application. Local development will require node version manager (nvm).\n\n## Django Backend[\uf0c1](#django-backend \"Permalink to this heading\")\n\n### Project Directory Overview[\uf0c1](#project-directory-overview \"Permalink to this heading\")\n\nThe Delphic application has a structured backend directory organization that follows common Django project conventions. From the repo root, in the `./delphic` subfolder, the main folders are:\n\n1.  `contrib`: This directory contains custom modifications or additions to Django\u2019s built-in `contrib` apps.\n    \n2.  `indexes`: This directory contains the core functionality related to document indexing and LLM integration. It includes:\n    \n\n*   `admin.py`: Django admin configuration for the app\n    \n*   `apps.py`: Application configuration\n    \n*   `models.py`: Contains the app\u2019s database models\n    \n*   `migrations`: Directory containing database schema migrations for the app\n    \n*   `signals.py`: Defines any signals for the app\n    \n*   `tests.py`: Unit tests for the app\n    \n\n3.  `tasks`: This directory contains tasks for asynchronous processing using Celery. The `index_tasks.py` file includes the tasks for creating vector indexes.\n    \n4.  `users`: This directory is dedicated to user management, including:\n    \n5.  `utils`: This directory contains utility modules and functions that are used across the application, such as custom storage backends, path helpers, and collection-related utilities.\n    \n\n### Database Models[\uf0c1](#database-models \"Permalink to this heading\")\n\nThe Delphic application has two core models: `Document` and `Collection`. These models represent the central entities the application deals with when indexing and querying documents using LLMs. They\u2019re defined in [`./delphic/indexes/models.py`](https://github.com/JSv4/Delphic/blob/main/delphic/indexes/models.py).\n\n1.  `Collection`:\n    \n\n*   `api_key`: A foreign key that links a collection to an API key. This helps associate jobs with the source API key.\n    \n*   `title`: A character field that provides a title for the collection.\n    \n*   `description`: A text field that provides a description of the collection.\n    \n*   `status`: A character field that stores the processing status of the collection, utilizing the `CollectionStatus` enumeration.\n    \n*   `created`: A datetime field that records when the collection was created.\n    \n*   `modified`: A datetime field that records the last modification time of the collection.\n    \n*   `model`: A file field that stores the model associated with the collection.\n    \n*   `processing`: A boolean field that indicates if the collection is currently being processed.\n    \n\n2.  `Document`:\n    \n\n*   `collection`: A foreign key that links a document to a collection. This represents the relationship between documents and collections.\n    \n*   `file`: A file field that stores the uploaded document file.\n    \n*   `description`: A text field that provides a description of the document.\n    \n*   `created`: A datetime field that records when the document was created.\n    \n*   `modified`: A datetime field that records the last modification time of the document.\n    \n\nThese models provide a solid foundation for collections of documents and the indexes created from them with LlamaIndex.\n\n### Django Ninja API[\uf0c1](#django-ninja-api \"Permalink to this heading\")\n\nDjango Ninja is a web framework for building APIs with Django and Python 3.7+ type hints. It provides a simple, intuitive, and expressive way of defining API endpoints, leveraging Python\u2019s type hints to automatically generate input validation, serialization, and documentation.\n\nIn the Delphic repo, the [`./config/api/endpoints.py`](https://github.com/JSv4/Delphic/blob/main/config/api/endpoints.py) file contains the API routes and logic for the API endpoints. Now, let\u2019s briefly address the purpose of each endpoint in the `endpoints.py` file:\n\n1.  `/heartbeat`: A simple GET endpoint to check if the API is up and running. Returns `True` if the API is accessible. This is helpful for Kubernetes setups that expect to be able to query your container to ensure it\u2019s up and running.\n    \n2.  `/collections/create`: A POST endpoint to create a new `Collection`. Accepts form parameters such as `title`, `description`, and a list of `files`. Creates a new `Collection` and `Document` instances for each file, and schedules a Celery task to create an index.\n    \n\n@collections\\_router.post(\"/create\")\nasync def create\\_collection(request,\n                            title: str \\= Form(...),\n                            description: str \\= Form(...),\n                            files: list\\[UploadedFile\\] \\= File(...), ):\n    key \\= None if getattr(request, \"auth\", None) is None else request.auth\n    if key is not None:\n        key \\= await key\n\n    collection\\_instance \\= Collection(\n        api\\_key\\=key,\n        title\\=title,\n        description\\=description,\n        status\\=CollectionStatusEnum.QUEUED,\n    )\n\n    await sync\\_to\\_async(collection\\_instance.save)()\n\n    for uploaded\\_file in files:\n        doc\\_data \\= uploaded\\_file.file.read()\n        doc\\_file \\= ContentFile(doc\\_data, uploaded\\_file.name)\n        document \\= Document(collection\\=collection\\_instance, file\\=doc\\_file)\n        await sync\\_to\\_async(document.save)()\n\n    create\\_index.si(collection\\_instance.id).apply\\_async()\n\n    return await sync\\_to\\_async(CollectionModelSchema)(\n        ...\n    )\n\n3.  `/collections/query` \u2014 a POST endpoint to query a document collection using the LLM. Accepts a JSON payload containing `collection_id` and `query_str`, and returns a response generated by querying the collection. We don\u2019t actually use this endpoint in our chat GUI (We use a websocket - see below), but you could build an app to integrate to this REST endpoint to query a specific collection.\n    \n\n@collections\\_router.post(\"/query\",\n                         response\\=CollectionQueryOutput,\n                         summary\\=\"Ask a question of a document collection\", )\ndef query\\_collection\\_view(request: HttpRequest, query\\_input: CollectionQueryInput):\n    collection\\_id \\= query\\_input.collection\\_id\n    query\\_str \\= query\\_input.query\\_str\n    response \\= query\\_collection(collection\\_id, query\\_str)\n    return {\"response\": response}\n\n4.  `/collections/available`: A GET endpoint that returns a list of all collections created with the user\u2019s API key. The output is serialized using the `CollectionModelSchema`.\n    \n\n@collections\\_router.get(\"/available\",\n                        response\\=list\\[CollectionModelSchema\\],\n                        summary\\=\"Get a list of all of the collections created with my api\\_key\", )\nasync def get\\_my\\_collections\\_view(request: HttpRequest):\n    key \\= None if getattr(request, \"auth\", None) is None else request.auth\n    if key is not None:\n        key \\= await key\n\n    collections \\= Collection.objects.filter(api\\_key\\=key)\n\n    return \\[\n        {\n            ...\n        }\n        async for collection in collections\n    \\]\n\n5.  `/collections/{collection_id}/add_file`: A POST endpoint to add a file to an existing collection. Accepts a `collection_id` path parameter, and form parameters such as `file` and `description`. Adds the file as a `Document` instance associated with the specified collection.\n    \n\n@collections\\_router.post(\"/{collection\\_id}/add\\_file\", summary\\=\"Add a file to a collection\")\nasync def add\\_file\\_to\\_collection(request,\n                                 collection\\_id: int,\n                                 file: UploadedFile \\= File(...),\n                                 description: str \\= Form(...), ):\n    collection \\= await sync\\_to\\_async(Collection.objects.get)(id\\=collection\\_id\n\n### Intro to Websockets[\uf0c1](#intro-to-websockets \"Permalink to this heading\")\n\nWebSockets are a communication protocol that enables bidirectional and full-duplex communication between a client and a server over a single, long-lived connection. The WebSocket protocol is designed to work over the same ports as HTTP and HTTPS (ports 80 and 443, respectively) and uses a similar handshake process to establish a connection. Once the connection is established, data can be sent in both directions as \u201cframes\u201d without the need to reestablish the connection each time, unlike traditional HTTP requests.\n\nThere are several reasons to use WebSockets, particularly when working with code that takes a long time to load into memory but is quick to run once loaded:\n\n1.  **Performance**: WebSockets eliminate the overhead associated with opening and closing multiple connections for each request, reducing latency.\n    \n2.  **Efficiency**: WebSockets allow for real-time communication without the need for polling, resulting in more efficient use of resources and better responsiveness.\n    \n3.  **Scalability**: WebSockets can handle a large number of simultaneous connections, making it ideal for applications that require high concurrency.\n    \n\nIn the case of the Delphic application, using WebSockets makes sense as the LLMs can be expensive to load into memory. By establishing a WebSocket connection, the LLM can remain loaded in memory, allowing subsequent requests to be processed quickly without the need to reload the model each time.\n\nThe ASGI configuration file [`./config/asgi.py`](https://github.com/JSv4/Delphic/blob/main/config/asgi.py) defines how the application should handle incoming connections, using the Django Channels `ProtocolTypeRouter` to route connections based on their protocol type. In this case, we have two protocol types: \u201chttp\u201d and \u201cwebsocket\u201d.\n\nThe \u201chttp\u201d protocol type uses the standard Django ASGI application to handle HTTP requests, while the \u201cwebsocket\u201d protocol type uses a custom `TokenAuthMiddleware` to authenticate WebSocket connections. The `URLRouter` within the `TokenAuthMiddleware` defines a URL pattern for the `CollectionQueryConsumer`, which is responsible for handling WebSocket connections related to querying document collections.\n\napplication \\= ProtocolTypeRouter(\n    {\n        \"http\": get\\_asgi\\_application(),\n        \"websocket\": TokenAuthMiddleware(\n            URLRouter(\n                \\[\n                    re\\_path(\n                        r\"ws/collections/(?P<collection\\_id>\\\\w+)/query/$\",\n                        CollectionQueryConsumer.as\\_asgi(),\n                    ),\n                \\]\n            )\n        ),\n    }\n)\n\nThis configuration allows clients to establish WebSocket connections with the Delphic application to efficiently query document collections using the LLMs, without the need to reload the models for each request.\n\n### Websocket Handler[\uf0c1](#websocket-handler \"Permalink to this heading\")\n\nThe `CollectionQueryConsumer` class in [`config/api/websockets/queries.py`](https://github.com/JSv4/Delphic/blob/main/config/api/websockets/queries.py) is responsible for handling WebSocket connections related to querying document collections. It inherits from the `AsyncWebsocketConsumer` class provided by Django Channels.\n\nThe `CollectionQueryConsumer` class has three main methods:\n\n1.  `connect`: Called when a WebSocket is handshaking as part of the connection process.\n    \n2.  `disconnect`: Called when a WebSocket closes for any reason.\n    \n3.  `receive`: Called when the server receives a message from the WebSocket.\n    \n\n#### Websocket connect listener[\uf0c1](#websocket-connect-listener \"Permalink to this heading\")\n\nThe `connect` method is responsible for establishing the connection, extracting the collection ID from the connection path, loading the collection model, and accepting the connection.\n\nasync def connect(self):\n    try:\n        self.collection\\_id \\= extract\\_connection\\_id(self.scope\\[\"path\"\\])\n        self.index \\= await load\\_collection\\_model(self.collection\\_id)\n        await self.accept()\n\nexcept ValueError as e:\nawait self.accept()\nawait self.close(code\\=4000)\nexcept Exception as e:\npass\n\n#### Websocket disconnect listener[\uf0c1](#websocket-disconnect-listener \"Permalink to this heading\")\n\nThe `disconnect` method is empty in this case, as there are no additional actions to be taken when the WebSocket is closed.\n\n#### Websocket receive listener[\uf0c1](#websocket-receive-listener \"Permalink to this heading\")\n\nThe `receive` method is responsible for processing incoming messages from the WebSocket. It takes the incoming message, decodes it, and then queries the loaded collection model using the provided query. The response is then formatted as a markdown string and sent back to the client over the WebSocket connection.\n\nasync def receive(self, text\\_data):\n    text\\_data\\_json \\= json.loads(text\\_data)\n\n    if self.index is not None:\n        query\\_str \\= text\\_data\\_json\\[\"query\"\\]\n        modified\\_query\\_str \\= f\"Please return a nicely formatted markdown string to this request:\\\\n\\\\n{query\\_str}\"\n        query\\_engine \\= self.index.as\\_query\\_engine()\n        response \\= query\\_engine.query(modified\\_query\\_str)\n\n        markdown\\_response \\= f\"## Response\\\\n\\\\n{response}\\\\n\\\\n\"\n        if response.source\\_nodes:\n            markdown\\_sources \\= f\"## Sources\\\\n\\\\n{response.get\\_formatted\\_sources()}\"\n        else:\n            markdown\\_sources \\= \"\"\n\n        formatted\\_response \\= f\"{markdown\\_response}{markdown\\_sources}\"\n\n        await self.send(json.dumps({\"response\": formatted\\_response}, indent\\=4))\n    else:\n        await self.send(json.dumps({\"error\": \"No index loaded for this connection.\"}, indent\\=4))\n\nTo load the collection model, the `load_collection_model` function is used, which can be found in [`delphic/utils/collections.py`](https://github.com/JSv4/Delphic/blob/main/delphic/utils/collections.py). This function retrieves the collection object with the given collection ID, checks if a JSON file for the collection model exists, and if not, creates one. Then, it sets up the `LLMPredictor` and `ServiceContext` before loading the `VectorStoreIndex` using the cache file.\n\nasync def load\\_collection\\_model(collection\\_id: str | int) \\-> VectorStoreIndex:\n    \"\"\"\n    Load the Collection model from cache or the database, and return the index.\n\n    Args:\n        collection\\_id (Union\\[str, int\\]): The ID of the Collection model instance.\n\n    Returns:\n        VectorStoreIndex: The loaded index.\n\n    This function performs the following steps:\n    1. Retrieve the Collection object with the given collection\\_id.\n    2. Check if a JSON file with the name '/cache/model\\_{collection\\_id}.json' exists.\n    3. If the JSON file doesn't exist, load the JSON from the Collection.model FileField and save it to\n       '/cache/model\\_{collection\\_id}.json'.\n    4. Call VectorStoreIndex.load\\_from\\_disk with the cache\\_file\\_path.\n    \"\"\"\n    \\# Retrieve the Collection object\n    collection \\= await Collection.objects.aget(id\\=collection\\_id)\n    logger.info(f\"load\\_collection\\_model() - loaded collection {collection\\_id}\")\n\n    \\# Make sure there's a model\n    if collection.model.name:\n        logger.info(\"load\\_collection\\_model() - Setup local json index file\")\n\n        \\# Check if the JSON file exists\n        cache\\_dir \\= Path(settings.BASE\\_DIR) / \"cache\"\n        cache\\_file\\_path \\= cache\\_dir / f\"model\\_{collection\\_id}.json\"\n        if not cache\\_file\\_path.exists():\n            cache\\_dir.mkdir(parents\\=True, exist\\_ok\\=True)\n            with collection.model.open(\"rb\") as model\\_file:\n                with cache\\_file\\_path.open(\"w+\", encoding\\=\"utf-8\") as cache\\_file:\n                    cache\\_file.write(model\\_file.read().decode(\"utf-8\"))\n\n        \\# define LLM\n        logger.info(\n            f\"load\\_collection\\_model() - Setup service context with tokens {settings.MAX\\_TOKENS} and \"\n            f\"model {settings.MODEL\\_NAME}\"\n        )\n        llm \\= OpenAI(temperature\\=0, model\\=\"text-davinci-003\", max\\_tokens\\=512)\n        service\\_context \\= ServiceContext.from\\_defaults(llm\\=llm)\n\n        \\# Call VectorStoreIndex.load\\_from\\_disk\n        logger.info(\"load\\_collection\\_model() - Load llama index\")\n        index \\= VectorStoreIndex.load\\_from\\_disk(\n            cache\\_file\\_path, service\\_context\\=service\\_context\n        )\n        logger.info(\n            \"load\\_collection\\_model() - Llamaindex loaded and ready for query...\"\n        )\n\n    else:\n        logger.error(\n            f\"load\\_collection\\_model() - collection {collection\\_id} has no model!\"\n        )\n        raise ValueError(\"No model exists for this collection!\")\n\n    return index\n\n## React Frontend[\uf0c1](#react-frontend \"Permalink to this heading\")\n\n### Overview[\uf0c1](#overview \"Permalink to this heading\")\n\nWe chose to use TypeScript, React and Material-UI (MUI) for the Delphic project\u2019s frontend for a couple reasons. First, as the most popular component library (MUI) for the most popular frontend framework (React), this choice makes this project accessible to a huge community of developers. Second, React is, at this point, a stable and generally well-liked framework that delivers valuable abstractions in the form of its virtual DOM while still being relatively stable and, in our opinion, pretty easy to learn, again making it accessible.\n\n### Frontend Project Structure[\uf0c1](#frontend-project-structure \"Permalink to this heading\")\n\nThe frontend can be found in the [`/frontend`](https://github.com/JSv4/Delphic/tree/main/frontend) directory of the repo, with the React-related components being in `/frontend/src` . You\u2019ll notice there is a DockerFile in the `frontend` directory and several folders and files related to configuring our frontend web server \u2014 [nginx](https://www.nginx.com/).\n\nThe `/frontend/src/App.tsx` file serves as the entry point of the application. It defines the main components, such as the login form, the drawer layout, and the collection create modal. The main components are conditionally rendered based on whether the user is logged in and has an authentication token.\n\nThe DrawerLayout2 component is defined in the`DrawerLayour2.tsx` file. This component manages the layout of the application and provides the navigation and main content areas.\n\nSince the application is relatively simple, we can get away with not using a complex state management solution like Redux and just use React\u2019s useState hooks.\n\n### Grabbing Collections from the Backend[\uf0c1](#grabbing-collections-from-the-backend \"Permalink to this heading\")\n\nThe collections available to the logged-in user are retrieved and displayed in the DrawerLayout2 component. The process can be broken down into the following steps:\n\n1.  Initializing state variables:\n    \n\nconst \\[collections, setCollections\\] = useState<CollectionModelSchema\\[\\]>(\\[\\]);\nconst \\[loading, setLoading\\] = useState(true);\n\nHere, we initialize two state variables: `collections` to store the list of collections and `loading` to track whether the collections are being fetched.\n\n2.  Collections are fetched for the logged-in user with the `fetchCollections()` function:\n    \n\nconst\nfetchCollections = async () = > {\ntry {\nconst accessToken = localStorage.getItem(\"accessToken\");\nif (accessToken) {\nconst response = await getMyCollections(accessToken);\nsetCollections(response.data);\n}\n} catch (error) {\nconsole.error(error);\n} finally {\nsetLoading(false);\n}\n};\n\nThe `fetchCollections` function retrieves the collections for the logged-in user by calling the `getMyCollections` API function with the user\u2019s access token. It then updates the `collections` state with the retrieved data and sets the `loading` state to `false` to indicate that fetching is complete.\n\n### Displaying Collections[\uf0c1](#displaying-collections \"Permalink to this heading\")\n\nThe latest collectios are displayed in the drawer like this:\n\n< List >\n{collections.map((collection) = > (\n    < div key={collection.id} >\n    < ListItem disablePadding >\n    < ListItemButton\n    disabled={\n    collection.status != = CollectionStatus.COMPLETE | |\n    !collection.has\\_model\n    }\n    onClick={() = > handleCollectionClick(collection)}\nselected = {\n    selectedCollection & &\n    selectedCollection.id == = collection.id\n}\n>\n< ListItemText\nprimary = {collection.title} / >\n          {collection.status == = CollectionStatus.RUNNING ? (\n    < CircularProgress\n    size={24}\n    style={{position: \"absolute\", right: 16}}\n    / >\n): null}\n< / ListItemButton >\n    < / ListItem >\n        < / div >\n))}\n< / List >\n\nYou\u2019ll notice that the `disabled` property of a collection\u2019s `ListItemButton` is set based on whether the collection\u2019s status is not `CollectionStatus.COMPLETE` or the collection does not have a model (`!collection.has_model`). If either of these conditions is true, the button is disabled, preventing users from selecting an incomplete or model-less collection. Where the CollectionStatus is RUNNING, we also show a loading wheel over the button.\n\nIn a separate `useEffect` hook, we check if any collection in the `collections` state has a status of `CollectionStatus.RUNNING` or `CollectionStatus.QUEUED`. If so, we set up an interval to repeatedly call the `fetchCollections` function every 15 seconds (15,000 milliseconds) to update the collection statuses. This way, the application periodically checks for completed collections, and the UI is updated accordingly when the processing is done.\n\nuseEffect(() = > {\n    let\ninterval: NodeJS.Timeout;\nif (\n    collections.some(\n        (collection) = >\ncollection.status == = CollectionStatus.RUNNING | |\ncollection.status == = CollectionStatus.QUEUED\n)\n) {\n    interval = setInterval(() = > {\n    fetchCollections();\n}, 15000);\n}\nreturn () = > clearInterval(interval);\n}, \\[collections\\]);\n\n### Chat View Component[\uf0c1](#chat-view-component \"Permalink to this heading\")\n\nThe `ChatView` component in `frontend/src/chat/ChatView.tsx` is responsible for handling and displaying a chat interface for a user to interact with a collection. The component establishes a WebSocket connection to communicate in real-time with the server, sending and receiving messages.\n\nKey features of the `ChatView` component include:\n\n1.  Establishing and managing the WebSocket connection with the server.\n    \n2.  Displaying messages from the user and the server in a chat-like format.\n    \n3.  Handling user input to send messages to the server.\n    \n4.  Updating the messages state and UI based on received messages from the server.\n    \n5.  Displaying connection status and errors, such as loading messages, connecting to the server, or encountering errors while loading a collection.\n    \n\nTogether, all of this allows users to interact with their selected collection with a very smooth, low-latency experience.\n\n#### Chat Websocket Client[\uf0c1](#chat-websocket-client \"Permalink to this heading\")\n\nThe WebSocket connection in the `ChatView` component is used to establish real-time communication between the client and the server. The WebSocket connection is set up and managed in the `ChatView` component as follows:\n\nFirst, we want to initialize the the WebSocket reference:\n\nconst websocket = useRef<WebSocket | null>(null);\n\nA `websocket` reference is created using `useRef`, which holds the WebSocket object that will be used for communication. `useRef` is a hook in React that allows you to create a mutable reference object that persists across renders. It is particularly useful when you need to hold a reference to a mutable object, such as a WebSocket connection, without causing unnecessary re-renders.\n\nIn the `ChatView` component, the WebSocket connection needs to be established and maintained throughout the lifetime of the component, and it should not trigger a re-render when the connection state changes. By using `useRef`, you ensure that the WebSocket connection is kept as a reference, and the component only re-renders when there are actual state changes, such as updating messages or displaying errors.\n\nThe `setupWebsocket` function is responsible for establishing the WebSocket connection and setting up event handlers to handle different WebSocket events.\n\nOverall, the setupWebsocket function looks like this:\n\nconst setupWebsocket = () => {\n  setConnecting(true);\n  // Here, a new WebSocket object is created using the specified URL, which includes the\n  // selected collection's ID and the user's authentication token.\n\n  websocket.current = new WebSocket(\n    \\`ws://localhost:8000/ws/collections/${selectedCollection.id}/query/?token=${authToken}\\`,\n  );\n\n  websocket.current.onopen = (event) => {\n    //...\n  };\n\n  websocket.current.onmessage = (event) => {\n    //...\n  };\n\n  websocket.current.onclose = (event) => {\n    //...\n  };\n\n  websocket.current.onerror = (event) => {\n    //...\n  };\n\n  return () => {\n    websocket.current?.close();\n  };\n};\n\nNotice in a bunch of places we trigger updates to the GUI based on the information from the web socket client.\n\nWhen the component first opens and we try to establish a connection, the `onopen` listener is triggered. In the callback, the component updates the states to reflect that the connection is established, any previous errors are cleared, and no messages are awaiting responses:\n\nwebsocket.current.onopen = (event) => {\n  setError(false);\n  setConnecting(false);\n  setAwaitingMessage(false);\n\n  console.log(\"WebSocket connected:\", event);\n};\n\n`onmessage`is triggered when a new message is received from the server through the WebSocket connection. In the callback, the received data is parsed and the `messages` state is updated with the new message from the server:\n\nwebsocket.current.onmessage \\= (event) \\=> {\n  const data \\= JSON.parse(event.data);\n  console.log(\"WebSocket message received:\", data);\n  setAwaitingMessage(false);\n\n  if (data.response) {\n    // Update the messages state with the new message from the server\n    setMessages((prevMessages) \\=> \\[\n      ...prevMessages,\n      {\n        sender\\_id: \"server\",\n        message: data.response,\n        timestamp: new Date().toLocaleTimeString(),\n      },\n    \\]);\n  }\n};\n\n`onclose`is triggered when the WebSocket connection is closed. In the callback, the component checks for a specific close code (`4000`) to display a warning toast and update the component states accordingly. It also logs the close event:\n\nwebsocket.current.onclose = (event) => {\n  if (event.code === 4000) {\n    toast.warning(\n      \"Selected collection's model is unavailable. Was it created properly?\",\n    );\n    setError(true);\n    setConnecting(false);\n    setAwaitingMessage(false);\n  }\n  console.log(\"WebSocket closed:\", event);\n};\n\nFinally, `onerror` is triggered when an error occurs with the WebSocket connection. In the callback, the component updates the states to reflect the error and logs the error event:\n\nwebsocket.current.onerror = (event) => {\n  setError(true);\n  setConnecting(false);\n  setAwaitingMessage(false);\n\n  console.error(\"WebSocket error:\", event);\n};\n\n#### Rendering our Chat Messages[\uf0c1](#rendering-our-chat-messages \"Permalink to this heading\")\n\nIn the `ChatView` component, the layout is determined using CSS styling and Material-UI components. The main layout consists of a container with a `flex` display and a column-oriented `flexDirection`. This ensures that the content within the container is arranged vertically.\n\nThere are three primary sections within the layout:\n\n1.  The chat messages area: This section takes up most of the available space and displays a list of messages exchanged between the user and the server. It has an overflow-y set to \u2018auto\u2019, which allows scrolling when the content overflows the available space. The messages are rendered using the `ChatMessage` component for each message and a `ChatMessageLoading` component to show the loading state while waiting for a server response.\n    \n2.  The divider: A Material-UI `Divider` component is used to separate the chat messages area from the input area, creating a clear visual distinction between the two sections.\n    \n3.  The input area: This section is located at the bottom and allows the user to type and send messages. It contains a `TextField` component from Material-UI, which is set to accept multiline input with a maximum of 2 rows. The input area also includes a `Button` component to send the message. The user can either click the \u201cSend\u201d button or press \u201c Enter\u201d on their keyboard to send the message.\n    \n\nThe user inputs accepted in the `ChatView` component are text messages that the user types in the `TextField`. The component processes these text inputs and sends them to the server through the WebSocket connection.\n\n## Deployment[\uf0c1](#deployment \"Permalink to this heading\")\n\n### Build and Deploy[\uf0c1](#build-and-deploy \"Permalink to this heading\")\n\nThe project is based on django-cookiecutter, and it\u2019s pretty easy to get it deployed on a VM and configured to serve HTTPs traffic for a specific domain. The configuration is somewhat involved, however \u2014 not because of this project, but it\u2019s just a fairly involved topic to configure your certificates, DNS, etc.\n\nFor the purposes of this guide, let\u2019s just get running locally. Perhaps we\u2019ll release a guide on production deployment. In the meantime, check out the [Django Cookiecutter project docs](https://cookiecutter-django.readthedocs.io/en/latest/deployment-with-docker.html) for starters.\n\nThis guide assumes your goal is to get the application up and running for use. If you want to develop, most likely you won\u2019t want to launch the compose stack with the \u2014 profiles fullstack flag and will instead want to launch the react frontend using the node development server.\n\nTo deploy, first clone the repo:\n\ngit clone https://github.com/yourusername/delphic.git\n\nChange into the project directory:\n\nCopy the sample environment files:\n\nmkdir -p ./.envs/.local/\ncp -a ./docs/sample\\_envs/local/.frontend ./frontend\ncp -a ./docs/sample\\_envs/local/.django ./.envs/.local\ncp -a ./docs/sample\\_envs/local/.postgres ./.envs/.local\n\nEdit the `.django` and `.postgres` configuration files to include your OpenAI API key and set a unique password for your database user. You can also set the response token limit in the .django file or switch which OpenAI model you want to use. GPT4 is supported, assuming you\u2019re authorized to access it.\n\nBuild the docker compose stack with the `--profiles fullstack` flag:\n\nsudo docker-compose --profiles fullstack -f local.yml build\n\nThe fullstack flag instructs compose to build a docker container from the frontend folder and this will be launched along with all of the needed, backend containers. It takes a long time to build a production React container, however, so we don\u2019t recommend you develop this way. Follow the [instructions in the project readme.md](https://github.com/JSv4/Delphic#development) for development environment setup instructions.\n\nFinally, bring up the application:\n\nsudo docker-compose -f local.yml up\n\nNow, visit `localhost:3000` in your browser to see the frontend, and use the Delphic application locally.\n\n## Using the Application[\uf0c1](#using-the-application \"Permalink to this heading\")\n\n### Setup Users[\uf0c1](#setup-users \"Permalink to this heading\")\n\nIn order to actually use the application (at the moment, we intend to make it possible to share certain models with unauthenticated users), you need a login. You can use either a superuser or non-superuser. In either case, someone needs to first create a superuser using the console:\n\n**Why set up a Django superuser?** A Django superuser has all the permissions in the application and can manage all aspects of the system, including creating, modifying, and deleting users, collections, and other data. Setting up a superuser allows you to fully control and manage the application.\n\n**How to create a Django superuser:**\n\n1 Run the following command to create a superuser:\n\nsudo docker-compose -f local.yml run django python manage.py createsuperuser\n\n2 You will be prompted to provide a username, email address, and password for the superuser. Enter the required information.\n\n**How to create additional users using Django admin:**\n\n1.  Start your Delphic application locally following the deployment instructions.\n    \n2.  Visit the Django admin interface by navigating to `http://localhost:8000/admin` in your browser.\n    \n3.  Log in with the superuser credentials you created earlier.\n    \n4.  Click on \u201cUsers\u201d under the \u201cAuthentication and Authorization\u201d section.\n    \n5.  Click on the \u201cAdd user +\u201d button in the top right corner.\n    \n6.  Enter the required information for the new user, such as username and password. Click \u201cSave\u201d to create the user.\n    \n7.  To grant the new user additional permissions or make them a superuser, click on their username in the user list, scroll down to the \u201cPermissions\u201d section, and configure their permissions accordingly. Save your changes."
}