{
    "metadata": {
        "type": "web",
        "url": "https://docs.llamaindex.ai/en/stable/examples/vector_stores/CassandraIndexDemo.html",
        "title": "Cassandra Vector Store - LlamaIndex \ud83e\udd99 0.8.49",
        "description": null
    },
    "text": "[Back to top](#)\n\nToggle table of contents sidebar\n\n## Cassandra Vector Store[\uf0c1](#cassandra-vector-store \"Permalink to this heading\")\n\n[Apache Cassandra\u00ae](https://cassandra.apache.org/) is a NoSQL, row-oriented, highly scalable and highly available database. Newest Cassandra releases natively [support](https://cwiki.apache.org/confluence/display/CASSANDRA/CEP-30%3A+Approximate+Nearest+Neighbor(ANN)+Vector+Search+via+Storage-Attached+Indexes) Vector Similarity Search.\n\n**This notebook shows the basic usage of Cassandra as a Vector Store in LlamaIndex.**\n\nTo run this notebook you need either a running Cassandra cluster equipped with Vector Search capabilities (in pre-release at the time of writing) or a DataStax Astra DB instance running in the cloud (you can get one for free at [datastax.com](https://astra.datastax.com/)). _This notebook covers both choices._ Check [cassio.org](https://cassio.org/start_here/) for more information, quickstarts and tutorials.\n\n## Setup[\uf0c1](#setup \"Permalink to this heading\")\n\n!pip install \"cassio>=0.1.0\"\n\nimport os\n\nfrom llama\\_index import (\n    VectorStoreIndex,\n    SimpleDirectoryReader,\n    Document,\n    StorageContext,\n)\nfrom llama\\_index.vector\\_stores import CassandraVectorStore\n\n### Please provide database connection parameters and secrets[\uf0c1](#please-provide-database-connection-parameters-and-secrets \"Permalink to this heading\")\n\nFirst you need a database connection (a `cassandra.cluster.Session` object).\n\nMake sure you have either a vector-capable running Cassandra cluster or an [Astra DB](https://astra.datastax.com/) instance in the cloud.\n\nimport os\nimport getpass\n\ndatabase\\_mode \\= (input(\"\\\\n(C)assandra or (A)stra DB? \")).upper()\n\nkeyspace\\_name \\= input(\"\\\\nKeyspace name? \")\n\nif database\\_mode \\== \"A\":\n    ASTRA\\_DB\\_APPLICATION\\_TOKEN \\= getpass.getpass(\n        '\\\\nAstra DB Token (\"AstraCS:...\") '\n    )\n    #\n    ASTRA\\_DB\\_SECURE\\_BUNDLE\\_PATH \\= input(\n        \"Full path to your Secure Connect Bundle? \"\n    )\nelif database\\_mode \\== \"C\":\n    CASSANDRA\\_CONTACT\\_POINTS \\= input(\n        \"Contact points? (comma-separated, empty for localhost) \"\n    ).strip()\n\nfrom cassandra.cluster import Cluster\nfrom cassandra.auth import PlainTextAuthProvider\n\nif database\\_mode \\== \"C\":\n    if CASSANDRA\\_CONTACT\\_POINTS:\n        cluster \\= Cluster(\n            \\[\n                cp.strip()\n                for cp in CASSANDRA\\_CONTACT\\_POINTS.split(\",\")\n                if cp.strip()\n            \\]\n        )\n    else:\n        cluster \\= Cluster()\n    session \\= cluster.connect()\nelif database\\_mode \\== \"A\":\n    ASTRA\\_DB\\_CLIENT\\_ID \\= \"token\"\n    cluster \\= Cluster(\n        cloud\\={\n            \"secure\\_connect\\_bundle\": ASTRA\\_DB\\_SECURE\\_BUNDLE\\_PATH,\n        },\n        auth\\_provider\\=PlainTextAuthProvider(\n            ASTRA\\_DB\\_CLIENT\\_ID,\n            ASTRA\\_DB\\_APPLICATION\\_TOKEN,\n        ),\n    )\n    session \\= cluster.connect()\nelse:\n    raise NotImplementedError\n\n### Please provide OpenAI access key[\uf0c1](#please-provide-openai-access-key \"Permalink to this heading\")\n\nIn order use embeddings by OpenAI you need to supply an OpenAI API Key:\n\nimport openai\n\nOPENAI\\_API\\_KEY \\= getpass.getpass(\"OpenAI API Key:\")\nopenai.api\\_key \\= OPENAI\\_API\\_KEY\n\n## Creating and populating the Vector Store[\uf0c1](#creating-and-populating-the-vector-store \"Permalink to this heading\")\n\nYou will now load some essays by Paul Graham from a local file and store them into the Cassandra Vector Store.\n\n\\# load documents\ndocuments \\= SimpleDirectoryReader(\"../data/paul\\_graham\").load\\_data()\nprint(f\"Total documents: {len(documents)}\")\nprint(f\"First document, id: {documents\\[0\\].doc\\_id}\")\nprint(f\"First document, hash: {documents\\[0\\].hash}\")\nprint(\n    \"First document, text\"\n    f\" ({len(documents\\[0\\].text)} characters):\\\\n{'='\\*20}\\\\n{documents\\[0\\].text\\[:360\\]} ...\"\n)\n\nTotal documents: 1\nFirst document, id: 5b7489b6-0cca-4088-8f30-6de32d540fdf\nFirst document, hash: 4c702b4df575421e1d1af4b1fd50511b226e0c9863dbfffeccb8b689b8448f35\nFirst document, text (75019 characters):\n====================\n\t\t\n\nWhat I Worked On\n\nFebruary 2021\n\nBefore college the two main things I worked on, outside of school, were writing and programming. I didn't write essays. I wrote what beginning writers were supposed to write then, and probably still are: short stories. My stories were awful. They had hardly any plot, just characters with strong feelings, which I imagined  ...\n\n### Initialize the Cassandra Vector Store[\uf0c1](#initialize-the-cassandra-vector-store \"Permalink to this heading\")\n\nCreation of the vector store entails creation of the underlying database table if it does not exist yet:\n\ncassandra\\_store \\= CassandraVectorStore(\n    session\\=session,\n    keyspace\\=keyspace\\_name,\n    table\\=\"cassandra\\_vector\\_table\\_1\",\n    embedding\\_dimension\\=1536,\n)\n\nNow wrap this store into an `index` LlamaIndex abstraction for later querying:\n\nstorage\\_context \\= StorageContext.from\\_defaults(vector\\_store\\=cassandra\\_store)\n\nindex \\= VectorStoreIndex.from\\_documents(\n    documents, storage\\_context\\=storage\\_context\n)\n\nNote that the above `from_documents` call does several things at once: it splits the input documents into chunks of manageable size (\u201cnodes\u201d), computes embedding vectors for each node, and stores them all in the Cassandra Vector Store.\n\n## Querying the store[\uf0c1](#querying-the-store \"Permalink to this heading\")\n\n### Basic querying[\uf0c1](#basic-querying \"Permalink to this heading\")\n\nquery\\_engine \\= index.as\\_query\\_engine()\nresponse \\= query\\_engine.query(\"Why did the author choose to work on AI?\")\nprint(response.response)\n\nThe author chose to work on AI because of his fascination with the novel The Moon is a Harsh Mistress, which featured an intelligent computer called Mike, and a PBS documentary that showed Terry Winograd using SHRDLU. He was also drawn to the idea that AI could be used to explore the ultimate truths that other fields could not.\n\n### MMR-based queries[\uf0c1](#mmr-based-queries \"Permalink to this heading\")\n\nThe MMR (maximal marginal relevance) method is designed to fetch text chunks from the store that are at the same time relevant to the query but as different as possible from each other, with the goal of providing a broader context to the building of the final answer:\n\nquery\\_engine \\= index.as\\_query\\_engine(vector\\_store\\_query\\_mode\\=\"mmr\")\nresponse \\= query\\_engine.query(\"Why did the author choose to work on AI?\")\nprint(response.response)\n\nThe author chose to work on AI because he was impressed and envious of his friend who had built a computer kit and was able to type programs into it. He was also inspired by a novel by Heinlein called The Moon is a Harsh Mistress, which featured an intelligent computer called Mike, and a PBS documentary that showed Terry Winograd using SHRDLU. He was also disappointed with philosophy courses in college, which he found to be boring, and he wanted to work on something that seemed more powerful.\n\n## Connecting to an existing store[\uf0c1](#connecting-to-an-existing-store \"Permalink to this heading\")\n\nSince this store is backed by Cassandra, it is persistent by definition. So, if you want to connect to a store that was created and populated previously, here is how:\n\nnew\\_store\\_instance \\= CassandraVectorStore(\n    session\\=session,\n    keyspace\\=keyspace\\_name,\n    table\\=\"cassandra\\_vector\\_table\\_1\",\n    embedding\\_dimension\\=1536,\n)\n\n\\# Create index (from preexisting stored vectors)\nnew\\_index\\_instance \\= VectorStoreIndex.from\\_vector\\_store(\n    vector\\_store\\=new\\_store\\_instance\n)\n\n\\# now you can do querying, etc:\nquery\\_engine \\= index.as\\_query\\_engine(similarity\\_top\\_k\\=5)\nresponse \\= query\\_engine.query(\n    \"What did the author study prior to working on AI?\"\n)\n\nThe author studied philosophy and painting, worked on spam filters, and wrote essays prior to working on AI.\n\n## Removing documents from the index[\uf0c1](#removing-documents-from-the-index \"Permalink to this heading\")\n\nFirst get an explicit list of pieces of a document, or \u201cnodes\u201d, from a `Retriever` spawned from the index:\n\nretriever \\= new\\_index\\_instance.as\\_retriever(\n    vector\\_store\\_query\\_mode\\=\"mmr\",\n    similarity\\_top\\_k\\=3,\n    vector\\_store\\_kwargs\\={\"mmr\\_prefetch\\_factor\": 4},\n)\nnodes\\_with\\_scores \\= retriever.retrieve(\n    \"What did the author study prior to working on AI?\"\n)\n\nprint(f\"Found {len(nodes\\_with\\_scores)} nodes.\")\nfor idx, node\\_with\\_score in enumerate(nodes\\_with\\_scores):\n    print(f\"    \\[{idx}\\] score = {node\\_with\\_score.score}\")\n    print(f\"        id    = {node\\_with\\_score.node.node\\_id}\")\n    print(f\"        text  = {node\\_with\\_score.node.text\\[:90\\]} ...\")\n\nFound 3 nodes.\n    \\[0\\] score = 0.42589144520149874\n        id    = 05f53f06-9905-461a-bc6d-fa4817e5a776\n        text  = What I Worked On\n\nFebruary 2021\n\nBefore college the two main things I worked on, outside o ...\n    \\[1\\] score = -0.0012061281453193962\n        id    = 2f9f843e-6495-4646-a03d-4b844ff7c1ab\n        text  = been explored. But all I wanted was to get out of grad school, and my rapidly written diss ...\n    \\[2\\] score = 0.025454533089838027\n        id    = 28ad32da-25f9-4aaa-8487-88390ec13348\n        text  = showed Terry Winograd using SHRDLU. I haven't tried rereading The Moon is a Harsh Mistress ...\n\nBut wait! When using the vector store, you should consider the **document** as the sensible unit to delete, and not any individual node belonging to it. Well, in this case, you just inserted a single text file, so all nodes will have the same `ref_doc_id`:\n\nprint(\"Nodes' ref\\_doc\\_id:\")\nprint(\"\\\\n\".join(\\[nws.node.ref\\_doc\\_id for nws in nodes\\_with\\_scores\\]))\n\nNodes' ref\\_doc\\_id:\n5b7489b6-0cca-4088-8f30-6de32d540fdf\n5b7489b6-0cca-4088-8f30-6de32d540fdf\n5b7489b6-0cca-4088-8f30-6de32d540fdf\n\nNow let\u2019s say you need to remove the text file you uploaded:\n\nnew\\_store\\_instance.delete(nodes\\_with\\_scores\\[0\\].node.ref\\_doc\\_id)\n\nRepeat the very same query and check the results now. You should see _no results_ being found:\n\nnodes\\_with\\_scores \\= retriever.retrieve(\n    \"What did the author study prior to working on AI?\"\n)\n\nprint(f\"Found {len(nodes\\_with\\_scores)} nodes.\")"
}