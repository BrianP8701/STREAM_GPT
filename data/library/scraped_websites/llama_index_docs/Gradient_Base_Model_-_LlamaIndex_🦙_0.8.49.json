{
    "metadata": {
        "type": "web",
        "url": "https://docs.llamaindex.ai/en/stable/api_reference/llms/gradient_base_model.html",
        "title": "Gradient Base Model - LlamaIndex \ud83e\udd99 0.8.49",
        "description": null
    },
    "text": "[Back to top](#)\n\nToggle table of contents sidebar\n\n## Gradient Base Model[\uf0c1](#gradient-base-model \"Permalink to this heading\")\n\n_pydantic model_ llama\\_index.llms.gradient.GradientBaseModelLLM[\uf0c1](#llama_index.llms.gradient.GradientBaseModelLLM \"Permalink to this definition\")\n\nShow JSON schema\n\n{\n   \"title\": \"GradientBaseModelLLM\",\n   \"description\": \"Simple abstract base class for custom LLMs.\\\\n\\\\nSubclasses must implement the \\`\\_\\_init\\_\\_\\`, \\`complete\\`,\\\\n    \\`stream\\_complete\\`, and \\`metadata\\` methods.\",\n   \"type\": \"object\",\n   \"properties\": {\n      \"callback\\_manager\": {\n         \"title\": \"Callback Manager\"\n      },\n      \"max\\_tokens\": {\n         \"title\": \"Max Tokens\",\n         \"description\": \"The number of tokens to generate.\",\n         \"exclusiveMinimum\": 0,\n         \"exclusiveMaximum\": 512,\n         \"type\": \"integer\"\n      },\n      \"access\\_token\": {\n         \"title\": \"Access Token\",\n         \"description\": \"The Gradient access token to use.\",\n         \"type\": \"string\"\n      },\n      \"host\": {\n         \"title\": \"Host\",\n         \"description\": \"The url of the Gradient service to access.\",\n         \"type\": \"string\"\n      },\n      \"workspace\\_id\": {\n         \"title\": \"Workspace Id\",\n         \"description\": \"The Gradient workspace id to use.\",\n         \"type\": \"string\"\n      },\n      \"base\\_model\\_slug\": {\n         \"title\": \"Base Model Slug\",\n         \"description\": \"The slug of the base model to use.\",\n         \"type\": \"string\"\n      }\n   },\n   \"required\": \\[\n      \"base\\_model\\_slug\"\n   \\]\n}\n\nConfig\n\n*   **arbitrary\\_types\\_allowed**: _bool = True_\n    \n\nFields\n\n*   [`access_token (Optional[str])`](#llama_index.llms.gradient.GradientBaseModelLLM.access_token \"llama_index.llms.gradient.GradientBaseModelLLM.access_token\")\n    \n*   [`base_model_slug (str)`](#llama_index.llms.gradient.GradientBaseModelLLM.base_model_slug \"llama_index.llms.gradient.GradientBaseModelLLM.base_model_slug\")\n    \n*   `callback_manager (llama_index.callbacks.base.CallbackManager)`\n    \n*   [`host (Optional[str])`](#llama_index.llms.gradient.GradientBaseModelLLM.host \"llama_index.llms.gradient.GradientBaseModelLLM.host\")\n    \n*   [`max_tokens (Optional[int])`](#llama_index.llms.gradient.GradientBaseModelLLM.max_tokens \"llama_index.llms.gradient.GradientBaseModelLLM.max_tokens\")\n    \n*   [`workspace_id (Optional[str])`](#llama_index.llms.gradient.GradientBaseModelLLM.workspace_id \"llama_index.llms.gradient.GradientBaseModelLLM.workspace_id\")\n    \n\nValidators\n\n*   `_validate_callback_manager` \u00bb `callback_manager`\n    \n\n_field_ access\\_token_: Optional\\[str\\]_ _\\= None_[\uf0c1](#llama_index.llms.gradient.GradientBaseModelLLM.access_token \"Permalink to this definition\")\n\nThe Gradient access token to use.\n\n_field_ base\\_model\\_slug_: str_ _\\[Required\\]_[\uf0c1](#llama_index.llms.gradient.GradientBaseModelLLM.base_model_slug \"Permalink to this definition\")\n\nThe slug of the base model to use.\n\n_field_ host_: Optional\\[str\\]_ _\\= None_[\uf0c1](#llama_index.llms.gradient.GradientBaseModelLLM.host \"Permalink to this definition\")\n\nThe url of the Gradient service to access.\n\n_field_ max\\_tokens_: Optional\\[int\\]_ _\\= None_[\uf0c1](#llama_index.llms.gradient.GradientBaseModelLLM.max_tokens \"Permalink to this definition\")\n\nThe number of tokens to generate.\n\nConstraints\n\n*   **exclusiveMinimum** = 0\n    \n*   **exclusiveMaximum** = 512\n    \n\n_field_ workspace\\_id_: Optional\\[str\\]_ _\\= None_[\uf0c1](#llama_index.llms.gradient.GradientBaseModelLLM.workspace_id \"Permalink to this definition\")\n\nThe Gradient workspace id to use.\n\nclose() \u2192 None[\uf0c1](#llama_index.llms.gradient.GradientBaseModelLLM.close \"Permalink to this definition\")\n\ncomplete(_\\*args: Any_, _\\*\\*kwargs: Any_) \u2192 Any[\uf0c1](#llama_index.llms.gradient.GradientBaseModelLLM.complete \"Permalink to this definition\")\n\nCompletion endpoint for LLM.\n\nstream\\_complete(_prompt: str_, _\\*\\*kwargs: Any_) \u2192 Generator\\[[CompletionResponse](https://docs.llamaindex.ai/en/stable/api_reference/llms.html#llama_index.llms.base.CompletionResponse \"llama_index.llms.base.CompletionResponse\"), None, None\\][\uf0c1](#llama_index.llms.gradient.GradientBaseModelLLM.stream_complete \"Permalink to this definition\")\n\nStreaming completion endpoint for LLM.\n\n_property_ metadata_: [LLMMetadata](https://docs.llamaindex.ai/en/stable/api_reference/llms.html#llama_index.llms.base.LLMMetadata \"llama_index.llms.base.LLMMetadata\")_[\uf0c1](#llama_index.llms.gradient.GradientBaseModelLLM.metadata \"Permalink to this definition\")\n\nLLM metadata."
}