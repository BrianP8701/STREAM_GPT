{
    "metadata": {
        "type": "web",
        "url": "https://docs.llamaindex.ai/en/stable/api_reference/llms/xinference.html",
        "title": "XOrbits Xinference - LlamaIndex \ud83e\udd99 0.8.49",
        "description": null
    },
    "text": "{\n   \"title\": \"Xinference\",\n   \"description\": \"Simple abstract base class for custom LLMs.\\\\n\\\\nSubclasses must implement the \\`\\_\\_init\\_\\_\\`, \\`complete\\`,\\\\n    \\`stream\\_complete\\`, and \\`metadata\\` methods.\",\n   \"type\": \"object\",\n   \"properties\": {\n      \"callback\\_manager\": {\n         \"title\": \"Callback Manager\"\n      },\n      \"model\\_uid\": {\n         \"title\": \"Model Uid\",\n         \"description\": \"The Xinference model to use.\",\n         \"type\": \"string\"\n      },\n      \"endpoint\": {\n         \"title\": \"Endpoint\",\n         \"description\": \"The Xinference endpoint URL to use.\",\n         \"type\": \"string\"\n      },\n      \"temperature\": {\n         \"title\": \"Temperature\",\n         \"description\": \"The temperature to use for sampling.\",\n         \"type\": \"number\"\n      },\n      \"max\\_tokens\": {\n         \"title\": \"Max Tokens\",\n         \"description\": \"The maximum new tokens to generate as answer.\",\n         \"type\": \"integer\"\n      },\n      \"context\\_window\": {\n         \"title\": \"Context Window\",\n         \"description\": \"The maximum number of context tokens for the model.\",\n         \"type\": \"integer\"\n      },\n      \"model\\_description\": {\n         \"title\": \"Model Description\",\n         \"description\": \"The model description from Xinference.\",\n         \"type\": \"object\"\n      }\n   },\n   \"required\": \\[\n      \"model\\_uid\",\n      \"endpoint\",\n      \"temperature\",\n      \"max\\_tokens\",\n      \"context\\_window\",\n      \"model\\_description\"\n   \\]\n}"
}