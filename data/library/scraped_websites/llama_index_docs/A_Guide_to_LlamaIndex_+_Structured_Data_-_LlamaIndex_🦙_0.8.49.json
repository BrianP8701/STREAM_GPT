{
    "metadata": {
        "type": "web",
        "url": "https://docs.llamaindex.ai/en/stable/end_to_end_tutorials/structured_data/sql_guide.html",
        "title": "A Guide to LlamaIndex + Structured Data - LlamaIndex \ud83e\udd99 0.8.49",
        "description": null
    },
    "text": "Toggle table of contents sidebar\n\nA lot of modern data systems depend on structured data, such as a Postgres DB or a Snowflake data warehouse. LlamaIndex provides a lot of advanced features, powered by LLM\u2019s, to both create structured data from unstructured data, as well as analyze this structured data through augmented text-to-SQL capabilities.\n\nThis guide helps walk through each of these capabilities. Specifically, we cover the following topics:\n\n*   **Setup**: Defining up our example SQL Table.\n    \n*   **Building our Table Index**: How to go from sql database to a Table Schema Index\n    \n*   **Using natural language SQL queries**: How to query our SQL database using natural language.\n    \n\nWe will walk through a toy example table which contains city/population/country information. A notebook for this tutorial is [available here](https://docs.llamaindex.ai/en/stable/examples/index_structs/struct_indices/SQLIndexDemo.html).\n\n## Setup[\uf0c1](#setup \"Permalink to this heading\")\n\nFirst, we use SQLAlchemy to setup a simple sqlite db:\n\nfrom sqlalchemy import create\\_engine, MetaData, Table, Column, String, Integer, select, column\n\nengine \\= create\\_engine(\"sqlite:///:memory:\")\nmetadata\\_obj \\= MetaData()\n\nWe then create a toy `city_stats` table:\n\n\\# create city SQL table\ntable\\_name \\= \"city\\_stats\"\ncity\\_stats\\_table \\= Table(\n    table\\_name,\n    metadata\\_obj,\n    Column(\"city\\_name\", String(16), primary\\_key\\=True),\n    Column(\"population\", Integer),\n    Column(\"country\", String(16), nullable\\=False),\n)\nmetadata\\_obj.create\\_all(engine)\n\nNow it\u2019s time to insert some datapoints!\n\nIf you want to look into filling into this table by inferring structured datapoints from unstructured data, take a look at the below section. Otherwise, you can choose to directly populate this table:\n\nfrom sqlalchemy import insert\nrows \\= \\[\n    {\"city\\_name\": \"Toronto\", \"population\": 2731571, \"country\": \"Canada\"},\n    {\"city\\_name\": \"Tokyo\", \"population\": 13929286, \"country\": \"Japan\"},\n    {\"city\\_name\": \"Berlin\", \"population\": 600000, \"country\": \"Germany\"},\n\\]\nfor row in rows:\n    stmt \\= insert(city\\_stats\\_table).values(\\*\\*row)\n    with engine.connect() as connection:\n        cursor \\= connection.execute(stmt)\n\nFinally, we can wrap the SQLAlchemy engine with our SQLDatabase wrapper; this allows the db to be used within LlamaIndex:\n\nfrom llama\\_index import SQLDatabase\n\nsql\\_database \\= SQLDatabase(engine, include\\_tables\\=\\[\"city\\_stats\"\\])\n\n## Natural language SQL[\uf0c1](#natural-language-sql \"Permalink to this heading\")\n\nOnce we have constructed our SQL database, we can use the NLSQLTableQueryEngine to construct natural language queries that are synthesized into SQL queries.\n\nNote that we need to specify the tables we want to use with this query engine. If we don\u2019t the query engine will pull all the schema context, which could overflow the context window of the LLM.\n\nfrom llama\\_index.indices.struct\\_store import NLSQLTableQueryEngine\n\nquery\\_engine \\= NLSQLTableQueryEngine(\n    sql\\_database\\=sql\\_database,\n    tables\\=\\[\"city\\_stats\"\\],\n)\nquery\\_str \\= (\n    \"Which city has the highest population?\"\n)\nresponse \\= query\\_engine.query(query\\_str)\n\nThis query engine should used in any case where you can specify the tables you want to query over beforehand, or the total size of all the table schema plus the rest of the prompt fits your context window.\n\n## Building our Table Index[\uf0c1](#building-our-table-index \"Permalink to this heading\")\n\nIf we don\u2019t know ahead of time which table we would like to use, and the total size of the table schema overflows your context window size, we should store the table schema in an index so that during query time we can retrieve the right schema.\n\nThe way we can do this is using the SQLTableNodeMapping object, which takes in a SQLDatabase and produces a Node object for each SQLTableSchema object passed into the ObjectIndex constructor.\n\nfrom llama\\_index.objects import SQLTableNodeMapping, ObjectIndex, SQLTableSchema\n\ntable\\_node\\_mapping \\= SQLTableNodeMapping(sql\\_database)\ntable\\_schema\\_objs \\= \\[(SQLTableSchema(table\\_name\\=\"city\\_stats\")), ...\\] \\# one SQLTableSchema for each table\n\nobj\\_index \\= ObjectIndex.from\\_objects(\n    table\\_schema\\_objs,\n    table\\_node\\_mapping,\n    VectorStoreIndex,\n)\n\nHere you can see we define our table\\_node\\_mapping, and a single SQLTableSchema with the \u201ccity\\_stats\u201d table name. We pass these into the ObjectIndex constructor, along with the VectorStoreIndex class definition we want to use. This will give us a VectorStoreIndex where each Node contains table schema and other context information. You can also add any additional context information you\u2019d like.\n\n\\# manually set extra context text\ncity\\_stats\\_text \\= (\n    \"This table gives information regarding the population and country of a given city.\\\\n\"\n    \"The user will query with codewords, where 'foo' corresponds to population and 'bar'\"\n    \"corresponds to city.\"\n)\n\ntable\\_node\\_mapping \\= SQLTableNodeMapping(sql\\_database)\ntable\\_schema\\_objs \\= \\[(SQLTableSchema(table\\_name\\=\"city\\_stats\", context\\_str\\=city\\_stats\\_text))\\]\n\n## Using natural language SQL queries[\uf0c1](#using-natural-language-sql-queries \"Permalink to this heading\")\n\nOnce we have defined our table schema index obj\\_index, we can construct a SQLTableRetrieverQueryEngine by passing in our SQLDatabase, and a retriever constructed from our object index.\n\nfrom llama\\_index.indices.struct\\_store import SQLTableRetrieverQueryEngine\n\nquery\\_engine \\= SQLTableRetrieverQueryEngine(\n    sql\\_database, obj\\_index.as\\_retriever(similarity\\_top\\_k\\=1)\n)\nresponse \\= query\\_engine.query(\"Which city has the highest population?\")\nprint(response)\n\nNow when we query the retriever query engine, it will retrieve the relevant table schema and synthesize a SQL query and a response from the results of that query.\n\n## Concluding Thoughts[\uf0c1](#concluding-thoughts \"Permalink to this heading\")\n\nThis is it for now! We\u2019re constantly looking for ways to improve our structured data support. If you have any questions let us know in [our Discord](https://discord.gg/dGcwcsnxhU)."
}