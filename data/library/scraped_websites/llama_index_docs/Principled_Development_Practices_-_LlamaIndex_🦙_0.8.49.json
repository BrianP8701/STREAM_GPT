{
    "metadata": {
        "type": "web",
        "url": "https://docs.llamaindex.ai/en/stable/end_to_end_tutorials/principled_dev_practices.html",
        "title": "Principled Development Practices - LlamaIndex \ud83e\udd99 0.8.49",
        "description": null
    },
    "text": "[Back to top](#)\n\nToggle table of contents sidebar\n\n## Principled Development Practices[\uf0c1](#principled-development-practices \"Permalink to this heading\")\n\nIn order to develop your application, it can help to implement some principled development practices.\n\nHere we provide some general guidance to help you better anticipate the challenges and concerns you may encounter as you develop your LLM application.\n\n*   [The Development Pathway](https://docs.llamaindex.ai/en/stable/end_to_end_tutorials/dev_practices/development_pathway.html)\n\nWe\u2019ve also accumulated some techniques for creating more performant RAG applications.\n\n*   [Building Performant RAG Applications for Production](https://docs.llamaindex.ai/en/stable/end_to_end_tutorials/dev_practices/production_rag.html)\n\nWith that said, we want to establish some general pillars of principled development for LLM and RAG applications.\n\n*   The first pillar is **observability**: setting up initial tools to observe, debug your system and evaluate it on ad-hoc examples.\n    \n*   The next pillar is **evaluation**: being able to evaluate different components of your system so that you can experiment and improve it in a more systematic fashion.\n    \n*   The last pillar is **monitoring**: after the application is deployed, we want to continuously monitor and test that it is performing well in production.\n    \n\n*   [Observability](https://docs.llamaindex.ai/en/stable/end_to_end_tutorials/dev_practices/observability.html)\n*   [Evaluation](https://docs.llamaindex.ai/en/stable/end_to_end_tutorials/dev_practices/evaluation.html)\n*   [Monitoring](https://docs.llamaindex.ai/en/stable/end_to_end_tutorials/dev_practices/monitoring.html)\n\n## Contribute Your Insights![\uf0c1](#contribute-your-insights \"Permalink to this heading\")\n\nIf you have thoughts on sections to add or how to improve, please make a contribution ([link](https://github.com/jerryjliu/llama_index/blob/main/CONTRIBUTING.md))"
}