{
    "metadata": {
        "type": "repo",
        "path": "src/variables/global_vars.py"
    },
    "text": "# global_vars.py\nimport threading\nimport queue\nfrom src.YOLOv8.inference import Inference\nimport src.MobileNetv3.inference as Mobilenet\nimport src.variables.constants as c\nimport onnxruntime as ort\n\nvideo_start_event = threading.Event() # Used to signal when video stream starts\nvideo_queue = queue.Queue() # Used by tracking thread to save or display video\n\ntracking = False # True if tracking, False if initializing\ntracking_done = False # True if tracking is done, False if tracking is not done\nacceleration = c.ACCELERATION # Acceleration of the printer in mm/s^2\nratio = 0 # Ratio of pixels to mm\nglobal_signal_index = 0 # Current signal index from signal stream\nglobal_frame_index = 0 # Currect frame index from video stream\ncurrent_y = 0 # Current screen y position. If YOLO prediction deviates from this too much, it signals an error\nstart_time = 0 # Time when video starts\n\n# Model Weights\nyolo_model = Inference(c.YOLO_PATH)\nort_session = ort.InferenceSession(c.MOBILE_PATH)\n\nyolo_history = [] # [frame, [x1, y1, x2, y2]]\n\nsignals = [] # [[signal_index, time, [x, y, z]]...\n\n# During initialization video stream adds to this buffer\ninitialization_video_buffer = [] # [[frame_index, img]... ]\n# During initialization, signal stream adds corresponding frames from initialization_video_buffer to this buffer and clears initialization_video_buffer\ninitialization_frame_signal_buffer = [] # [[frame_index, signal_index, img]... ]      \n# Video stream adds to this buffer for YOLO inference during tracking\nyolo_video_buffer = [] # [[frame_index, img]... ]\n\nscreen_predictions = [] # Contains the screen predictions per frame as: [[x, y], ...]\n\nbed_predictions = [] # Contains the bed predictions per frame from the gcode file as: [[x, y, z], ...]\nangles = [] # Contains the angles per frame, matching the bed predictions as: [angle, ...]\ncorner_indices = [] # Indices of corners in bed predictions\n\n# [[frame, offset], ...]\nx_spatial_offsets = []\ny_spatial_offsets = []\n\n# Used by data collection thread to receive data from tracking thread\ndata_queue = queue.Queue() # [img, img_with_gmms, extrusion_class, frame_index]\n\n# Metric measurement queues\nmeasure_speed_queue = queue.Queue() # [frame_index] Contains frame indices of MobileNet inference\nmeasure_classification_queue = queue.Queue() # [frame_index, extrusion_class] Contains frame indices of MobileNet inference along with the corresponding extrusion class\nmeasure_diameter_queue = queue.Queue()\nort_session = ort.InferenceSession('src/MobileNetv3/mob_l_gmms2_finetune.onnx')"
}