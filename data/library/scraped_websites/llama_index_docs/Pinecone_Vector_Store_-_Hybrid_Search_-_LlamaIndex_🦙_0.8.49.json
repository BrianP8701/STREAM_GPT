{
    "metadata": {
        "type": "web",
        "url": "https://docs.llamaindex.ai/en/stable/examples/vector_stores/PineconeIndexDemo-Hybrid.html",
        "title": "Pinecone Vector Store - Hybrid Search - LlamaIndex \ud83e\udd99 0.8.49",
        "description": null
    },
    "text": "[Back to top](#)\n\nToggle table of contents sidebar\n\n## Creating a Pinecone Index[\uf0c1](#creating-a-pinecone-index \"Permalink to this heading\")\n\nimport logging\nimport sys\n\nlogging.basicConfig(stream\\=sys.stdout, level\\=logging.INFO)\nlogging.getLogger().addHandler(logging.StreamHandler(stream\\=sys.stdout))\n\napi\\_key \\= \"\"\npinecone.init(api\\_key\\=api\\_key, environment\\=\"us-west1-gcp\")\n\npinecone.describe\\_index(\"quickstart\")\n\n\\# dimensions are for text-embedding-ada-002\n\\# NOTE: needs dotproduct for hybrid search\npinecone.create\\_index(\n    \"quickstart\", dimension\\=1536, metric\\=\"dotproduct\", pod\\_type\\=\"p1\"\n)\n\npinecone\\_index \\= pinecone.Index(\"quickstart\")\n\n## Load documents, build the PineconeVectorStore[\uf0c1](#load-documents-build-the-pineconevectorstore \"Permalink to this heading\")\n\nfrom llama\\_index import VectorStoreIndex, SimpleDirectoryReader\nfrom llama\\_index.vector\\_stores import PineconeVectorStore\nfrom IPython.display import Markdown, display\n\n\\# load documents\ndocuments \\= SimpleDirectoryReader(\"../paul\\_graham\\_essay/data\").load\\_data()\n\n\\# set add\\_sparse\\_vector=True to compute sparse vectors during upsert\nfrom llama\\_index.storage.storage\\_context import StorageContext\n\nvector\\_store \\= PineconeVectorStore(\n    pinecone\\_index\\=pinecone\\_index,\n    add\\_sparse\\_vector\\=True,\n)\nstorage\\_context \\= StorageContext.from\\_defaults(vector\\_store\\=vector\\_store)\nindex \\= VectorStoreIndex.from\\_documents(\n    documents, storage\\_context\\=storage\\_context\n)\n\n## Query Index[\uf0c1](#query-index \"Permalink to this heading\")\n\n\\# set Logging to DEBUG for more detailed outputs\nquery\\_engine \\= index.as\\_query\\_engine(vector\\_store\\_query\\_mode\\=\"hybrid\")\nresponse \\= query\\_engine.query(\"What did the author do growing up?\")\n\ndisplay(Markdown(f\"<b>{response}</b>\"))"
}