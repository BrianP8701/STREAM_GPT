{
    "metadata": {
        "type": "web",
        "url": "https://docs.llamaindex.ai/en/stable/examples/index_structs/knowledge_graph/KuzuGraphDemo.html",
        "title": "K\u00f9zu Graph Store - LlamaIndex \ud83e\udd99 0.8.49",
        "description": null
    },
    "text": "[Back to top](#)\n\nToggle table of contents sidebar\n\n## K\u00f9zu Graph Store[\uf0c1](#kuzu-graph-store \"Permalink to this heading\")\n\nThis notebook walks through configuring `K\u00f9zu` to be the backend for graph storage in LlamaIndex.\n\n\\# My OpenAI Key\nimport os\n\nos.environ\\[\"OPENAI\\_API\\_KEY\"\\] \\= \"API\\_KEY\\_HERE\"\n\nimport logging\nimport sys\n\nlogging.basicConfig(stream\\=sys.stdout, level\\=logging.INFO)\n\n## Prepare for K\u00f9zu[\uf0c1](#prepare-for-kuzu \"Permalink to this heading\")\n\n\\# Clean up all the directories used in this notebook\nimport shutil\n\nshutil.rmtree(\"./test1\", ignore\\_errors\\=True)\nshutil.rmtree(\"./test2\", ignore\\_errors\\=True)\nshutil.rmtree(\"./test3\", ignore\\_errors\\=True)\n\n%pip install kuzu\nimport kuzu\n\ndb \\= kuzu.Database(\"test1\")\n\nCollecting kuzu\n  Downloading kuzu-0.0.6-cp39-cp39-macosx\\_11\\_0\\_arm64.whl (5.5 MB)\n     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 5.5 MB 4.8 MB/s eta 0:00:01\n?25hInstalling collected packages: kuzu\nSuccessfully installed kuzu-0.0.6\nWARNING: You are using pip version 21.2.4; however, version 23.2.1 is available.\nYou should consider upgrading via the '/Users/loganmarkewich/llama\\_index/llama-index/bin/python -m pip install --upgrade pip' command.\nNote: you may need to restart the kernel to use updated packages.\n\n## Using Knowledge Graph with KuzuGraphStore[\uf0c1](#using-knowledge-graph-with-kuzugraphstore \"Permalink to this heading\")\n\nfrom llama\\_index.graph\\_stores import KuzuGraphStore\n\ngraph\\_store \\= KuzuGraphStore(db)\n\nINFO:numexpr.utils:Note: NumExpr detected 12 cores but \"NUMEXPR\\_MAX\\_THREADS\" not set, so enforcing safe limit of 8.\nINFO:numexpr.utils:NumExpr defaulting to 8 threads.\n\n### Building the Knowledge Graph[\uf0c1](#building-the-knowledge-graph \"Permalink to this heading\")\n\nfrom llama\\_index import (\n    SimpleDirectoryReader,\n    ServiceContext,\n    KnowledgeGraphIndex,\n)\n\nfrom llama\\_index.llms import OpenAI\nfrom IPython.display import Markdown, display\nimport kuzu\n\ndocuments \\= SimpleDirectoryReader(\n    \"../../../../examples/paul\\_graham\\_essay/data\"\n).load\\_data()\n\n\\# define LLM\n\nllm \\= OpenAI(temperature\\=0, model\\=\"gpt-3.5-turbo\")\nservice\\_context \\= ServiceContext.from\\_defaults(llm\\=llm, chunk\\_size\\=512)\n\nfrom llama\\_index.storage.storage\\_context import StorageContext\n\nstorage\\_context \\= StorageContext.from\\_defaults(graph\\_store\\=graph\\_store)\n\n\\# NOTE: can take a while!\nindex \\= KnowledgeGraphIndex.from\\_documents(\n    documents,\n    max\\_triplets\\_per\\_chunk\\=2,\n    storage\\_context\\=storage\\_context,\n    service\\_context\\=service\\_context,\n)\n\n### Querying the Knowledge Graph[\uf0c1](#querying-the-knowledge-graph \"Permalink to this heading\")\n\nFirst, we can query and send only the triplets to the LLM.\n\nquery\\_engine \\= index.as\\_query\\_engine(\n    include\\_text\\=False, response\\_mode\\=\"tree\\_summarize\"\n)\nresponse \\= query\\_engine.query(\n    \"Tell me more about Interleaf\",\n)\n\nINFO:llama\\_index.indices.knowledge\\_graph.retriever:> Starting query: Tell me more about Interleaf\n\nINFO:llama\\_index.indices.knowledge\\_graph.retriever:> Query keywords: \\['Interleaf'\\]\nERROR:llama\\_index.indices.knowledge\\_graph.retriever:Index was not constructed with embeddings, skipping embedding usage...\nINFO:llama\\_index.indices.knowledge\\_graph.retriever:> Extracted relationships: The following are knowledge sequence in max depth 2 in the form of \\`subject \\[predicate, object, predicate\\_next\\_hop, object\\_next\\_hop ...\\]\\`\nInterleaf \\['made', 'software for creating documents'\\]\nInterleaf \\['added', 'scripting language'\\]\nInterleaf \\['taught', 'what not to do'\\]\n\ndisplay(Markdown(f\"<b>{response}</b>\"))\n\n**Interleaf is a company that made software for creating documents. They also added a scripting language to their software. Additionally, they taught what not to do.**\n\nFor more detailed answers, we can also send the text from where the retrieved tripets were extracted.\n\nquery\\_engine \\= index.as\\_query\\_engine(\n    include\\_text\\=True, response\\_mode\\=\"tree\\_summarize\"\n)\nresponse \\= query\\_engine.query(\n    \"Tell me more about Interleaf\",\n)\n\nINFO:llama\\_index.indices.knowledge\\_graph.retriever:> Starting query: Tell me more about Interleaf\nINFO:llama\\_index.indices.knowledge\\_graph.retriever:> Query keywords: \\['Interleaf'\\]\nERROR:llama\\_index.indices.knowledge\\_graph.retriever:Index was not constructed with embeddings, skipping embedding usage...\nINFO:llama\\_index.indices.knowledge\\_graph.retriever:> Querying with idx: 144f784c-d052-4fed-86f8-c895da6e13df: each student had. But the Accademia wasn't teaching me anything except Italia...\nINFO:llama\\_index.indices.knowledge\\_graph.retriever:> Querying with idx: 7c877dd3-3375-4ab7-8745-e0dfbabfe5bd: learned some useful things at Interleaf, though they were mostly about what n...\nINFO:llama\\_index.indices.knowledge\\_graph.retriever:> Extracted relationships: The following are knowledge sequence in max depth 2 in the form of \\`subject \\[predicate, object, predicate\\_next\\_hop, object\\_next\\_hop ...\\]\\`\nInterleaf \\['made', 'software for creating documents'\\]\nInterleaf \\['added', 'scripting language'\\]\nInterleaf \\['taught', 'what not to do'\\]\n\ndisplay(Markdown(f\"<b>{response}</b>\"))\n\n**Interleaf was a company that made software for creating documents. They were inspired by Emacs and added a scripting language to their software, which was a dialect of Lisp. The company hired a Lisp hacker to write things in this scripting language. The narrator worked at Interleaf for a year but admits to being a bad employee. They found it difficult to understand most of the software because it was primarily written in C, a language they did not know or want to learn. Despite this, they were paid well and managed to save enough money to go back to RISD and pay off their college loans. The narrator also learned some valuable lessons at Interleaf, such as the importance of having product people rather than sales people running technology companies, the drawbacks of having too many people edit code, the impact of office space on productivity, the value of corridor conversations over planned meetings, the challenges of dealing with big bureaucratic customers, and the importance of being the \u201centry level\u201d option in a market.**\n\n### Query with embeddings[\uf0c1](#query-with-embeddings \"Permalink to this heading\")\n\n\\# NOTE: can take a while!\ndb \\= kuzu.Database(\"test2\")\ngraph\\_store \\= KuzuGraphStore(db)\nstorage\\_context \\= StorageContext.from\\_defaults(graph\\_store\\=graph\\_store)\nnew\\_index \\= KnowledgeGraphIndex.from\\_documents(\n    documents,\n    max\\_triplets\\_per\\_chunk\\=2,\n    service\\_context\\=service\\_context,\n    storage\\_context\\=storage\\_context,\n    include\\_embeddings\\=True,\n)\n\nWARNING:llama\\_index.llms.openai\\_utils:Retrying llama\\_index.llms.openai\\_utils.completion\\_with\\_retry.<locals>.\\_completion\\_with\\_retry in 4.0 seconds as it raised ServiceUnavailableError: The server is overloaded or not ready yet..\n\nrel\\_map \\= graph\\_store.get\\_rel\\_map()\n\n\\# query using top 3 triplets plus keywords (duplicate triplets are removed)\nquery\\_engine \\= index.as\\_query\\_engine(\n    include\\_text\\=True,\n    response\\_mode\\=\"tree\\_summarize\",\n    embedding\\_mode\\=\"hybrid\",\n    similarity\\_top\\_k\\=5,\n)\nresponse \\= query\\_engine.query(\n    \"Tell me more about what the author worked on at Interleaf\",\n)\n\nINFO:llama\\_index.indices.knowledge\\_graph.retriever:> Starting query: Tell me more about what the author worked on at Interleaf\nINFO:llama\\_index.indices.knowledge\\_graph.retriever:> Query keywords: \\['Interleaf', 'author', 'worked'\\]\nERROR:llama\\_index.indices.knowledge\\_graph.retriever:Index was not constructed with embeddings, skipping embedding usage...\nINFO:llama\\_index.indices.knowledge\\_graph.retriever:> Querying with idx: 144f784c-d052-4fed-86f8-c895da6e13df: each student had. But the Accademia wasn't teaching me anything except Italia...\nINFO:llama\\_index.indices.knowledge\\_graph.retriever:> Querying with idx: 7c877dd3-3375-4ab7-8745-e0dfbabfe5bd: learned some useful things at Interleaf, though they were mostly about what n...\nINFO:llama\\_index.indices.knowledge\\_graph.retriever:> Extracted relationships: The following are knowledge sequence in max depth 2 in the form of \\`subject \\[predicate, object, predicate\\_next\\_hop, object\\_next\\_hop ...\\]\\`\nInterleaf \\['made', 'software for creating documents'\\]\nInterleaf \\['added', 'scripting language'\\]\nInterleaf \\['taught', 'what not to do'\\]\n\ndisplay(Markdown(f\"<b>{response}</b>\"))\n\n**At Interleaf, the author worked on creating software for creating documents. They also worked on adding a scripting language, which was inspired by Emacs and was a dialect of Lisp. However, the author admits to being a bad employee and not fully understanding the software, as it was primarily written in C. They also mention that they spent a lot of time working on their book \u201cOn Lisp\u201d during their time at Interleaf. Overall, the author learned some useful things at Interleaf, particularly about what not to do in technology companies.**\n\n### Visualizing the Graph[\uf0c1](#visualizing-the-graph \"Permalink to this heading\")\n\nCollecting pyvis\n  Downloading pyvis-0.3.2-py3-none-any.whl (756 kB)\n     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 756 kB 2.0 MB/s eta 0:00:01\n?25hCollecting jsonpickle>=1.4.1\n  Downloading jsonpickle-3.0.1-py2.py3-none-any.whl (40 kB)\n     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 40 kB 4.1 MB/s eta 0:00:01\n?25hRequirement already satisfied: networkx>=1.11 in /Users/loganmarkewich/llama\\_index/llama-index/lib/python3.9/site-packages (from pyvis) (3.1)\nRequirement already satisfied: ipython>=5.3.0 in /Users/loganmarkewich/llama\\_index/llama-index/lib/python3.9/site-packages (from pyvis) (8.10.0)\nRequirement already satisfied: jinja2>=2.9.6 in /Users/loganmarkewich/llama\\_index/llama-index/lib/python3.9/site-packages (from pyvis) (3.1.2)\nRequirement already satisfied: pexpect>4.3 in /Users/loganmarkewich/llama\\_index/llama-index/lib/python3.9/site-packages (from ipython>=5.3.0->pyvis) (4.8.0)\nRequirement already satisfied: backcall in /Users/loganmarkewich/llama\\_index/llama-index/lib/python3.9/site-packages (from ipython>=5.3.0->pyvis) (0.2.0)\nRequirement already satisfied: decorator in /Users/loganmarkewich/llama\\_index/llama-index/lib/python3.9/site-packages (from ipython>=5.3.0->pyvis) (5.1.1)\nRequirement already satisfied: pickleshare in /Users/loganmarkewich/llama\\_index/llama-index/lib/python3.9/site-packages (from ipython>=5.3.0->pyvis) (0.7.5)\nRequirement already satisfied: prompt-toolkit<3.1.0,>=3.0.30 in /Users/loganmarkewich/llama\\_index/llama-index/lib/python3.9/site-packages (from ipython>=5.3.0->pyvis) (3.0.39)\nRequirement already satisfied: appnope in /Users/loganmarkewich/llama\\_index/llama-index/lib/python3.9/site-packages (from ipython>=5.3.0->pyvis) (0.1.3)\nRequirement already satisfied: pygments>=2.4.0 in /Users/loganmarkewich/llama\\_index/llama-index/lib/python3.9/site-packages (from ipython>=5.3.0->pyvis) (2.15.1)\nRequirement already satisfied: traitlets>=5 in /Users/loganmarkewich/llama\\_index/llama-index/lib/python3.9/site-packages (from ipython>=5.3.0->pyvis) (5.9.0)\nRequirement already satisfied: jedi>=0.16 in /Users/loganmarkewich/llama\\_index/llama-index/lib/python3.9/site-packages (from ipython>=5.3.0->pyvis) (0.18.2)\nRequirement already satisfied: matplotlib-inline in /Users/loganmarkewich/llama\\_index/llama-index/lib/python3.9/site-packages (from ipython>=5.3.0->pyvis) (0.1.6)\nRequirement already satisfied: stack-data in /Users/loganmarkewich/llama\\_index/llama-index/lib/python3.9/site-packages (from ipython>=5.3.0->pyvis) (0.6.2)\nRequirement already satisfied: parso<0.9.0,>=0.8.0 in /Users/loganmarkewich/llama\\_index/llama-index/lib/python3.9/site-packages (from jedi>=0.16->ipython>=5.3.0->pyvis) (0.8.3)\nRequirement already satisfied: MarkupSafe>=2.0 in /Users/loganmarkewich/llama\\_index/llama-index/lib/python3.9/site-packages (from jinja2>=2.9.6->pyvis) (2.1.3)\nRequirement already satisfied: ptyprocess>=0.5 in /Users/loganmarkewich/llama\\_index/llama-index/lib/python3.9/site-packages (from pexpect>4.3->ipython>=5.3.0->pyvis) (0.7.0)\nRequirement already satisfied: wcwidth in /Users/loganmarkewich/llama\\_index/llama-index/lib/python3.9/site-packages (from prompt-toolkit<3.1.0,>=3.0.30->ipython>=5.3.0->pyvis) (0.2.6)\nRequirement already satisfied: executing>=1.2.0 in /Users/loganmarkewich/llama\\_index/llama-index/lib/python3.9/site-packages (from stack-data->ipython>=5.3.0->pyvis) (1.2.0)\nRequirement already satisfied: asttokens>=2.1.0 in /Users/loganmarkewich/llama\\_index/llama-index/lib/python3.9/site-packages (from stack-data->ipython>=5.3.0->pyvis) (2.2.1)\nRequirement already satisfied: pure-eval in /Users/loganmarkewich/llama\\_index/llama-index/lib/python3.9/site-packages (from stack-data->ipython>=5.3.0->pyvis) (0.2.2)\nRequirement already satisfied: six in /Users/loganmarkewich/llama\\_index/llama-index/lib/python3.9/site-packages (from asttokens>=2.1.0->stack-data->ipython>=5.3.0->pyvis) (1.16.0)\nInstalling collected packages: jsonpickle, pyvis\nSuccessfully installed jsonpickle-3.0.1 pyvis-0.3.2\nWARNING: You are using pip version 21.2.4; however, version 23.2.1 is available.\nYou should consider upgrading via the '/Users/loganmarkewich/llama\\_index/llama-index/bin/python -m pip install --upgrade pip' command.\nNote: you may need to restart the kernel to use updated packages.\n\n\\## create graph\nfrom pyvis.network import Network\n\ng \\= index.get\\_networkx\\_graph()\nnet \\= Network(notebook\\=True, cdn\\_resources\\=\"in\\_line\", directed\\=True)\nnet.from\\_nx(g)\nnet.show(\"kuzugraph\\_draw.html\")\n\n### \\[Optional\\] Try building the graph and manually add triplets![\uf0c1](#optional-try-building-the-graph-and-manually-add-triplets \"Permalink to this heading\")\n\nfrom llama\\_index.node\\_parser import SimpleNodeParser\n\nnode\\_parser \\= SimpleNodeParser.from\\_defaults()\n\nnodes \\= node\\_parser.get\\_nodes\\_from\\_documents(documents)\n\n\\# initialize an empty database\ndb \\= kuzu.Database(\"test3\")\ngraph\\_store \\= KuzuGraphStore(db)\nstorage\\_context \\= StorageContext.from\\_defaults(graph\\_store\\=graph\\_store)\nindex \\= KnowledgeGraphIndex(\n    \\[\\],\n    service\\_context\\=service\\_context,\n    storage\\_context\\=storage\\_context,\n)\n\n\\# add keyword mappings and nodes manually\n\\# add triplets (subject, relationship, object)\n\n\\# for node 0\nnode\\_0\\_tups \\= \\[\n    (\"author\", \"worked on\", \"writing\"),\n    (\"author\", \"worked on\", \"programming\"),\n\\]\nfor tup in node\\_0\\_tups:\n    index.upsert\\_triplet\\_and\\_node(tup, nodes\\[0\\])\n\n\\# for node 1\nnode\\_1\\_tups \\= \\[\n    (\"Interleaf\", \"made software for\", \"creating documents\"),\n    (\"Interleaf\", \"added\", \"scripting language\"),\n    (\"software\", \"generate\", \"web sites\"),\n\\]\nfor tup in node\\_1\\_tups:\n    index.upsert\\_triplet\\_and\\_node(tup, nodes\\[1\\])\n\nquery\\_engine \\= index.as\\_query\\_engine(\n    include\\_text\\=False, response\\_mode\\=\"tree\\_summarize\"\n)\nresponse \\= query\\_engine.query(\n    \"Tell me more about Interleaf\",\n)\n\nINFO:llama\\_index.indices.knowledge\\_graph.retriever:> Starting query: Tell me more about Interleaf\nINFO:llama\\_index.indices.knowledge\\_graph.retriever:> Query keywords: \\['Interleaf'\\]\nERROR:llama\\_index.indices.knowledge\\_graph.retriever:Index was not constructed with embeddings, skipping embedding usage...\nINFO:llama\\_index.indices.knowledge\\_graph.retriever:> Extracted relationships: The following are knowledge sequence in max depth 2 in the form of \\`subject \\[predicate, object, predicate\\_next\\_hop, object\\_next\\_hop ...\\]\\`\nInterleaf \\['made software for', 'creating documents'\\]\nInterleaf \\['added', 'scripting language'\\]\n\n'Interleaf is a software company that specializes in creating documents. They have also added a scripting language to their software.'"
}