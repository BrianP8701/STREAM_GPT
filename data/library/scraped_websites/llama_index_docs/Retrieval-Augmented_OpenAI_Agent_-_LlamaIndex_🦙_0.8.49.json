{
    "metadata": {
        "type": "web",
        "url": "https://docs.llamaindex.ai/en/stable/examples/agent/openai_agent_retrieval.html",
        "title": "Retrieval-Augmented OpenAI Agent - LlamaIndex \ud83e\udd99 0.8.49",
        "description": null
    },
    "text": "[Back to top](#)\n\nToggle table of contents sidebar\n\n## Retrieval-Augmented OpenAI Agent[\uf0c1](#retrieval-augmented-openai-agent \"Permalink to this heading\")\n\nIn this tutorial, we show you how to use our `FnRetrieverOpenAI` implementation to build an agent on top of OpenAI\u2019s function API and store/index an arbitrary number of tools. Our indexing/retrieval modules help to remove the complexity of having too many functions to fit in the prompt.\n\n## Initial Setup[\uf0c1](#initial-setup \"Permalink to this heading\")\n\nLet\u2019s start by importing some simple building blocks.\n\nThe main thing we need is:\n\n1.  the OpenAI API\n    \n2.  a place to keep conversation history\n    \n3.  a definition for tools that our agent can use.\n    \n\nimport json\nfrom typing import Sequence\n\nfrom llama\\_index.tools import BaseTool, FunctionTool\n\n/Users/suo/miniconda3/envs/llama/lib/python3.9/site-packages/deeplake/util/check\\_latest\\_version.py:32: UserWarning: A newer version of deeplake (3.6.7) is available. It's recommended that you update to the latest version using \\`pip install -U deeplake\\`.\n  warnings.warn(\n\nLet\u2019s define some very simple calculator tools for our agent.\n\ndef multiply(a: int, b: int) \\-> int:\n    \"\"\"Multiply two integers and returns the result integer\"\"\"\n    return a \\* b\n\ndef add(a: int, b: int) \\-> int:\n    \"\"\"Add two integers and returns the result integer\"\"\"\n    return a + b\n\ndef useless(a: int, b: int) \\-> int:\n    \"\"\"Toy useless function.\"\"\"\n    pass\n\nmultiply\\_tool \\= FunctionTool.from\\_defaults(fn\\=multiply, name\\=\"multiply\")\nuseless\\_tools \\= \\[\n    FunctionTool.from\\_defaults(fn\\=useless, name\\=f\"useless\\_{str(idx)}\")\n    for idx in range(28)\n\\]\nadd\\_tool \\= FunctionTool.from\\_defaults(fn\\=add, name\\=\"add\")\n\nall\\_tools \\= \\[multiply\\_tool\\] + \\[add\\_tool\\] + useless\\_tools\nall\\_tools\\_map \\= {t.metadata.name: t for t in all\\_tools}\n\n## Building an Object Index[\uf0c1](#building-an-object-index \"Permalink to this heading\")\n\nWe have an `ObjectIndex` construct in LlamaIndex that allows the user to use our index data structures over arbitrary objects. The ObjectIndex will handle serialiation to/from the object, and use an underying index (e.g. VectorStoreIndex, SummaryIndex, KeywordTableIndex) as the storage mechanism.\n\nIn this case, we have a large collection of Tool objects, and we\u2019d want to define an ObjectIndex over these Tools.\n\nThe index comes bundled with a retrieval mechanism, an `ObjectRetriever`.\n\nThis can be passed in to our agent so that it can perform Tool retrieval during query-time.\n\n\\# define an \"object\" index over these tools\nfrom llama\\_index import VectorStoreIndex\nfrom llama\\_index.objects import ObjectIndex, SimpleToolNodeMapping\n\ntool\\_mapping \\= SimpleToolNodeMapping.from\\_objects(all\\_tools)\nobj\\_index \\= ObjectIndex.from\\_objects(\n    all\\_tools,\n    tool\\_mapping,\n    VectorStoreIndex,\n)\n\n## Our `FnRetrieverOpenAIAgent` Implementation[\uf0c1](#our-fnretrieveropenaiagent-implementation \"Permalink to this heading\")\n\nWe provide a `FnRetrieverOpenAIAgent` implementation in LlamaIndex, which can take in an `ObjectRetriever` over a set of `BaseTool` objects.\n\nDuring query-time, we would first use the `ObjectRetriever` to retrieve a set of relevant Tools. These tools would then be passed into the agent; more specifically, their function signatures would be passed into the OpenAI Function calling API.\n\nfrom llama\\_index.agent import FnRetrieverOpenAIAgent\n\nagent \\= FnRetrieverOpenAIAgent.from\\_retriever(\n    obj\\_index.as\\_retriever(), verbose\\=True\n)\n\nagent.chat(\"What's 212 multiplied by 122? Make sure to use Tools\")\n\n\\=== Calling Function ===\nCalling function: multiply with args: {\n  \"a\": 212,\n  \"b\": 122\n}\nGot output: 25864\n========================\n\nResponse(response='212 multiplied by 122 is 25,864.', source\\_nodes=\\[\\], metadata=None)\n\nagent.chat(\"What's 212 added to 122 ? Make sure to use Tools\")\n\n\\=== Calling Function ===\nCalling function: add with args: {\n  \"a\": 212,\n  \"b\": 122\n}\nGot output: 334\n========================\n\nResponse(response='212 added to 122 is 334.', source\\_nodes=\\[\\], metadata=None)"
}