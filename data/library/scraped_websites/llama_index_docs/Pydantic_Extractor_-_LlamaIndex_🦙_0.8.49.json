{
    "metadata": {
        "type": "web",
        "url": "https://docs.llamaindex.ai/en/stable/examples/metadata_extraction/PydanticExtractor.html",
        "title": "Pydantic Extractor - LlamaIndex \ud83e\udd99 0.8.49",
        "description": null
    },
    "text": "[Back to top](#)\n\nToggle table of contents sidebar\n\n## Pydantic Extractor[\uf0c1](#pydantic-extractor \"Permalink to this heading\")\n\nHere we test out the capabilities of our `PydanticProgramExtractor` - being able to extract out an entire Pydantic object using an LLM (either a standard text completion LLM or a function calling LLM).\n\nThe advantage of this over using a \u201csingle\u201d metadata extractor is that we can extract multiple entities with a single LLM call.\n\n## Setup[\uf0c1](#setup \"Permalink to this heading\")\n\nimport nest\\_asyncio\n\nnest\\_asyncio.apply()\n\nimport os\nimport openai\n\nos.environ\\[\"OPENAI\\_API\\_KEY\"\\] \\= \"YOUR\\_API\\_KEY\"\nopenai.api\\_key \\= os.getenv(\"OPENAI\\_API\\_KEY\")\n\n### Setup the Pydantic Model[\uf0c1](#setup-the-pydantic-model \"Permalink to this heading\")\n\nHere we define a basic structured schema that we want to extract. It contains:\n\n*   entities: unique entities in a text chunk\n    \n*   summary: a concise summary of the text chunk\n    \n*   contains\\_number: whether the chunk contains numbers\n    \n\nThis is obviously a toy schema. We\u2019d encourage you to be creative about the type of metadata you\u2019d want to extract!\n\nfrom pydantic import BaseModel, Field\nfrom typing import List\n\nclass NodeMetadata(BaseModel):\n    \"\"\"Node metadata.\"\"\"\n\n    entities: List\\[str\\] \\= Field(\n        ..., description\\=\"Unique entities in this text chunk.\"\n    )\n    summary: str \\= Field(\n        ..., description\\=\"A concise summary of this text chunk.\"\n    )\n    contains\\_number: bool \\= Field(\n        ...,\n        description\\=(\n            \"Whether the text chunk contains any numbers (ints, floats, etc.)\"\n        ),\n    )\n\n### Setup the Extractor[\uf0c1](#setup-the-extractor \"Permalink to this heading\")\n\nHere we setup the metadata extractor. Note that we provide the prompt template for visibility into what\u2019s going on.\n\nfrom llama\\_index.program.openai\\_program import OpenAIPydanticProgram\nfrom llama\\_index.node\\_parser.extractors import (\n    PydanticProgramExtractor,\n    MetadataExtractor,\n)\n\nEXTRACT\\_TEMPLATE\\_STR \\= \"\"\"\\\\\nHere is the content of the section:\n\\----------------\n{context\\_str}\n\\----------------\nGiven the contextual information, extract out a {class\\_name} object.\\\\\n\"\"\"\n\nopenai\\_program \\= OpenAIPydanticProgram.from\\_defaults(\n    output\\_cls\\=NodeMetadata,\n    prompt\\_template\\_str\\=\"{input}\",\n    \\# extract\\_template\\_str=EXTRACT\\_TEMPLATE\\_STR\n)\n\nprogram\\_extractor \\= PydanticProgramExtractor(\n    program\\=openai\\_program, input\\_key\\=\"input\", show\\_progress\\=True\n)\n\nmetadata\\_extractor \\= MetadataExtractor(extractors\\=\\[program\\_extractor\\])\n\n### Load in Data[\uf0c1](#load-in-data \"Permalink to this heading\")\n\nWe load in Eugene\u2019s essay (https://eugeneyan.com/writing/llm-patterns/) using our LlamaHub SimpleWebPageReader.\n\n\\# load in blog\n\nfrom llama\\_hub.web.simple\\_web.base import SimpleWebPageReader\nfrom llama\\_index.node\\_parser import SimpleNodeParser\n\nreader \\= SimpleWebPageReader(html\\_to\\_text\\=True)\ndocs \\= reader.load\\_data(urls\\=\\[\"https://eugeneyan.com/writing/llm-patterns/\"\\])\n\nnode\\_parser \\= SimpleNodeParser.from\\_defaults(chunk\\_size\\=1024)\norig\\_nodes \\= node\\_parser.get\\_nodes\\_from\\_documents(docs)"
}