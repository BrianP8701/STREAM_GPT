{
    "metadata": {
        "type": "web",
        "url": "https://docs.llamaindex.ai/en/stable/community/integrations/chatgpt_plugins.html",
        "title": "ChatGPT Plugin Integrations - LlamaIndex \ud83e\udd99 0.8.49",
        "description": null
    },
    "text": "[Back to top](#)\n\nToggle table of contents sidebar\n\n## ChatGPT Plugin Integrations[\uf0c1](#chatgpt-plugin-integrations \"Permalink to this heading\")\n\n**NOTE**: This is a work-in-progress, stay tuned for more exciting updates on this front!\n\n## ChatGPT Retrieval Plugin Integrations[\uf0c1](#chatgpt-retrieval-plugin-integrations \"Permalink to this heading\")\n\nThe [OpenAI ChatGPT Retrieval Plugin](https://github.com/openai/chatgpt-retrieval-plugin) offers a centralized API specification for any document storage system to interact with ChatGPT. Since this can be deployed on any service, this means that more and more document retrieval services will implement this spec; this allows them to not only interact with ChatGPT, but also interact with any LLM toolkit that may use a retrieval service.\n\nLlamaIndex provides a variety of integrations with the ChatGPT Retrieval Plugin.\n\n### Loading Data from LlamaHub into the ChatGPT Retrieval Plugin[\uf0c1](#loading-data-from-llamahub-into-the-chatgpt-retrieval-plugin \"Permalink to this heading\")\n\nThe ChatGPT Retrieval Plugin defines an `/upsert` endpoint for users to load documents. This offers a natural integration point with LlamaHub, which offers over 65 data loaders from various API\u2019s and document formats.\n\nHere is a sample code snippet of showing how to load a document from LlamaHub into the JSON format that `/upsert` expects:\n\nfrom llama\\_index import download\\_loader, Document\nfrom typing import Dict, List\nimport json\n\n\\# download loader, load documents\nSimpleWebPageReader \\= download\\_loader(\"SimpleWebPageReader\")\nloader \\= SimpleWebPageReader(html\\_to\\_text\\=True)\nurl \\= \"http://www.paulgraham.com/worked.html\"\ndocuments \\= loader.load\\_data(urls\\=\\[url\\])\n\n\\# Convert LlamaIndex Documents to JSON format\ndef dump\\_docs\\_to\\_json(documents: List\\[Document\\], out\\_path: str) \\-> Dict:\n    \"\"\"Convert LlamaIndex Documents to JSON format and save it.\"\"\"\n    result\\_json \\= \\[\\]\n    for doc in documents:\n        cur\\_dict \\= {\n            \"text\": doc.get\\_text(),\n            \"id\": doc.get\\_doc\\_id(),\n            \\# NOTE: feel free to customize the other fields as you wish\n            \\# fields taken from https://github.com/openai/chatgpt-retrieval-plugin/tree/main/scripts/process\\_json#usage\n            \\# \"source\": ...,\n            \\# \"source\\_id\": ...,\n            \\# \"url\": url,\n            \\# \"created\\_at\": ...,\n            \\# \"author\": \"Paul Graham\",\n        }\n        result\\_json.append(cur\\_dict)\n\n    json.dump(result\\_json, open(out\\_path, 'w'))\n\nFor more details, check out the [full example notebook](https://github.com/jerryjliu/llama_index/blob/main/examples/chatgpt_plugin/ChatGPT_Retrieval_Plugin_Upload.ipynb).\n\n### ChatGPT Retrieval Plugin Data Loader[\uf0c1](#chatgpt-retrieval-plugin-data-loader \"Permalink to this heading\")\n\nThe ChatGPT Retrieval Plugin data loader [can be accessed on LlamaHub](https://llamahub.ai/l/chatgpt_plugin).\n\nIt allows you to easily load data from any docstore that implements the plugin API, into a LlamaIndex data structure.\n\nExample code:\n\nfrom llama\\_index.readers import ChatGPTRetrievalPluginReader\nimport os\n\n\\# load documents\nbearer\\_token \\= os.getenv(\"BEARER\\_TOKEN\")\nreader \\= ChatGPTRetrievalPluginReader(\n    endpoint\\_url\\=\"http://localhost:8000\",\n    bearer\\_token\\=bearer\\_token\n)\ndocuments \\= reader.load\\_data(\"What did the author do growing up?\")\n\n\\# build and query index\nfrom llama\\_index import SummaryIndex\nindex \\= SummaryIndex.from\\_documents(documents)\n\\# set Logging to DEBUG for more detailed outputs\nquery\\_engine \\= vector\\_index.as\\_query\\_engine(\n    response\\_mode\\=\"compact\"\n)\nresponse \\= query\\_engine.query(\n    \"Summarize the retrieved content and describe what the author did growing up\",\n)\n\nFor more details, check out the [full example notebook](https://github.com/jerryjliu/llama_index/blob/main/examples/chatgpt_plugin/ChatGPTRetrievalPluginReaderDemo.ipynb).\n\n### ChatGPT Retrieval Plugin Index[\uf0c1](#chatgpt-retrieval-plugin-index \"Permalink to this heading\")\n\nThe ChatGPT Retrieval Plugin Index allows you to easily build a vector index over any documents, with storage backed by a document store implementing the ChatGPT endpoint.\n\nNote: this index is a vector index, allowing top-k retrieval.\n\nExample code:\n\nfrom llama\\_index.indices.vector\\_store import ChatGPTRetrievalPluginIndex\nfrom llama\\_index import SimpleDirectoryReader\nimport os\n\n\\# load documents\ndocuments \\= SimpleDirectoryReader('../paul\\_graham\\_essay/data').load\\_data()\n\n\\# build index\nbearer\\_token \\= os.getenv(\"BEARER\\_TOKEN\")\n\\# initialize without metadata filter\nindex \\= ChatGPTRetrievalPluginIndex(\n    documents,\n    endpoint\\_url\\=\"http://localhost:8000\",\n    bearer\\_token\\=bearer\\_token,\n)\n\n\\# query index\nquery\\_engine \\= vector\\_index.as\\_query\\_engine(\n    similarity\\_top\\_k\\=3,\n    response\\_mode\\=\"compact\",\n)\nresponse \\= query\\_engine.query(\"What did the author do growing up?\")\n\nFor more details, check out the [full example notebook](https://github.com/jerryjliu/llama_index/blob/main/examples/chatgpt_plugin/ChatGPTRetrievalPluginIndexDemo.ipynb)."
}