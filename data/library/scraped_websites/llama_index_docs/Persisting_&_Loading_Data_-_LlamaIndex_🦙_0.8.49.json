{
    "metadata": {
        "type": "web",
        "url": "https://docs.llamaindex.ai/en/stable/core_modules/data_modules/storage/save_load.html",
        "title": "Persisting & Loading Data - LlamaIndex \ud83e\udd99 0.8.49",
        "description": null
    },
    "text": "[Back to top](#)\n\nToggle table of contents sidebar\n\n## Persisting & Loading Data[\uf0c1](#persisting-loading-data \"Permalink to this heading\")\n\n## Persisting Data[\uf0c1](#persisting-data \"Permalink to this heading\")\n\nBy default, LlamaIndex stores data in-memory, and this data can be explicitly persisted if desired:\n\nstorage\\_context.persist(persist\\_dir\\=\"<persist\\_dir>\")\n\nThis will persist data to disk, under the specified `persist_dir` (or `./storage` by default).\n\nMultiple indexes can be persisted and loaded from the same directory, assuming you keep track of index ID\u2019s for loading.\n\nUser can also configure alternative storage backends (e.g. `MongoDB`) that persist data by default. In this case, calling `storage_context.persist()` will do nothing.\n\n## Loading Data[\uf0c1](#loading-data \"Permalink to this heading\")\n\nTo load data, user simply needs to re-create the storage context using the same configuration (e.g. pass in the same `persist_dir` or vector store client).\n\nstorage\\_context \\= StorageContext.from\\_defaults(\n    docstore\\=SimpleDocumentStore.from\\_persist\\_dir(persist\\_dir\\=\"<persist\\_dir>\"),\n    vector\\_store\\=SimpleVectorStore.from\\_persist\\_dir(persist\\_dir\\=\"<persist\\_dir>\"),\n    index\\_store\\=SimpleIndexStore.from\\_persist\\_dir(persist\\_dir\\=\"<persist\\_dir>\"),\n)\n\nWe can then load specific indices from the `StorageContext` through some convenience functions below.\n\nfrom llama\\_index import load\\_index\\_from\\_storage, load\\_indices\\_from\\_storage, load\\_graph\\_from\\_storage\n\n\\# load a single index\n\\# need to specify index\\_id if multiple indexes are persisted to the same directory\nindex \\= load\\_index\\_from\\_storage(storage\\_context, index\\_id\\=\"<index\\_id>\")\n\n\\# don't need to specify index\\_id if there's only one index in storage context\nindex \\= load\\_index\\_from\\_storage(storage\\_context)\n\n\\# load multiple indices\nindices \\= load\\_indices\\_from\\_storage(storage\\_context) \\# loads all indices\nindices \\= load\\_indices\\_from\\_storage(storage\\_context, index\\_ids\\=\\[index\\_id1, ...\\]) \\# loads specific indices\n\n\\# load composable graph\ngraph \\= load\\_graph\\_from\\_storage(storage\\_context, root\\_id\\=\"<root\\_id>\") \\# loads graph with the specified root\\_id\n\nHere\u2019s the full [API Reference on saving and loading](https://docs.llamaindex.ai/en/stable/api_reference/storage/indices_save_load.html).\n\n## Using a remote backend[\uf0c1](#using-a-remote-backend \"Permalink to this heading\")\n\nBy default, LlamaIndex uses a local filesystem to load and save files. However, you can override this by passing a `fsspec.AbstractFileSystem` object.\n\nHere\u2019s a simple example, instantiating a vector store:\n\nimport dotenv\nimport s3fs\nimport os\ndotenv.load\\_dotenv(\"../../../.env\")\n\n\\# load documents\ndocuments \\= SimpleDirectoryReader('../../../examples/paul\\_graham\\_essay/data/').load\\_data()\nprint(len(documents))\nindex \\= VectorStoreIndex.from\\_documents(documents)\n\nAt this point, everything has been the same. Now - let\u2019s instantiate a S3 filesystem and save / load from there.\n\n\\# set up s3fs\nAWS\\_KEY \\= os.environ\\['AWS\\_ACCESS\\_KEY\\_ID'\\]\nAWS\\_SECRET \\= os.environ\\['AWS\\_SECRET\\_ACCESS\\_KEY'\\]\nR2\\_ACCOUNT\\_ID \\= os.environ\\['R2\\_ACCOUNT\\_ID'\\]\n\nassert AWS\\_KEY is not None and AWS\\_KEY != \"\"\n\ns3 \\= s3fs.S3FileSystem(\n   key\\=AWS\\_KEY,\n   secret\\=AWS\\_SECRET,\n   endpoint\\_url\\=f'https://{R2\\_ACCOUNT\\_ID}.r2.cloudflarestorage.com',\n   s3\\_additional\\_kwargs\\={'ACL': 'public-read'}\n)\n\n\\# If you're using 2+ indexes with the same StorageContext,\n\\# run this to save the index to remote blob storage\nindex.set\\_index\\_id(\"vector\\_index\")\n\n\\# persist index to s3\ns3\\_bucket\\_name \\= 'llama-index/storage\\_demo'  \\# {bucket\\_name}/{index\\_name}\nindex.storage\\_context.persist(persist\\_dir\\=s3\\_bucket\\_name, fs\\=s3)\n\n\\# load index from s3\nindex\\_from\\_s3 \\= load\\_index\\_from\\_storage(\n    StorageContext.from\\_defaults(persist\\_dir\\=s3\\_bucket\\_name, fs\\=s3),\n    index\\_id\\='vector\\_index'\n)\n\nBy default, if you do not pass a filesystem, we will assume a local filesystem."
}