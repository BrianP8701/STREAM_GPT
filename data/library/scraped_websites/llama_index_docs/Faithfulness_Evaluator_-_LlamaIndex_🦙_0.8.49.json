{
    "metadata": {
        "type": "web",
        "url": "https://docs.llamaindex.ai/en/stable/examples/evaluation/faithfulness_eval.html",
        "title": "Faithfulness Evaluator - LlamaIndex \ud83e\udd99 0.8.49",
        "description": null
    },
    "text": "[Back to top](#)\n\nToggle table of contents sidebar\n\n## Faithfulness Evaluator[\uf0c1](#faithfulness-evaluator \"Permalink to this heading\")\n\nThis notebook uses the `FaithfulnessEvaluator` module to measure if the response from a query engine matches any source nodes.  \nThis is useful for measuring if the response was hallucinated.  \nThe data is extracted from the [New York City](https://en.wikipedia.org/wiki/New_York_City) wikipedia page.\n\n\\# attach to the same event-loop\nimport nest\\_asyncio\n\nnest\\_asyncio.apply()\n\n\\# configuring logger to INFO level\nimport logging\nimport sys\n\nlogging.basicConfig(stream\\=sys.stdout, level\\=logging.INFO)\nlogging.getLogger().addHandler(logging.StreamHandler(stream\\=sys.stdout))\n\nfrom llama\\_index import (\n    TreeIndex,\n    VectorStoreIndex,\n    SimpleDirectoryReader,\n    ServiceContext,\n    Response,\n)\nfrom llama\\_index.llms import OpenAI\nfrom llama\\_index.evaluation import FaithfulnessEvaluator\nimport pandas as pd\n\npd.set\\_option(\"display.max\\_colwidth\", 0)\n\nUsing GPT-4 here for evaluation\n\n\\# gpt-4\ngpt4 \\= OpenAI(temperature\\=0, model\\=\"gpt-4\")\nservice\\_context\\_gpt4 \\= ServiceContext.from\\_defaults(llm\\=gpt4)\n\nevaluator\\_gpt4 \\= FaithfulnessEvaluator(service\\_context\\=service\\_context\\_gpt4)\n\ndocuments \\= SimpleDirectoryReader(\"./test\\_wiki\\_data/\").load\\_data()\n\n\\# create vector index\nservice\\_context \\= ServiceContext.from\\_defaults(chunk\\_size\\=512)\nvector\\_index \\= VectorStoreIndex.from\\_documents(\n    documents, service\\_context\\=service\\_context\n)\n\n\\# define jupyter display function\ndef display\\_eval\\_df(response: Response, eval\\_result: str) \\-> None:\n    if response.source\\_nodes \\== \\[\\]:\n        print(\"no response!\")\n        return\n    eval\\_df \\= pd.DataFrame(\n        {\n            \"Response\": str(response),\n            \"Source\": response.source\\_nodes\\[0\\].node.text\\[:1000\\] + \"...\",\n            \"Evaluation Result\": \"Pass\" if eval\\_result.passing else \"Fail\",\n        },\n        index\\=\\[0\\],\n    )\n    eval\\_df \\= eval\\_df.style.set\\_properties(\n        \\*\\*{\n            \"inline-size\": \"600px\",\n            \"overflow-wrap\": \"break-word\",\n        },\n        subset\\=\\[\"Response\", \"Source\"\\]\n    )\n    display(eval\\_df)\n\nTo run evaluations you can call the `.evaluate_response()` function on the `Response` object return from the query to run the evaluations. Lets evaluate the outputs of the vector\\_index.\n\nquery\\_engine \\= vector\\_index.as\\_query\\_engine()\nresponse\\_vector \\= query\\_engine.query(\"How did New York City get its name?\")\neval\\_result \\= evaluator\\_gpt4.evaluate\\_response(response\\=response\\_vector)\n\ndisplay\\_eval\\_df(response\\_vector, eval\\_result)\n\n|     | Response | Source | Evaluation Result |\n| --- | --- | --- | --- |\n| 0   | New York City got its name from the English explorer Henry Hudson, who rediscovered New York Harbor in 1609 while searching for the Northwest Passage. He named the area New York after the Duke of York, who later became King James II of England. | He claimed the area for France and named it Nouvelle Angoul\u00eame (New Angoul\u00eame).A Spanish expedition, led by the Portuguese captain Est\u00eav\u00e3o Gomes sailing for Emperor Charles V, arrived in New York Harbor in January 1525 and charted the mouth of the Hudson River, which he named R\u00edo de San Antonio ('Saint Anthony's River').The Padr\u00f3n Real of 1527, the first scientific map to show the East Coast of North America continuously, was informed by Gomes' expedition and labeled the northeastern United States as Tierra de Esteban G\u00f3mez in his honor.In 1609, the English explorer Henry Hudson rediscovered New York Harbor while searching for the Northwest Passage to the Orient for the Dutch East India Company.He proceeded to sail up what the Dutch would name the North River (now the Hudson River), named first by Hudson as the Mauritius after Maurice, Prince of Orange.Hudson's first mate described the harbor as \"a very good Harbour for all windes\" and the river as \"a mile broad\" and \"full of fish\".Hud... | Fail |\n\n## Benchmark on Generated Question[\uf0c1](#benchmark-on-generated-question \"Permalink to this heading\")\n\nNow lets generate a few more questions so that we have more to evaluate with and run a small benchmark.\n\nfrom llama\\_index.evaluation import DatasetGenerator\n\nquestion\\_generator \\= DatasetGenerator.from\\_documents(documents)\neval\\_questions \\= question\\_generator.generate\\_questions\\_from\\_nodes(5)\n\neval\\_questions\n\nWARNING:llama\\_index.indices.service\\_context:chunk\\_size\\_limit is deprecated, please specify chunk\\_size instead\nchunk\\_size\\_limit is deprecated, please specify chunk\\_size instead\nchunk\\_size\\_limit is deprecated, please specify chunk\\_size instead\n\n\\['What is the population of New York City as of 2020?',\n 'Which borough of New York City is home to the headquarters of the United Nations?',\n 'How many languages are spoken in New York City, making it the most linguistically diverse city in the world?',\n 'Who founded the trading post on Manhattan Island that would later become New York City?',\n 'What was New York City named after in 1664?'\\]\n\nimport asyncio\n\ndef evaluate\\_query\\_engine(query\\_engine, questions):\n    c \\= \\[query\\_engine.aquery(q) for q in questions\\]\n    results \\= asyncio.run(asyncio.gather(\\*c))\n    print(\"finished query\")\n\n    total\\_correct \\= 0\n    for r in results:\n        \\# evaluate with gpt 4\n        eval\\_result \\= (\n            1 if evaluator\\_gpt4.evaluate\\_response(response\\=r).passing else 0\n        )\n        total\\_correct += eval\\_result\n\n    return total\\_correct, len(results)\n\nvector\\_query\\_engine \\= vector\\_index.as\\_query\\_engine()\ncorrect, total \\= evaluate\\_query\\_engine(vector\\_query\\_engine, eval\\_questions\\[:5\\])\n\nprint(f\"score: {correct}/{total}\")\n\nINFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/embeddings processing\\_ms=35 request\\_id=b36e17a843c31e827f0b7034e603cf28 response\\_code=200\nmessage='OpenAI API response' path=https://api.openai.com/v1/embeddings processing\\_ms=35 request\\_id=b36e17a843c31e827f0b7034e603cf28 response\\_code=200\nmessage='OpenAI API response' path=https://api.openai.com/v1/embeddings processing\\_ms=35 request\\_id=b36e17a843c31e827f0b7034e603cf28 response\\_code=200\nINFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/embeddings processing\\_ms=35 request\\_id=5acb726518065db9312da9f23beef411 response\\_code=200\nmessage='OpenAI API response' path=https://api.openai.com/v1/embeddings processing\\_ms=35 request\\_id=5acb726518065db9312da9f23beef411 response\\_code=200\nmessage='OpenAI API response' path=https://api.openai.com/v1/embeddings processing\\_ms=35 request\\_id=5acb726518065db9312da9f23beef411 response\\_code=200\nINFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/embeddings processing\\_ms=46 request\\_id=4af43bfbe4e24fdae0ec33312ee7491e response\\_code=200\nmessage='OpenAI API response' path=https://api.openai.com/v1/embeddings processing\\_ms=46 request\\_id=4af43bfbe4e24fdae0ec33312ee7491e response\\_code=200\nmessage='OpenAI API response' path=https://api.openai.com/v1/embeddings processing\\_ms=46 request\\_id=4af43bfbe4e24fdae0ec33312ee7491e response\\_code=200\nINFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/embeddings processing\\_ms=37 request\\_id=e30413546fe5f96d3890606767f2ec53 response\\_code=200\nmessage='OpenAI API response' path=https://api.openai.com/v1/embeddings processing\\_ms=37 request\\_id=e30413546fe5f96d3890606767f2ec53 response\\_code=200\nmessage='OpenAI API response' path=https://api.openai.com/v1/embeddings processing\\_ms=37 request\\_id=e30413546fe5f96d3890606767f2ec53 response\\_code=200\nINFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/embeddings processing\\_ms=33 request\\_id=01f0a8dada4dae80c97a9a412f03b84f response\\_code=200\nmessage='OpenAI API response' path=https://api.openai.com/v1/embeddings processing\\_ms=33 request\\_id=01f0a8dada4dae80c97a9a412f03b84f response\\_code=200\nmessage='OpenAI API response' path=https://api.openai.com/v1/embeddings processing\\_ms=33 request\\_id=01f0a8dada4dae80c97a9a412f03b84f response\\_code=200\nINFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing\\_ms=282 request\\_id=ed7b1f8ba68ae32b1d8e24e0d0764e86 response\\_code=200\nmessage='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing\\_ms=282 request\\_id=ed7b1f8ba68ae32b1d8e24e0d0764e86 response\\_code=200\nmessage='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing\\_ms=282 request\\_id=ed7b1f8ba68ae32b1d8e24e0d0764e86 response\\_code=200\nINFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing\\_ms=820 request\\_id=b4532c6d665b6cfd644861ed69819cb9 response\\_code=200\nmessage='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing\\_ms=820 request\\_id=b4532c6d665b6cfd644861ed69819cb9 response\\_code=200\nmessage='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing\\_ms=820 request\\_id=b4532c6d665b6cfd644861ed69819cb9 response\\_code=200\nINFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing\\_ms=847 request\\_id=4d9bbc71a95b7e0bb69a048e251772c8 response\\_code=200\nmessage='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing\\_ms=847 request\\_id=4d9bbc71a95b7e0bb69a048e251772c8 response\\_code=200\nmessage='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing\\_ms=847 request\\_id=4d9bbc71a95b7e0bb69a048e251772c8 response\\_code=200\nINFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing\\_ms=952 request\\_id=d1657940d881929d500b1fddc46b5866 response\\_code=200\nmessage='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing\\_ms=952 request\\_id=d1657940d881929d500b1fddc46b5866 response\\_code=200\nmessage='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing\\_ms=952 request\\_id=d1657940d881929d500b1fddc46b5866 response\\_code=200\nINFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing\\_ms=1482 request\\_id=c4456f75580d227f846d3a044e5eef1b response\\_code=200\nmessage='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing\\_ms=1482 request\\_id=c4456f75580d227f846d3a044e5eef1b response\\_code=200\nmessage='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing\\_ms=1482 request\\_id=c4456f75580d227f846d3a044e5eef1b response\\_code=200\nfinished query\nscore: 5/5"
}