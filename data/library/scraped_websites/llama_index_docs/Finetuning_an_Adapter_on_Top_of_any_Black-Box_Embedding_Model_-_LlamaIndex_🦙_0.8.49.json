{
    "metadata": {
        "type": "web",
        "url": "https://docs.llamaindex.ai/en/stable/examples/finetuning/embeddings/finetune_embedding_adapter.html",
        "title": "Finetuning an Adapter on Top of any Black-Box Embedding Model - LlamaIndex \ud83e\udd99 0.8.49",
        "description": null
    },
    "text": "[Back to top](#)\n\nToggle table of contents sidebar\n\nWe have capabilities in LlamaIndex allowing you to fine-tune an adapter on top of embeddings produced from any model (sentence\\_transformers, OpenAI, and more).\n\nThis allows you to transform your embedding representations into a new latent space that\u2019s optimized for retrieval over your specific data and queries. This can lead to small increases in retrieval performance that in turn translate to better performing RAG systems.\n\nWe do this via our `EmbeddingAdapterFinetuneEngine` abstraction. We fine-tune three types of adapters:\n\n*   Linear\n    \n*   2-Layer NN\n    \n*   Custom NN\n    \n\n## Generate Corpus[\uf0c1](#generate-corpus \"Permalink to this heading\")\n\nWe use our helper abstractions, `generate_qa_embedding_pairs`, to generate our training and evaluation dataset. This function takes in any set of text nodes (chunks) and generates a structured dataset containing (question, context) pairs.\n\nimport json\n\nfrom llama\\_index import SimpleDirectoryReader\nfrom llama\\_index.node\\_parser import SimpleNodeParser\nfrom llama\\_index.schema import MetadataMode\n\nTRAIN\\_FILES \\= \\[\"../../../examples/data/10k/lyft\\_2021.pdf\"\\]\nVAL\\_FILES \\= \\[\"../../../examples/data/10k/uber\\_2021.pdf\"\\]\n\nTRAIN\\_CORPUS\\_FPATH \\= \"./data/train\\_corpus.json\"\nVAL\\_CORPUS\\_FPATH \\= \"./data/val\\_corpus.json\"\n\ndef load\\_corpus(files, verbose\\=False):\n    if verbose:\n        print(f\"Loading files {files}\")\n\n    reader \\= SimpleDirectoryReader(input\\_files\\=files)\n    docs \\= reader.load\\_data()\n    if verbose:\n        print(f\"Loaded {len(docs)} docs\")\n\n    parser \\= SimpleNodeParser.from\\_defaults()\n    nodes \\= parser.get\\_nodes\\_from\\_documents(docs, show\\_progress\\=verbose)\n\n    if verbose:\n        print(f\"Parsed {len(nodes)} nodes\")\n\n    return nodes\n\nWe do a very naive train/val split by having the Lyft corpus as the train dataset, and the Uber corpus as the val dataset.\n\ntrain\\_nodes \\= load\\_corpus(TRAIN\\_FILES, verbose\\=True)\nval\\_nodes \\= load\\_corpus(VAL\\_FILES, verbose\\=True)\n\nLoading files \\['../../../examples/data/10k/lyft\\_2021.pdf'\\]\nLoaded 238 docs\n\nParsed 349 nodes\nLoading files \\['../../../examples/data/10k/uber\\_2021.pdf'\\]\nLoaded 307 docs\n\n### Generate synthetic queries[\uf0c1](#generate-synthetic-queries \"Permalink to this heading\")\n\nNow, we use an LLM (gpt-3.5-turbo) to generate questions using each text chunk in the corpus as context.\n\nEach pair of (generated question, text chunk used as context) becomes a datapoint in the finetuning dataset (either for training or evaluation).\n\nfrom llama\\_index.finetuning import (\n    generate\\_qa\\_embedding\\_pairs,\n    EmbeddingQAFinetuneDataset,\n)\n\ntrain\\_dataset \\= generate\\_qa\\_embedding\\_pairs(train\\_nodes)\nval\\_dataset \\= generate\\_qa\\_embedding\\_pairs(val\\_nodes)\n\ntrain\\_dataset.save\\_json(\"train\\_dataset.json\")\nval\\_dataset.save\\_json(\"val\\_dataset.json\")\n\n\\# \\[Optional\\] Load\ntrain\\_dataset \\= EmbeddingQAFinetuneDataset.from\\_json(\"train\\_dataset.json\")\nval\\_dataset \\= EmbeddingQAFinetuneDataset.from\\_json(\"val\\_dataset.json\")\n\n## Run Embedding Finetuning[\uf0c1](#run-embedding-finetuning \"Permalink to this heading\")\n\nWe then fine-tune our linear adapter on top of an existing embedding model. We import our new `EmbeddingAdapterFinetuneEngine` abstraction, which takes in an existing embedding model and a set of training parameters.\n\n### Fine-tune bge-small-en (default)[\uf0c1](#fine-tune-bge-small-en-default \"Permalink to this heading\")\n\nfrom llama\\_index.finetuning import EmbeddingAdapterFinetuneEngine\nfrom llama\\_index.embeddings import resolve\\_embed\\_model\nimport torch\n\nbase\\_embed\\_model \\= resolve\\_embed\\_model(\"local:BAAI/bge-small-en\")\n\nfinetune\\_engine \\= EmbeddingAdapterFinetuneEngine(\n    train\\_dataset,\n    base\\_embed\\_model,\n    model\\_output\\_path\\=\"model\\_output\\_test\",\n    \\# bias=True,\n    epochs\\=4,\n    verbose\\=True,\n    \\# optimizer\\_class=torch.optim.SGD,\n    \\# optimizer\\_params={\"lr\": 0.01}\n)\n\nfinetune\\_engine.finetune()\n\nembed\\_model \\= finetune\\_engine.get\\_finetuned\\_model()\n\n\\# alternatively import model\n\\# from llama\\_index.embeddings import LinearAdapterEmbeddingModel\n\\# embed\\_model = LinearAdapterEmbeddingModel(base\\_embed\\_model, \"model\\_output\\_test\")\n\n## Evaluate Finetuned Model[\uf0c1](#evaluate-finetuned-model \"Permalink to this heading\")\n\nWe compare the fine-tuned model against the base model, as well as against text-embedding-ada-002.\n\nWe evaluate with two ranking metrics:\n\n*   **Hit-rate metric**: For each (query, context) pair, we retrieve the top-k documents with the query. It\u2019s a hit if the results contain the ground-truth context.\n    \n*   **Mean Reciprocal Rank**: A slightly more granular ranking metric that looks at the \u201creciprocal rank\u201d of the ground-truth context in the top-k retrieved set. The reciprocal rank is defined as 1/rank. Of course, if the results don\u2019t contain the context, then the reciprocal rank is 0.\n    \n\nfrom llama\\_index.embeddings import OpenAIEmbedding\nfrom llama\\_index import ServiceContext, VectorStoreIndex\nfrom llama\\_index.schema import TextNode\nfrom tqdm.notebook import tqdm\nimport pandas as pd\n\nfrom eval\\_utils import evaluate, display\\_results\n\nada \\= OpenAIEmbedding()\nada\\_val\\_results \\= evaluate(val\\_dataset, ada)\n\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 790/790 \\[03:03<00:00,  4.30it/s\\]\n\ndisplay\\_results(\\[\"ada\"\\], \\[ada\\_val\\_results\\])\n\n|     | retrievers | hit\\_rate | mrr |\n| --- | --- | --- | --- |\n| 0   | ada | 0.870886 | 0.72884 |\n\nbge \\= \"local:BAAI/bge-small-en\"\nbge\\_val\\_results \\= evaluate(val\\_dataset, bge)\n\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 790/790 \\[00:23<00:00, 33.76it/s\\]\n\ndisplay\\_results(\\[\"bge\"\\], \\[bge\\_val\\_results\\])\n\n|     | retrievers | hit\\_rate | mrr |\n| --- | --- | --- | --- |\n| 0   | bge | 0.787342 | 0.643038 |\n\nft\\_val\\_results \\= evaluate(val\\_dataset, embed\\_model)\n\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 790/790 \\[00:21<00:00, 36.95it/s\\]\n\ndisplay\\_results(\\[\"ft\"\\], \\[ft\\_val\\_results\\])\n\n|     | retrievers | hit\\_rate | mrr |\n| --- | --- | --- | --- |\n| 0   | ft  | 0.798734 | 0.662152 |\n\nHere we show all the results concatenated together.\n\ndisplay\\_results(\n    \\[\"ada\", \"bge\", \"ft\"\\], \\[ada\\_val\\_results, bge\\_val\\_results, ft\\_val\\_results\\]\n)\n\n|     | retrievers | hit\\_rate | mrr |\n| --- | --- | --- | --- |\n| 0   | ada | 0.870886 | 0.730105 |\n| 1   | bge | 0.787342 | 0.643038 |\n| 2   | ft  | 0.798734 | 0.662152 |\n\n## Fine-tune a Two-Layer Adapter[\uf0c1](#fine-tune-a-two-layer-adapter \"Permalink to this heading\")\n\nLet\u2019s try fine-tuning a two-layer NN as well!\n\nIt\u2019s a simple two-layer NN with a ReLU activation and a residual layer at the end.\n\nWe train for 25 epochs - longer than the linear adapter - and preserve checkpoints eveyr 100 steps.\n\n\\# requires torch dependency\nfrom llama\\_index.embeddings.adapter\\_utils import TwoLayerNN\n\nfrom llama\\_index.finetuning import EmbeddingAdapterFinetuneEngine\nfrom llama\\_index.embeddings import resolve\\_embed\\_model\nfrom llama\\_index.embeddings import AdapterEmbeddingModel\n\nbase\\_embed\\_model \\= resolve\\_embed\\_model(\"local:BAAI/bge-small-en\")\nadapter\\_model \\= TwoLayerNN(\n    384,  \\# input dimension\n    1024,  \\# hidden dimension\n    384,  \\# output dimension\n    bias\\=True,\n    add\\_residual\\=True,\n)\n\nfinetune\\_engine \\= EmbeddingAdapterFinetuneEngine(\n    train\\_dataset,\n    base\\_embed\\_model,\n    model\\_output\\_path\\=\"model5\\_output\\_test\",\n    model\\_checkpoint\\_path\\=\"model5\\_ck\",\n    adapter\\_model\\=adapter\\_model,\n    epochs\\=25,\n    verbose\\=True,\n)\n\nfinetune\\_engine.finetune()\n\nembed\\_model\\_2layer \\= finetune\\_engine.get\\_finetuned\\_model(\n    adapter\\_cls\\=TwoLayerNN\n)\n\n### Evaluation Results[\uf0c1](#evaluation-results \"Permalink to this heading\")\n\nRun the same evaluation script used in the previous section to measure hit-rate/MRR within the two-layer model.\n\n\\# load model from checkpoint in the midde\nembed\\_model\\_2layer \\= AdapterEmbeddingModel(\n    base\\_embed\\_model,\n    \"model5\\_output\\_test\",\n    TwoLayerNN,\n)\n\nfrom eval\\_utils import evaluate, display\\_results\n\nft\\_val\\_results\\_2layer \\= evaluate(val\\_dataset, embed\\_model\\_2layer)\n\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 790/790 \\[00:21<00:00, 36.93it/s\\]\n\n\\# comment out if you haven't run ada/bge yet\ndisplay\\_results(\n    \\[\"ada\", \"bge\", \"ft\\_2layer\"\\],\n    \\[ada\\_val\\_results, bge\\_val\\_results, ft\\_val\\_results\\_2layer\\],\n)\n\n\\# uncomment if you just want to display the fine-tuned model's results\n\\# display\\_results(\\[\"ft\\_2layer\"\\], \\[ft\\_val\\_results\\_2layer\\])\n\n|     | retrievers | hit\\_rate | mrr |\n| --- | --- | --- | --- |\n| 0   | ada | 0.870886 | 0.728840 |\n| 1   | bge | 0.787342 | 0.643038 |\n| 2   | ft\\_2layer | 0.798734 | 0.662848 |\n\n\\# load model from checkpoint in the midde\nembed\\_model\\_2layer\\_s900 \\= AdapterEmbeddingModel(\n    base\\_embed\\_model,\n    \"model5\\_ck/step\\_900\",\n    TwoLayerNN,\n)\n\nft\\_val\\_results\\_2layer\\_s900 \\= evaluate(val\\_dataset, embed\\_model\\_2layer\\_s900)\n\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 790/790 \\[00:19<00:00, 40.57it/s\\]\n\n\\# comment out if you haven't run ada/bge yet\ndisplay\\_results(\n    \\[\"ada\", \"bge\", \"ft\\_2layer\\_s900\"\\],\n    \\[ada\\_val\\_results, bge\\_val\\_results, ft\\_val\\_results\\_2layer\\_s900\\],\n)\n\n\\# uncomment if you just want to display the fine-tuned model's results\n\\# display\\_results(\\[\"ft\\_2layer\\_s900\"\\], \\[ft\\_val\\_results\\_2layer\\_s900\\])\n\n|     | retrievers | hit\\_rate | mrr |\n| --- | --- | --- | --- |\n| 0   | ada | 0.870886 | 0.728840 |\n| 1   | bge | 0.787342 | 0.643038 |\n| 2   | ft\\_2layer\\_s900 | 0.803797 | 0.667426 |\n\n## Try Your Own Custom Model[\uf0c1](#try-your-own-custom-model \"Permalink to this heading\")\n\nYou can define your own custom adapter here! Simply subclass `BaseAdapter`, which is a light wrapper around the `nn.Module` class.\n\nYou just need to subclass `forward` and `get_config_dict`.\n\nJust make sure you\u2019re familiar with writing `PyTorch` code :)\n\nfrom llama\\_index.embeddings.adapter\\_utils import BaseAdapter\nimport torch.nn.functional as F\nfrom torch import nn, Tensor\nfrom typing import Dict\n\nclass CustomNN(BaseAdapter):\n    \"\"\"Custom NN transformation.\n\n    Is a copy of our TwoLayerNN, showing it here for notebook purposes.\n\n    Args:\n        in\\_features (int): Input dimension.\n        hidden\\_features (int): Hidden dimension.\n        out\\_features (int): Output dimension.\n        bias (bool): Whether to use bias. Defaults to False.\n        activation\\_fn\\_str (str): Name of activation function. Defaults to \"relu\".\n\n    \"\"\"\n\n    def \\_\\_init\\_\\_(\n        self,\n        in\\_features: int,\n        hidden\\_features: int,\n        out\\_features: int,\n        bias: bool \\= False,\n        add\\_residual: bool \\= False,\n    ) \\-> None:\n        super(CustomNN, self).\\_\\_init\\_\\_()\n        self.in\\_features \\= in\\_features\n        self.hidden\\_features \\= hidden\\_features\n        self.out\\_features \\= out\\_features\n        self.bias \\= bias\n\n        self.linear1 \\= nn.Linear(in\\_features, hidden\\_features, bias\\=True)\n        self.linear2 \\= nn.Linear(hidden\\_features, out\\_features, bias\\=True)\n        self.\\_add\\_residual \\= add\\_residual\n        \\# if add\\_residual, then add residual\\_weight (init to 0)\n        self.residual\\_weight \\= nn.Parameter(torch.zeros(1))\n\n    def forward(self, embed: Tensor) \\-> Tensor:\n        \"\"\"Forward pass (Wv).\n\n        Args:\n            embed (Tensor): Input tensor.\n\n        \"\"\"\n        output1 \\= self.linear1(embed)\n        output1 \\= F.relu(output1)\n        output2 \\= self.linear2(output1)\n\n        if self.\\_add\\_residual:\n            output2 \\= self.residual\\_weight \\* output2 + embed\n\n        return output2\n\n    def get\\_config\\_dict(self) \\-> Dict:\n        \"\"\"Get config dict.\"\"\"\n        return {\n            \"in\\_features\": self.in\\_features,\n            \"hidden\\_features\": self.hidden\\_features,\n            \"out\\_features\": self.out\\_features,\n            \"bias\": self.bias,\n            \"add\\_residual\": self.\\_add\\_residual,\n        }\n\ncustom\\_adapter \\= CustomNN(\n    384,  \\# input dimension\n    1024,  \\# hidden dimension\n    384,  \\# output dimension\n    bias\\=True,\n    add\\_residual\\=True,\n)\n\nfinetune\\_engine \\= EmbeddingAdapterFinetuneEngine(\n    train\\_dataset,\n    base\\_embed\\_model,\n    model\\_output\\_path\\=\"custom\\_model\\_output\",\n    model\\_checkpoint\\_path\\=\"custom\\_model\\_ck\",\n    adapter\\_model\\=custom\\_adapter,\n    epochs\\=25,\n    verbose\\=True,\n)\n\nfinetune\\_engine.finetune()\n\nembed\\_model\\_custom \\= finetune\\_engine.get\\_finetuned\\_model(\n    adapter\\_cls\\=CustomAdapter\n)\n\n### Evaluation Results[\uf0c1](#id1 \"Permalink to this heading\")\n\nRun the same evaluation script used in the previous section to measure hit-rate/MRR.\n\n\\# \\[optional\\] load model manually\n\\# embed\\_model\\_custom = AdapterEmbeddingModel(\n\\#     base\\_embed\\_model,\n\\#     \"custom\\_model\\_ck/step\\_300\",\n\\#     TwoLayerNN,\n\\# )\n\nfrom eval\\_utils import evaluate, display\\_results\n\nft\\_val\\_results\\_custom \\= evaluate(val\\_dataset, embed\\_model\\_custom)\n\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 790/790 \\[00:20<00:00, 37.77it/s\\]\n\ndisplay\\_results(\\[\"ft\\_custom\"\\]x, \\[ft\\_val\\_results\\_custom\\])\n\n|     | retrievers | hit\\_rate | mrr |\n| --- | --- | --- | --- |\n| 0   | ft\\_custom | 0.789873 | 0.645127 |"
}