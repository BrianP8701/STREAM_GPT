{
    "metadata": {
        "type": "web",
        "url": "https://docs.llamaindex.ai/en/stable/examples/vector_stores/TencentVectorDBIndexDemo.html",
        "title": "Tencent Cloud VectorDB - LlamaIndex \ud83e\udd99 0.8.49",
        "description": null
    },
    "text": "[Back to top](#)\n\nToggle table of contents sidebar\n\n## Tencent Cloud VectorDB[\uf0c1](#tencent-cloud-vectordb \"Permalink to this heading\")\n\n> [Tencent Cloud VectorDB](https://cloud.tencent.com/document/product/1709) is a fully managed, self-developed, enterprise-level distributed database service designed for storing, retrieving, and analyzing multi-dimensional vector data. The database supports multiple index types and similarity calculation methods. A single index can support a vector scale of up to 1 billion and can support millions of QPS and millisecond-level query latency. Tencent Cloud Vector Database can not only provide an external knowledge base for large models to improve the accuracy of large model responses but can also be widely used in AI fields such as recommendation systems, NLP services, computer vision, and intelligent customer service.\n\n**This notebook shows the basic usage of TencentVectorDB as a Vector Store in LlamaIndex.**\n\nTo run, you should have a [Database instance.](https://cloud.tencent.com/document/product/1709/95101)\n\n## Setup[\uf0c1](#setup \"Permalink to this heading\")\n\nfrom llama\\_index import (\n    VectorStoreIndex,\n    SimpleDirectoryReader,\n    StorageContext,\n)\nfrom llama\\_index.vector\\_stores import TencentVectorDB\nfrom llama\\_index.vector\\_stores.tencentvectordb import (\n    CollectionParams,\n    FilterField,\n)\nimport tcvectordb\n\ntcvectordb.debug.DebugEnable \\= False\n\n### Please provide OpenAI access key[\uf0c1](#please-provide-openai-access-key \"Permalink to this heading\")\n\nIn order use embeddings by OpenAI you need to supply an OpenAI API Key:\n\nimport openai\n\nOPENAI\\_API\\_KEY \\= getpass.getpass(\"OpenAI API Key:\")\nopenai.api\\_key \\= OPENAI\\_API\\_KEY\n\n## Creating and populating the Vector Store[\uf0c1](#creating-and-populating-the-vector-store \"Permalink to this heading\")\n\nYou will now load some essays by Paul Graham from a local file and store them into the Tencent Cloud VectorDB.\n\n\\# load documents\ndocuments \\= SimpleDirectoryReader(\"../data/paul\\_graham\").load\\_data()\nprint(f\"Total documents: {len(documents)}\")\nprint(f\"First document, id: {documents\\[0\\].doc\\_id}\")\nprint(f\"First document, hash: {documents\\[0\\].hash}\")\nprint(\n    f\"First document, text ({len(documents\\[0\\].text)} characters):\\\\n{'='\\*20}\\\\n{documents\\[0\\].text\\[:360\\]} ...\"\n)\n\nTotal documents: 1\nFirst document, id: 5b7489b6-0cca-4088-8f30-6de32d540fdf\nFirst document, hash: 4c702b4df575421e1d1af4b1fd50511b226e0c9863dbfffeccb8b689b8448f35\nFirst document, text (75019 characters):\n====================\n\t\t\n\nWhat I Worked On\n\nFebruary 2021\n\nBefore college the two main things I worked on, outside of school, were writing and programming. I didn't write essays. I wrote what beginning writers were supposed to write then, and probably still are: short stories. My stories were awful. They had hardly any plot, just characters with strong feelings, which I imagined  ...\n\n### Initialize the Tencent Cloud VectorDB[\uf0c1](#initialize-the-tencent-cloud-vectordb \"Permalink to this heading\")\n\nCreation of the vector store entails creation of the underlying database collection if it does not exist yet:\n\nvector\\_store \\= TencentVectorDB(\n    url\\=\"http://10.0.X.X\",\n    key\\=\"eC4bLRy2va\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\",\n    collection\\_params\\=CollectionParams(dimension\\=1536, drop\\_exists\\=True),\n)\n\nNow wrap this store into an `index` LlamaIndex abstraction for later querying:\n\nstorage\\_context \\= StorageContext.from\\_defaults(vector\\_store\\=vector\\_store)\n\nindex \\= VectorStoreIndex.from\\_documents(\n    documents, storage\\_context\\=storage\\_context\n)\n\nNote that the above `from_documents` call does several things at once: it splits the input documents into chunks of manageable size (\u201cnodes\u201d), computes embedding vectors for each node, and stores them all in the Tencent Cloud VectorDB.\n\n## Querying the store[\uf0c1](#querying-the-store \"Permalink to this heading\")\n\n### Basic querying[\uf0c1](#basic-querying \"Permalink to this heading\")\n\nquery\\_engine \\= index.as\\_query\\_engine()\nresponse \\= query\\_engine.query(\"Why did the author choose to work on AI?\")\nprint(response)\n\nThe author chose to work on AI because of his fascination with the novel The Moon is a Harsh Mistress, which featured an intelligent computer called Mike, and a PBS documentary that showed Terry Winograd using SHRDLU. He was also drawn to the idea that AI could be used to explore the ultimate truths that other fields could not.\n\n### MMR-based queries[\uf0c1](#mmr-based-queries \"Permalink to this heading\")\n\nThe MMR (maximal marginal relevance) method is designed to fetch text chunks from the store that are at the same time relevant to the query but as different as possible from each other, with the goal of providing a broader context to the building of the final answer:\n\nquery\\_engine \\= index.as\\_query\\_engine(vector\\_store\\_query\\_mode\\=\"mmr\")\nresponse \\= query\\_engine.query(\"Why did the author choose to work on AI?\")\nprint(response)\n\nThe author chose to work on AI because he was impressed and envious of his friend who had built a computer kit and was able to type programs into it. He was also inspired by a novel by Heinlein called The Moon is a Harsh Mistress, which featured an intelligent computer called Mike, and a PBS documentary that showed Terry Winograd using SHRDLU. He was also disappointed with philosophy courses in college, which he found to be boring, and he wanted to work on something that seemed more powerful.\n\n## Connecting to an existing store[\uf0c1](#connecting-to-an-existing-store \"Permalink to this heading\")\n\nSince this store is backed by Tencent Cloud VectorDB, it is persistent by definition. So, if you want to connect to a store that was created and populated previously, here is how:\n\nnew\\_vector\\_store \\= TencentVectorDB(\n    url\\=\"http://10.0.X.X\",\n    key\\=\"eC4bLRy2va\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\",\n    collection\\_params\\=CollectionParams(dimension\\=1536, drop\\_exists\\=False),\n)\n\n\\# Create index (from preexisting stored vectors)\nnew\\_index\\_instance \\= VectorStoreIndex.from\\_vector\\_store(\n    vector\\_store\\=new\\_vector\\_store\n)\n\n\\# now you can do querying, etc:\nquery\\_engine \\= index.as\\_query\\_engine(similarity\\_top\\_k\\=5)\nresponse \\= query\\_engine.query(\n    \"What did the author study prior to working on AI?\"\n)\n\nThe author studied philosophy and painting, worked on spam filters, and wrote essays prior to working on AI.\n\n## Removing documents from the index[\uf0c1](#removing-documents-from-the-index \"Permalink to this heading\")\n\nFirst get an explicit list of pieces of a document, or \u201cnodes\u201d, from a `Retriever` spawned from the index:\n\nretriever \\= new\\_index\\_instance.as\\_retriever(\n    vector\\_store\\_query\\_mode\\=\"mmr\",\n    similarity\\_top\\_k\\=3,\n    vector\\_store\\_kwargs\\={\"mmr\\_prefetch\\_factor\": 4},\n)\nnodes\\_with\\_scores \\= retriever.retrieve(\n    \"What did the author study prior to working on AI?\"\n)\n\nprint(f\"Found {len(nodes\\_with\\_scores)} nodes.\")\nfor idx, node\\_with\\_score in enumerate(nodes\\_with\\_scores):\n    print(f\"    \\[{idx}\\] score = {node\\_with\\_score.score}\")\n    print(f\"        id    = {node\\_with\\_score.node.node\\_id}\")\n    print(f\"        text  = {node\\_with\\_score.node.text\\[:90\\]} ...\")\n\nFound 3 nodes.\n    \\[0\\] score = 0.42589144520149874\n        id    = 05f53f06-9905-461a-bc6d-fa4817e5a776\n        text  = What I Worked On\n\nFebruary 2021\n\nBefore college the two main things I worked on, outside o ...\n    \\[1\\] score = -0.0012061281453193962\n        id    = 2f9f843e-6495-4646-a03d-4b844ff7c1ab\n        text  = been explored. But all I wanted was to get out of grad school, and my rapidly written diss ...\n    \\[2\\] score = 0.025454533089838027\n        id    = 28ad32da-25f9-4aaa-8487-88390ec13348\n        text  = showed Terry Winograd using SHRDLU. I haven't tried rereading The Moon is a Harsh Mistress ...\n\nBut wait! When using the vector store, you should consider the **document** as the sensible unit to delete, and not any individual node belonging to it. Well, in this case, you just inserted a single text file, so all nodes will have the same `ref_doc_id`:\n\nprint(\"Nodes' ref\\_doc\\_id:\")\nprint(\"\\\\n\".join(\\[nws.node.ref\\_doc\\_id for nws in nodes\\_with\\_scores\\]))\n\nNodes' ref\\_doc\\_id:\n5b7489b6-0cca-4088-8f30-6de32d540fdf\n5b7489b6-0cca-4088-8f30-6de32d540fdf\n5b7489b6-0cca-4088-8f30-6de32d540fdf\n\nNow let\u2019s say you need to remove the text file you uploaded:\n\nnew\\_vector\\_store.delete(nodes\\_with\\_scores\\[0\\].node.ref\\_doc\\_id)\n\nRepeat the very same query and check the results now. You should see _no results_ being found:\n\nnodes\\_with\\_scores \\= retriever.retrieve(\n    \"What did the author study prior to working on AI?\"\n)\n\nprint(f\"Found {len(nodes\\_with\\_scores)} nodes.\")"
}