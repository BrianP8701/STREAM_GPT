{
    "metadata": {
        "type": "web",
        "url": "https://docs.llamaindex.ai/en/stable/core_modules/data_modules/storage/vector_stores.html",
        "title": "Vector Stores - LlamaIndex \ud83e\udd99 0.8.49",
        "description": null
    },
    "text": "Toggle site navigation sidebar\n\nToggle table of contents sidebar\n\n[Back to top](#)\n\nToggle table of contents sidebar\n\n## Vector Stores[\uf0c1](#vector-stores \"Permalink to this heading\")\n\nVector stores contain embedding vectors of ingested document chunks (and sometimes the document chunks as well).\n\n## Simple Vector Store[\uf0c1](#simple-vector-store \"Permalink to this heading\")\n\nBy default, LlamaIndex uses a simple in-memory vector store that\u2019s great for quick experimentation. They can be persisted to (and loaded from) disk by calling `vector_store.persist()` (and `SimpleVectorStore.from_persist_path(...)` respectively)."
}