{
    "metadata": {
        "type": "web",
        "url": "https://docs.llamaindex.ai/en/stable/examples/vector_stores/RocksetIndexDemo.html",
        "title": "Rockset Vector Store - LlamaIndex \ud83e\udd99 0.8.49",
        "description": null
    },
    "text": "[Back to top](#)\n\nToggle table of contents sidebar\n\n## Rockset Vector Store[\uf0c1](#rockset-vector-store \"Permalink to this heading\")\n\nAs a real-time search and analytics database, Rockset uses indexing to deliver scalable and performant personalization, product search, semantic search, chatbot applications, and more. Since Rockset is purpose-built for real-time, you can build these responsive applications on constantly updating, streaming data. By integrating Rockset with LlamaIndex, you can easily use LLMs on your own real-time data for production-ready vector search applications.\n\nWe\u2019ll walk through a demonstration of how to use Rockset as a vector store in LlamaIndex.\n\n## Tutorial[\uf0c1](#tutorial \"Permalink to this heading\")\n\nIn this example, we\u2019ll use OpenAI\u2019s `text-embedding-ada-002` model to generate embeddings and Rockset as vector store to store embeddings. We\u2019ll ingest text from a file and ask questions about the content.\n\n### Setting Up Your Environment[\uf0c1](#setting-up-your-environment \"Permalink to this heading\")\n\n1.  Create a [collection](https://rockset.com/docs/collections) from the Rockset console with the [Write API](https://rockset.com/docs/write-api/) as your source. Name your collection `llamaindex_demo`. Configure the following [ingest transformation](https://rockset.com/docs/ingest-transformation) with [`VECTOR_ENFORCE`](https://rockset.com/docs/vector-functions) to define your embeddings field and take advantage of performance and storage optimizations:\n    \n\nSELECT \n    \\_input.\\* EXCEPT(\\_meta), \n    VECTOR\\_ENFORCE(\n        \\_input.embedding,\n        1536,\n        'float'\n    ) as embedding\nFROM \\_input\n\n2.  Create an [API key](https://rockset.com/docs/iam) from the Rockset console and set the `ROCKSET_API_KEY` environment variable. Find your API server [here](http://rockset.com/docs/rest-api#introduction) and set the `ROCKSET_API_SERVER` environment variable. Set the `OPENAI_API_KEY` environment variable.\n    \n3.  Install the dependencies.\n    \n\npip3 install llama\\_index rockset \n\n4.  LlamaIndex allows you to ingest data from a variety of sources. For this example, we\u2019ll read from a text file named `constitution.txt`, which is a transcript of the American Constitution, found [here](https://www.archives.gov/founding-docs/constitution-transcript).\n    \n\n### Data ingestion[\uf0c1](#data-ingestion \"Permalink to this heading\")\n\nUse LlamaIndex\u2019s `SimpleDirectoryReader` class to convert the text file to a list of `Document` objects.\n\nfrom llama\\_index import SimpleDirectoryReader\n\ndocs \\= SimpleDirectoryReader(\n    input\\_files\\=\\[\"{path to}/consitution.txt\"\\]\n).load\\_data()\n\nInstantiate the LLM and service context.\n\nfrom llama\\_index import ServiceContext\nfrom llama\\_index.llms import OpenAI\n\nllm \\= OpenAI(temperature\\=0.8, model\\=\"gpt-3.5-turbo\")\nservice\\_context \\= ServiceContext.from\\_defaults(llm\\=llm)\n\nInstantiate the vector store and storage context.\n\nfrom llama\\_index import StorageContext\nfrom llama\\_index.vector\\_stores import RocksetVectorStore\n\nvector\\_store \\= RocksetVectorStore(collection\\=\"llamaindex\\_demo\")\nstorage\\_context \\= StorageContext.from\\_defaults(vector\\_store\\=vector\\_store)\n\nAdd documents to the `llamaindex_demo` collection and create an index.\n\nfrom llama\\_index import VectorStoreIndex\n\nindex \\= VectorStoreIndex.from\\_documents(\n    docs, storage\\_context\\=storage\\_context, service\\_context\\=service\\_context\n)\n\n### Querying[\uf0c1](#querying \"Permalink to this heading\")\n\nAsk a question about your document and generate a response.\n\nresponse \\= index.as\\_query\\_engine(service\\_context\\=service\\_context).query(\n    \"What is the duty of the president?\"\n)\n\nprint(str(response))\n\nRun the program.\n\n$ python3 main.py\nThe duty of the president is to faithfully execute the Office of President of the United States, preserve, protect and defend the Constitution of the United States, serve as the Commander in Chief of the Army and Navy, grant reprieves and pardons for offenses against the United States (except in cases of impeachment), make treaties and appoint ambassadors and other public ministers, take care that the laws be faithfully executed, and commission all the officers of the United States.\n\n## Creating an Index from an Existing Collection[\uf0c1](#creating-an-index-from-an-existing-collection \"Permalink to this heading\")\n\nYou can create indices with data from existing collections.\n\nfrom llama\\_index import VectorStoreIndex\nfrom llama\\_index.vector\\_stores import RocksetVectorStore\n\nvector\\_store \\= RocksetVectorStore(collection\\=\"llamaindex\\_demo\")\n\nindex \\= VectorStoreIndex.from\\_vector\\_store(vector\\_store)\n\n## Creating an Index from a New Collection[\uf0c1](#creating-an-index-from-a-new-collection \"Permalink to this heading\")\n\nYou can also create a new Rockset collection to use as a vector store.\n\nfrom llama\\_index.vector\\_stores import RocksetVectorStore\n\nvector\\_store \\= RocksetVectorStore.with\\_new\\_collection(\n    collection\\=\"llamaindex\\_demo\",  \\# name of new collection\n    dimensions\\=1536,  \\# specifies length of vectors in ingest tranformation (optional)\n    \\# other RocksetVectorStore args\n)\n\nindex \\= VectorStoreIndex(\n    nodes,\n    storage\\_context\\=StorageContext.from\\_defaults(vector\\_store\\=vector\\_store),\n)\n\n## Configuration[\uf0c1](#configuration \"Permalink to this heading\")\n\n*   **collection**: Name of the collection to query (required).\n    \n\nRocksetVectorStore(collection\\=\"my\\_collection\")\n\n*   **workspace**: Name of the workspace containing the collection. Defaults to `\"commons\"`.\n    \n\nRocksetVectorStore(worksapce\\=\"my\\_workspace\")\n\n*   **api\\_key**: The API key to use to authenticate Rockset requests. Ignored if `client` is passed in. Defaults to the `ROCKSET_API_KEY` environment variable.\n    \n\nRocksetVectorStore(api\\_key\\=\"<my key>\")\n\n*   **api\\_server**: The API server to use for Rockset requests. Ignored if `client` is passed in. Defaults to the `ROCKSET_API_KEY` environment variable or `\"https://api.use1a1.rockset.com\"` if the `ROCKSET_API_SERVER` is not set.\n    \n\nfrom rockset import Regions\nRocksetVectorStore(api\\_server\\=Regions.euc1a1)\n\n*   **client**: Rockset client object to use to execute Rockset requests. If not specified, a client object is internally constructed with the `api_key` parameter (or `ROCKSET_API_SERVER` environment variable) and the `api_server` parameter (or `ROCKSET_API_SERVER` environment variable).\n    \n\nfrom rockset import RocksetClient\nRocksetVectorStore(client\\=RocksetClient(api\\_key\\=\"<my key>\"))\n\n*   **embedding\\_col**: The name of the database field containing embeddings. Defaults to `\"embedding\"`.\n    \n\nRocksetVectorStore(embedding\\_col\\=\"my\\_embedding\")\n\n*   **metadata\\_col**: The name of the database field containing node data. Defaults to `\"metadata\"`.\n    \n\nRocksetVectorStore(metadata\\_col\\=\"node\")\n\n*   **distance\\_func**: The metric to measure vector relationship. Defaults to cosine similarity.\n    \n\nRocksetVectorStore(distance\\_func\\=RocksetVectorStore.DistanceFunc.DOT\\_PRODUCT)"
}