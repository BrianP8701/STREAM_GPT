{
    "metadata": {
        "type": "web",
        "url": "https://docs.llamaindex.ai/en/stable/core_modules/model_modules/llms/usage_standalone.html",
        "title": "Using LLMs as standalone modules - LlamaIndex \ud83e\udd99 0.8.49",
        "description": null
    },
    "text": "[Back to top](#)\n\nToggle table of contents sidebar\n\nYou can use our LLM modules on their own.\n\n## Text Completion Example[\uf0c1](#text-completion-example \"Permalink to this heading\")\n\nfrom llama\\_index.llms import OpenAI\n\n\\# non-streaming\nresp \\= OpenAI().complete('Paul Graham is ')\nprint(resp)\n\n\\# using streaming endpoint\nfrom llama\\_index.llms import OpenAI\nllm \\= OpenAI()\nresp \\= llm.stream\\_complete('Paul Graham is ')\nfor delta in resp:\n    print(delta, end\\='')\n\n## Chat Example[\uf0c1](#chat-example \"Permalink to this heading\")\n\nfrom llama\\_index.llms import ChatMessage, OpenAI\n\nmessages \\= \\[\n    ChatMessage(role\\=\"system\", content\\=\"You are a pirate with a colorful personality\"),\n    ChatMessage(role\\=\"user\", content\\=\"What is your name\"),\n\\]\nresp \\= OpenAI().chat(messages)\nprint(resp)\n\nCheck out our [modules section](https://docs.llamaindex.ai/en/stable/core_modules/model_modules/llms/modules.html) for usage guides for each LLM."
}