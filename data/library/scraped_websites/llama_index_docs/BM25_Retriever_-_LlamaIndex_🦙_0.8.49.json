{
    "metadata": {
        "type": "web",
        "url": "https://docs.llamaindex.ai/en/stable/examples/retrievers/bm25_retriever.html",
        "title": "BM25 Retriever - LlamaIndex \ud83e\udd99 0.8.49",
        "description": null
    },
    "text": "[Back to top](#)\n\nToggle table of contents sidebar\n\n## BM25 Retriever[\uf0c1](#bm25-retriever \"Permalink to this heading\")\n\nIn this guide, we define a bm25 retriever that search documents using bm25 method.\n\nThis notebook is very similar to the RouterQueryEngine notebook.\n\n## Setup[\uf0c1](#setup \"Permalink to this heading\")\n\n\\# NOTE: This is ONLY necessary in jupyter notebook.\n\\# Details: Jupyter runs an event-loop behind the scenes.\n\\#          This results in nested event-loops when we start an event-loop to make async queries.\n\\#          This is normally not allowed, we use nest\\_asyncio to allow it for convenience.\nimport nest\\_asyncio\n\nnest\\_asyncio.apply()\n\nimport os\nimport openai\n\nos.environ\\[\"OPENAI\\_API\\_KEY\"\\] \\= \"sk-...\"\nopenai.api\\_key \\= os.environ\\[\"OPENAI\\_API\\_KEY\"\\]\n\nimport logging\nimport sys\n\nlogging.basicConfig(stream\\=sys.stdout, level\\=logging.INFO)\nlogging.getLogger().handlers \\= \\[\\]\nlogging.getLogger().addHandler(logging.StreamHandler(stream\\=sys.stdout))\n\nfrom llama\\_index import (\n    SimpleDirectoryReader,\n    ServiceContext,\n    StorageContext,\n    VectorStoreIndex,\n)\nfrom llama\\_index.retrievers import BM25Retriever\nfrom llama\\_index.indices.vector\\_store.retrievers.retriever import (\n    VectorIndexRetriever,\n)\nfrom llama\\_index.llms import OpenAI\n\n## Load Data[\uf0c1](#load-data \"Permalink to this heading\")\n\nWe first show how to convert a Document into a set of Nodes, and insert into a DocumentStore.\n\n\\# load documents\ndocuments \\= SimpleDirectoryReader(\"../data/paul\\_graham\").load\\_data()\n\n\\# initialize service context (set chunk size)\nllm \\= OpenAI(model\\=\"gpt-4\")\nservice\\_context \\= ServiceContext.from\\_defaults(chunk\\_size\\=1024, llm\\=llm)\nnodes \\= service\\_context.node\\_parser.get\\_nodes\\_from\\_documents(documents)\n\n\\# initialize storage context (by default it's in-memory)\nstorage\\_context \\= StorageContext.from\\_defaults()\nstorage\\_context.docstore.add\\_documents(nodes)\n\nindex \\= VectorStoreIndex(\n    nodes\\=nodes,\n    storage\\_context\\=storage\\_context,\n    service\\_context\\=service\\_context,\n)\n\n## BM25 Retriever[\uf0c1](#id1 \"Permalink to this heading\")\n\nWe will search document with bm25 retriever.\n\n\\# We can pass in the index, doctore, or list of nodes to create the retriever\nretriever \\= BM25Retriever.from\\_defaults(nodes\\=nodes, similarity\\_top\\_k\\=2)\n\nfrom llama\\_index.response.notebook\\_utils import display\\_source\\_node\n\n\\# will retrieve context from specific companies\nnodes \\= retriever.retrieve(\"What happened at Viaweb and Interleaf?\")\nfor node in nodes:\n    display\\_source\\_node(node)\n\n**Node ID:** d95537b4-b398-4b47-94ff-da86f05a27f7  \n**Similarity:** 5.171801938898801  \n**Text:** I wanted to go back to RISD, but I was now broke and RISD was very expensive, so I decided to get\u2026  \n\n**Node ID:** 6f84e2a5-1ab1-4389-8799-b7713e085931  \n**Similarity:** 4.838241203957084  \n**Text:** All you had to do was teach SHRDLU more words.\n\nThere weren\u2019t any classes in AI at Cornell then, \u2026  \n\nnodes \\= retriever.retrieve(\"What did Paul Graham do after RISD?\")\nfor node in nodes:\n    display\\_source\\_node(node)\n\n**Node ID:** a4fd0b29-4138-4741-9e27-9f65d6968eb4  \n**Similarity:** 8.090884087344435  \n**Text:** Not so much because it was badly written as because the problem is so convoluted. When you\u2019re wor\u2026  \n\n**Node ID:** d95537b4-b398-4b47-94ff-da86f05a27f7  \n**Similarity:** 5.830874349482576  \n**Text:** I wanted to go back to RISD, but I was now broke and RISD was very expensive, so I decided to get\u2026  \n\n## Router Retriever with bm25 method[\uf0c1](#router-retriever-with-bm25-method \"Permalink to this heading\")\n\nNow we will combine bm25 retriever with vector index retriever.\n\nfrom llama\\_index.tools import RetrieverTool\n\nvector\\_retriever \\= VectorIndexRetriever(index)\nbm25\\_retriever \\= BM25Retriever.from\\_defaults(nodes\\=nodes, similarity\\_top\\_k\\=2)\n\nretriever\\_tools \\= \\[\n    RetrieverTool.from\\_defaults(\n        retriever\\=vector\\_retriever,\n        description\\=\"Useful in most cases\",\n    ),\n    RetrieverTool.from\\_defaults(\n        retriever\\=bm25\\_retriever,\n        description\\=\"Useful if searching about specific information\",\n    ),\n\\]\n\nfrom llama\\_index.retrievers import RouterRetriever\n\nretriever \\= RouterRetriever.from\\_defaults(\n    retriever\\_tools\\=retriever\\_tools,\n    service\\_context\\=service\\_context,\n    select\\_multi\\=True,\n)\n\n\\# will retrieve all context from the author's life\nnodes \\= retriever.retrieve(\n    \"Can you give me all the context regarding the author's life?\"\n)\nfor node in nodes:\n    display\\_source\\_node(node)\n\nSelecting retriever 0: The author's life context is a broad topic, which may require a comprehensive approach that is useful in most cases..\n\n**Node ID:** fcd399c1-3544-4df3-80a9-0a7d3fd41f1f  \n**Similarity:** 0.7942753162501964  \n**Text:** \\[10\\]\n\nWow, I thought, there\u2019s an audience. If I write something and put it on the web, anyone can\u2026  \n\n**Node ID:** b203e140-d549-4284-99f4-b1b5bcd996ea  \n**Similarity:** 0.7788031317604815  \n**Text:** Now all I had to do was learn Italian.\n\nOnly stranieri (foreigners) had to take this entrance exa\u2026  \n\n## Advanced - Hybrid Retriever + Re-Ranking[\uf0c1](#advanced-hybrid-retriever-re-ranking \"Permalink to this heading\")\n\nHere we extend the base retriever class and create a custom retriever that always uses the vector retriever and BM25 retreiver.\n\nThen, nodes can be re-ranked and filtered. This lets us keep intermediate top-k values large and letting the re-ranking filter out un-needed nodes.\n\nTo best demonstrate this, we will use a larger set of source documents \u2013 Chapter 3 from the 2022 IPCC Climate Report.\n\n### Setup data[\uf0c1](#setup-data \"Permalink to this heading\")\n\n!curl https://www.ipcc.ch/report/ar6/wg2/downloads/report/IPCC\\_AR6\\_WGII\\_Chapter03.pdf \\--output IPCC\\_AR6\\_WGII\\_Chapter03.pdf\n\n  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n                                 Dload  Upload   Total   Spent    Left  Speed\n100 20.7M  100 20.7M    0     0   361k      0  0:00:58  0:00:58 --:--:--  422k\n\nfrom llama\\_index import (\n    VectorStoreIndex,\n    ServiceContext,\n    StorageContext,\n    SimpleDirectoryReader,\n)\nfrom llama\\_index.llms import OpenAI\n\n\\# load documents\ndocuments \\= SimpleDirectoryReader(\n    input\\_files\\=\\[\"IPCC\\_AR6\\_WGII\\_Chapter03.pdf\"\\]\n).load\\_data()\n\n\\# initialize service context (set chunk size)\n\\# -- here, we set a smaller chunk size, to allow for more effective re-ranking\nllm \\= OpenAI(model\\=\"gpt-3.5-turbo\")\nservice\\_context \\= ServiceContext.from\\_defaults(chunk\\_size\\=256, llm\\=llm)\nnodes \\= service\\_context.node\\_parser.get\\_nodes\\_from\\_documents(documents)\n\n\\# initialize storage context (by default it's in-memory)\nstorage\\_context \\= StorageContext.from\\_defaults()\nstorage\\_context.docstore.add\\_documents(nodes)\n\nindex \\= VectorStoreIndex(\n    nodes, storage\\_context\\=storage\\_context, service\\_context\\=service\\_context\n)\n\nfrom llama\\_index.retrievers import BM25Retriever\n\n\\# retireve the top 10 most similar nodes using embeddings\nvector\\_retriever \\= index.as\\_retriever(similarity\\_top\\_k\\=10)\n\n\\# retireve the top 10 most similar nodes using bm25\nbm25\\_retriever \\= BM25Retriever.from\\_defaults(nodes\\=nodes, similarity\\_top\\_k\\=10)\n\n### Custom Retriever Implementation[\uf0c1](#custom-retriever-implementation \"Permalink to this heading\")\n\nfrom llama\\_index.retrievers import BaseRetriever\n\nclass HybridRetriever(BaseRetriever):\n    def \\_\\_init\\_\\_(self, vector\\_retriever, bm25\\_retriever):\n        self.vector\\_retriever \\= vector\\_retriever\n        self.bm25\\_retriever \\= bm25\\_retriever\n\n    def \\_retrieve(self, query, \\*\\*kwargs):\n        bm25\\_nodes \\= self.bm25\\_retriever.retrieve(query, \\*\\*kwargs)\n        vector\\_nodes \\= self.vector\\_retriever.retrieve(query, \\*\\*kwargs)\n\n        \\# combine the two lists of nodes\n        all\\_nodes \\= \\[\\]\n        node\\_ids \\= set()\n        for n in bm25\\_nodes + vector\\_nodes:\n            if n.node.node\\_id not in node\\_ids:\n                all\\_nodes.append(n)\n                node\\_ids.add(n.node.node\\_id)\n        return all\\_nodes\n\nindex.as\\_retriever(similarity\\_top\\_k\\=5)\n\nhybrid\\_retriever \\= HybridRetriever(vector\\_retriever, bm25\\_retriever)\n\n### Re-Ranker Setup[\uf0c1](#re-ranker-setup \"Permalink to this heading\")\n\n\\# !pip install sentence\\_transformers\n\nfrom llama\\_index.indices.postprocessor import SentenceTransformerRerank\n\nreranker \\= SentenceTransformerRerank(top\\_n\\=4, model\\=\"BAAI/bge-reranker-base\")\n\nDownloading (\u2026)lve/main/config.json: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 799/799 \\[00:00<00:00, 3.86MB/s\\]\nDownloading pytorch\\_model.bin: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1.11G/1.11G \\[00:32<00:00, 34.4MB/s\\]\nDownloading (\u2026)okenizer\\_config.json: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 443/443 \\[00:00<00:00, 2.19MB/s\\]\nDownloading (\u2026)tencepiece.bpe.model: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 5.07M/5.07M \\[00:00<00:00, 14.1MB/s\\]\nDownloading (\u2026)cial\\_tokens\\_map.json: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 279/279 \\[00:00<00:00, 1.48MB/s\\]\n\n### Retrieve[\uf0c1](#retrieve \"Permalink to this heading\")\n\nfrom llama\\_index import QueryBundle\n\nnodes \\= hybrid\\_retriever.retrieve(\n    \"What is the impact of climate change on the ocean?\"\n)\nreranked\\_nodes \\= reranker.postprocess\\_nodes(\n    nodes,\n    query\\_bundle\\=QueryBundle(\n        \"What is the impact of climate change on the ocean?\"\n    ),\n)\n\nprint(\"Initial retrieval: \", len(nodes), \" nodes\")\nprint(\"Re-ranked retrieval: \", len(reranked\\_nodes), \" nodes\")\n\nBatches: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 \\[00:05<00:00,  5.61s/it\\]\n\nInitial retrieval:  19  nodes\nRe-ranked retrieval:  4  nodes\n\nfrom llama\\_index.response.notebook\\_utils import display\\_source\\_node\n\nfor node in reranked\\_nodes:\n    display\\_source\\_node(node)\n\n**Node ID:** 74b12b7b-f4b9-490a-9342-b640211468dd  \n**Similarity:** 0.998129665851593  \n**Text:** 3 469Oceans and Coastal Ecosystems and Their Services Chapter 3 Frequently Asked Questions FAQ 3\u2026  \n\n**Node ID:** 2b35824c-2e96-47b7-8dfb-da25c4eefb7d  \n**Similarity:** 0.996731162071228  \n**Text:** {Box\u00a03.2, 3.2.2.1, 3.4.2.5, 3.4.2.10, 3.4.3.3, Cross-Chapter Box\u00a0PALEO in Chapter\u00a01} Climate imp\u2026  \n\n**Node ID:** 01ef2a9e-0dd0-4bce-ab60-e6a3f6456f7b  \n**Similarity:** 0.9954373240470886  \n**Text:** These ecosystems are also influenced by non-climate drivers, especially fisheries, oil and gas ex\u2026  \n\n**Node ID:** 8a23b728-0352-4b01-a5c0-42765669855d  \n**Similarity:** 0.9872682690620422  \n**Text:** Additionally, climate-change-driven oxygen loss (Section\u00a0 3.2.3.2; Luna et\u00a0 al., 2012; Belley et\u2026  \n\n### Full Query Engine[\uf0c1](#full-query-engine \"Permalink to this heading\")\n\nfrom llama\\_index.query\\_engine import RetrieverQueryEngine\n\nquery\\_engine \\= RetrieverQueryEngine.from\\_args(\n    retriever\\=hybrid\\_retriever,\n    node\\_postprocessors\\=\\[reranker\\],\n    service\\_context\\=service\\_context,\n)\n\nresponse \\= query\\_engine.query(\n    \"What is the impact of climate change on the ocean?\"\n)\n\nBatches: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 \\[00:05<00:00,  5.74s/it\\]\n\nfrom llama\\_index.response.notebook\\_utils import display\\_response\n\ndisplay\\_response(response)\n\n**`Final Response:`** Climate change has significant impacts on the ocean. It is degrading ocean health and altering stocks of marine resources. This, combined with over-harvesting, is threatening the sustenance provided to Indigenous Peoples, the livelihoods of artisanal fisheries, and marine-based industries such as tourism, shipping, and transportation. Climate change can also influence human activities and employment by altering resource availability, spreading pathogens, flooding shorelines, and degrading ocean ecosystems. Additionally, increases in intensity, reoccurrence, and duration of marine heatwaves due to climate change can lead to species extirpation, habitat collapse, and surpassing ecological tipping points. Some habitat-forming coastal ecosystems, including coral reefs, kelp forests, and seagrass meadows, are at high risk of irreversible phase shifts due to marine heatwaves. Non-climate drivers such as fisheries, oil and gas extraction, cable laying, and mineral resource exploration also influence ocean ecosystems."
}