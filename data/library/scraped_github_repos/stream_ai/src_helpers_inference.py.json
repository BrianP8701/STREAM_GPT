{
    "metadata": {
        "type": "repo",
        "path": "src/helpers/inference.py"
    },
    "text": "'''\nThis file contains functions that perform object detection or classification.\n'''\nfrom src.YOLOv8.inference import Inference\nimport src.MobileNetv3.inference as Mobilenet\nimport cv2\n\n# inf = Inference(c.YOLO_PATH)\ndef yolo_inference(img, model):\n    if isinstance(img, str):\n        img = cv2.imread(img)\n        \n    box = model.predict(img)\n    return box\n\n\n# model = mobilenet.load_model('src2/MobileNetv3/mob_l_gmms2_finetune.pt')\ndef mobile_inference(img, model):\n    image_class = Mobilenet.infer_image(img, model)\n    \n    if image_class == 0: image_class = 'normal'\n    elif image_class == 1: image_class = 'over'\n    elif image_class == 2: image_class = 'under'\n    return image_class\n\n\n# YOLO inference on image larger than 640x640\ndef infer_large_image(img, model, stride=320):\n    if isinstance(img, str):\n        img = cv2.imread(img)\n        \n    # Initialize the bounding box to [-1, -1, -1, -1]\n    bbox = [-1, -1, -1, -1]\n\n    # Get the dimensions of the image\n    height, width, _ = img.shape\n\n    # Slide a 640x640 window across the image\n    for y in range(0, height - 640, stride):\n        for x in range(0, width - 640, stride):\n            # Extract the window\n            window = img[y:y+640, x:x+640]\n\n            # Apply the yolo_inference method to the window\n            window_bbox = yolo_inference(window, model)\n\n            # If an object was detected in the window, update the bounding box\n            if window_bbox != [-1, -1, -1, -1]:\n                # Adjust the coordinates of the bounding box to be relative to the whole image\n                bbox = [x + window_bbox[0], y + window_bbox[1], x + window_bbox[2], y + window_bbox[3]]\n\n    return bbox\n\n"
}