{
    "metadata": {
        "type": "web",
        "url": "https://docs.llamaindex.ai/en/stable/api_reference/query/chat_engines/condense_question_chat_engine.html",
        "title": "Condense Question Chat Engine - LlamaIndex \ud83e\udd99 0.8.49",
        "description": null
    },
    "text": "[Back to top](#)\n\nToggle table of contents sidebar\n\n## Condense Question Chat Engine[\uf0c1](#condense-question-chat-engine \"Permalink to this heading\")\n\n_class_ llama\\_index.chat\\_engine.condense\\_question.CondenseQuestionChatEngine(_query\\_engine: BaseQueryEngine_, _condense\\_question\\_prompt: [BasePromptTemplate](https://docs.llamaindex.ai/en/stable/api_reference/prompts.html#llama_index.prompts.base.BasePromptTemplate \"llama_index.prompts.base.BasePromptTemplate\")_, _memory: [BaseMemory](https://docs.llamaindex.ai/en/stable/api_reference/memory.html#llama_index.memory.BaseMemory \"llama_index.memory.types.BaseMemory\")_, _service\\_context: [ServiceContext](https://docs.llamaindex.ai/en/stable/api_reference/service_context.html#llama_index.indices.service_context.ServiceContext \"llama_index.indices.service_context.ServiceContext\")_, _verbose: bool \\= False_, _callback\\_manager: Optional\\[[CallbackManager](https://docs.llamaindex.ai/en/stable/api_reference/callbacks.html#llama_index.callbacks.CallbackManager \"llama_index.callbacks.base.CallbackManager\")\\] \\= None_)[\uf0c1](#llama_index.chat_engine.condense_question.CondenseQuestionChatEngine \"Permalink to this definition\")\n\nCondense Question Chat Engine.\n\nFirst generate a standalone question from conversation context and last message, then query the query engine for a response.\n\n_async_ achat(_\\*args: Any_, _\\*\\*kwargs: Any_) \u2192 Any[\uf0c1](#llama_index.chat_engine.condense_question.CondenseQuestionChatEngine.achat \"Permalink to this definition\")\n\nAsync version of main chat interface.\n\n_async_ astream\\_chat(_\\*args: Any_, _\\*\\*kwargs: Any_) \u2192 Any[\uf0c1](#llama_index.chat_engine.condense_question.CondenseQuestionChatEngine.astream_chat \"Permalink to this definition\")\n\nAsync version of main chat interface.\n\nchat(_\\*args: Any_, _\\*\\*kwargs: Any_) \u2192 Any[\uf0c1](#llama_index.chat_engine.condense_question.CondenseQuestionChatEngine.chat \"Permalink to this definition\")\n\nMain chat interface.\n\n_property_ chat\\_history_: List\\[[ChatMessage](https://docs.llamaindex.ai/en/stable/api_reference/llms.html#llama_index.llms.base.ChatMessage \"llama_index.llms.base.ChatMessage\")\\]_[\uf0c1](#llama_index.chat_engine.condense_question.CondenseQuestionChatEngine.chat_history \"Permalink to this definition\")\n\nGet chat history.\n\nchat\\_repl() \u2192 None[\uf0c1](#llama_index.chat_engine.condense_question.CondenseQuestionChatEngine.chat_repl \"Permalink to this definition\")\n\nEnter interactive chat REPL.\n\n_classmethod_ from\\_defaults(_query\\_engine: ~llama\\_index.indices.query.base.BaseQueryEngine_, _condense\\_question\\_prompt: ~typing.Optional\\[~llama\\_index.prompts.base.BasePromptTemplate\\] \\= None_, _chat\\_history: ~typing.Optional\\[~typing.List\\[~llama\\_index.llms.base.ChatMessage\\]\\] \\= None_, _memory: ~typing.Optional\\[~llama\\_index.memory.types.BaseMemory\\] \\= None_, _memory\\_cls: ~typing.Type\\[~llama\\_index.memory.types.BaseMemory\\] \\= <class 'llama\\_index.memory.chat\\_memory\\_buffer.ChatMemoryBuffer'>_, _service\\_context: ~typing.Optional\\[~llama\\_index.indices.service\\_context.ServiceContext\\] \\= None_, _verbose: bool \\= False_, _system\\_prompt: ~typing.Optional\\[str\\] \\= None_, _prefix\\_messages: ~typing.Optional\\[~typing.List\\[~llama\\_index.llms.base.ChatMessage\\]\\] \\= None_, _\\*\\*kwargs: ~typing.Any_) \u2192 [CondenseQuestionChatEngine](#llama_index.chat_engine.condense_question.CondenseQuestionChatEngine \"llama_index.chat_engine.condense_question.CondenseQuestionChatEngine\")[\uf0c1](#llama_index.chat_engine.condense_question.CondenseQuestionChatEngine.from_defaults \"Permalink to this definition\")\n\nInitialize a CondenseQuestionChatEngine from default parameters.\n\nreset() \u2192 None[\uf0c1](#llama_index.chat_engine.condense_question.CondenseQuestionChatEngine.reset \"Permalink to this definition\")\n\nReset conversation state.\n\nstream\\_chat(_\\*args: Any_, _\\*\\*kwargs: Any_) \u2192 Any[\uf0c1](#llama_index.chat_engine.condense_question.CondenseQuestionChatEngine.stream_chat \"Permalink to this definition\")\n\nStream chat interface."
}