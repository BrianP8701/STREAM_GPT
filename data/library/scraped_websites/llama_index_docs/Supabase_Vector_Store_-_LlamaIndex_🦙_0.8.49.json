{
    "metadata": {
        "type": "web",
        "url": "https://docs.llamaindex.ai/en/stable/examples/vector_stores/SupabaseVectorIndexDemo.html",
        "title": "Supabase Vector Store - LlamaIndex \ud83e\udd99 0.8.49",
        "description": null
    },
    "text": "[Back to top](#)\n\nToggle table of contents sidebar\n\n## Supabase Vector Store[\uf0c1](#supabase-vector-store \"Permalink to this heading\")\n\nIn this notebook we are going to show how to use [Vecs](https://supabase.github.io/vecs/) to perform vector searches in LlamaIndex.  \nSee [this guide](https://supabase.github.io/vecs/hosting/) for instructions on hosting a database on Supabase\n\nimport logging\nimport sys\n\n\\# Uncomment to see debug logs\n\\# logging.basicConfig(stream=sys.stdout, level=logging.DEBUG)\n\\# logging.getLogger().addHandler(logging.StreamHandler(stream=sys.stdout))\n\nfrom llama\\_index import SimpleDirectoryReader, Document, StorageContext\nfrom llama\\_index.indices.vector\\_store import VectorStoreIndex\nfrom llama\\_index.vector\\_stores import SupabaseVectorStore\nimport textwrap\n\n## Setup OpenAI[\uf0c1](#setup-openai \"Permalink to this heading\")\n\nThe first step is to configure the OpenAI key. It will be used to created embeddings for the documents loaded into the index\n\nimport os\n\nos.environ\\[\"OPENAI\\_API\\_KEY\"\\] \\= \"\\[your\\_openai\\_api\\_key\\]\"\n\n## Loading documents[\uf0c1](#loading-documents \"Permalink to this heading\")\n\nLoad the documents stored in the `../data/paul_graham/` using the SimpleDirectoryReader\n\ndocuments \\= SimpleDirectoryReader(\"../data/paul\\_graham/\").load\\_data()\nprint(\n    \"Document ID:\",\n    documents\\[0\\].doc\\_id,\n    \"Document Hash:\",\n    documents\\[0\\].doc\\_hash,\n)\n\nDocument ID: fb056993-ee9e-4463-80b4-32cf9509d1d8 Document Hash: 77ae91ab542f3abb308c4d7c77c9bc4c9ad0ccd63144802b7cbe7e1bb3a4094e\n\n## Create an index backed by Supabase\u2019s vector store.[\uf0c1](#create-an-index-backed-by-supabase-s-vector-store \"Permalink to this heading\")\n\nThis will work with all Postgres providers that support pgvector. If the collection does not exist, we will attempt to create a new collection\n\n> Note: you need to pass in the embedding dimension if not using OpenAI\u2019s text-embedding-ada-002, e.g. `vector_store = SupabaseVectorStore(..., dimension=...)`\n\nvector\\_store \\= SupabaseVectorStore(\n    postgres\\_connection\\_string\\=(\n        \"postgresql://<user>:<password>@<host>:<port>/<db\\_name>\"\n    ),\n    collection\\_name\\=\"base\\_demo\",\n)\nstorage\\_context \\= StorageContext.from\\_defaults(vector\\_store\\=vector\\_store)\nindex \\= VectorStoreIndex.from\\_documents(\n    documents, storage\\_context\\=storage\\_context\n)\n\n## Query the index[\uf0c1](#query-the-index \"Permalink to this heading\")\n\nWe can now ask questions using our index.\n\nquery\\_engine \\= index.as\\_query\\_engine()\nresponse \\= query\\_engine.query(\"Who is the author?\")\n\n/Users/suo/miniconda3/envs/llama/lib/python3.9/site-packages/vecs/collection.py:182: UserWarning: Query does not have a covering index for cosine\\_distance. See Collection.create\\_index\n  warnings.warn(\n\nprint(textwrap.fill(str(response), 100))\n\n The author of this text is Paul Graham.\n\nresponse \\= query\\_engine.query(\"What did the author do growing up?\")\n\nprint(textwrap.fill(str(response), 100))\n\n The author grew up writing essays, learning Italian, exploring Florence, painting people, working\nwith computers, attending RISD, living in a rent-stabilized apartment, building an online store\nbuilder, editing Lisp expressions, publishing essays online, writing essays, painting still life,\nworking on spam filters, cooking for groups, and buying a building in Cambridge."
}